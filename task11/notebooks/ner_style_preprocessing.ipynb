{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "## Approah 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train_articles = pd.read_csv(\"/data/semeval-2020/task-11/processed/train_article.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "spans = pd.read_csv(\"/data/semeval-2020/task-11/processed/span_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>762956953</td>\n",
       "      <td>Iran Admits To Aiding Al-Qaeda and Facilitatin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>787529309</td>\n",
       "      <td>The Last-Minute Character Assassination of Jud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>999001296</td>\n",
       "      <td>Altered Election Documents Tied To Florida Dem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>729348908</td>\n",
       "      <td>Virginia man who wanted to join ISIS pleads gu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>111111134</td>\n",
       "      <td>Paul Manafort Secretly Met With Julian Assange...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                            content\n",
       "0   762956953  Iran Admits To Aiding Al-Qaeda and Facilitatin...\n",
       "1   787529309  The Last-Minute Character Assassination of Jud...\n",
       "2   999001296  Altered Election Documents Tied To Florida Dem...\n",
       "3   729348908  Virginia man who wanted to join ISIS pleads gu...\n",
       "4   111111134  Paul Manafort Secretly Met With Julian Assange..."
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>776616374</td>\n",
       "      <td>149</td>\n",
       "      <td>174</td>\n",
       "      <td>Exaggeration_Minimisation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>776616374</td>\n",
       "      <td>751</td>\n",
       "      <td>786</td>\n",
       "      <td>Exaggeration_Minimisation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>776616374</td>\n",
       "      <td>831</td>\n",
       "      <td>849</td>\n",
       "      <td>Name_Calling_Labeling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>776616374</td>\n",
       "      <td>2641</td>\n",
       "      <td>2650</td>\n",
       "      <td>Flag-Waving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>776616374</td>\n",
       "      <td>2771</td>\n",
       "      <td>2782</td>\n",
       "      <td>Loaded_Language</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id  start   end                      label\n",
       "0   776616374    149   174  Exaggeration_Minimisation\n",
       "1   776616374    751   786  Exaggeration_Minimisation\n",
       "2   776616374    831   849      Name_Calling_Labeling\n",
       "3   776616374   2641  2650                Flag-Waving\n",
       "4   776616374   2771  2782            Loaded_Language"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "spans[\"start_end\"] = spans.apply(lambda x:(x.start,x.end,x.label),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>label</th>\n",
       "      <th>start_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>776616374</td>\n",
       "      <td>149</td>\n",
       "      <td>174</td>\n",
       "      <td>Exaggeration_Minimisation</td>\n",
       "      <td>(149, 174, Exaggeration_Minimisation)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>776616374</td>\n",
       "      <td>751</td>\n",
       "      <td>786</td>\n",
       "      <td>Exaggeration_Minimisation</td>\n",
       "      <td>(751, 786, Exaggeration_Minimisation)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>776616374</td>\n",
       "      <td>831</td>\n",
       "      <td>849</td>\n",
       "      <td>Name_Calling_Labeling</td>\n",
       "      <td>(831, 849, Name_Calling_Labeling)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>776616374</td>\n",
       "      <td>2641</td>\n",
       "      <td>2650</td>\n",
       "      <td>Flag-Waving</td>\n",
       "      <td>(2641, 2650, Flag-Waving)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>776616374</td>\n",
       "      <td>2771</td>\n",
       "      <td>2782</td>\n",
       "      <td>Loaded_Language</td>\n",
       "      <td>(2771, 2782, Loaded_Language)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id  start   end                      label  \\\n",
       "0   776616374    149   174  Exaggeration_Minimisation   \n",
       "1   776616374    751   786  Exaggeration_Minimisation   \n",
       "2   776616374    831   849      Name_Calling_Labeling   \n",
       "3   776616374   2641  2650                Flag-Waving   \n",
       "4   776616374   2771  2782            Loaded_Language   \n",
       "\n",
       "                               start_end  \n",
       "0  (149, 174, Exaggeration_Minimisation)  \n",
       "1  (751, 786, Exaggeration_Minimisation)  \n",
       "2      (831, 849, Name_Calling_Labeling)  \n",
       "3              (2641, 2650, Flag-Waving)  \n",
       "4          (2771, 2782, Loaded_Language)  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "article_with_span = train_articles.merge(spans,on=\"article_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "article_with_span[\"article_length\"] = article_with_span.content.apply(lambda x: len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>content</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>label</th>\n",
       "      <th>start_end</th>\n",
       "      <th>article_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>762956953</td>\n",
       "      <td>Iran Admits To Aiding Al-Qaeda and Facilitatin...</td>\n",
       "      <td>630</td>\n",
       "      <td>669</td>\n",
       "      <td>Exaggeration_Minimisation</td>\n",
       "      <td>(630, 669, Exaggeration_Minimisation)</td>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>787529309</td>\n",
       "      <td>The Last-Minute Character Assassination of Jud...</td>\n",
       "      <td>70</td>\n",
       "      <td>88</td>\n",
       "      <td>Loaded_Language</td>\n",
       "      <td>(70, 88, Loaded_Language)</td>\n",
       "      <td>1568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>787529309</td>\n",
       "      <td>The Last-Minute Character Assassination of Jud...</td>\n",
       "      <td>288</td>\n",
       "      <td>320</td>\n",
       "      <td>Loaded_Language</td>\n",
       "      <td>(288, 320, Loaded_Language)</td>\n",
       "      <td>1568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>787529309</td>\n",
       "      <td>The Last-Minute Character Assassination of Jud...</td>\n",
       "      <td>924</td>\n",
       "      <td>961</td>\n",
       "      <td>Loaded_Language</td>\n",
       "      <td>(924, 961, Loaded_Language)</td>\n",
       "      <td>1568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>787529309</td>\n",
       "      <td>The Last-Minute Character Assassination of Jud...</td>\n",
       "      <td>2405</td>\n",
       "      <td>2431</td>\n",
       "      <td>Loaded_Language</td>\n",
       "      <td>(2405, 2431, Loaded_Language)</td>\n",
       "      <td>1568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>789121265</td>\n",
       "      <td>Juanita Broaddrick: Senator Feinstein Had No I...</td>\n",
       "      <td>1969</td>\n",
       "      <td>1979</td>\n",
       "      <td>Loaded_Language</td>\n",
       "      <td>(1969, 1979, Loaded_Language)</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>789121265</td>\n",
       "      <td>Juanita Broaddrick: Senator Feinstein Had No I...</td>\n",
       "      <td>2018</td>\n",
       "      <td>2195</td>\n",
       "      <td>Whataboutism_Straw_Men_Red_Herring</td>\n",
       "      <td>(2018, 2195, Whataboutism_Straw_Men_Red_Herring)</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>789121265</td>\n",
       "      <td>Juanita Broaddrick: Senator Feinstein Had No I...</td>\n",
       "      <td>2566</td>\n",
       "      <td>2577</td>\n",
       "      <td>Loaded_Language</td>\n",
       "      <td>(2566, 2577, Loaded_Language)</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>789121265</td>\n",
       "      <td>Juanita Broaddrick: Senator Feinstein Had No I...</td>\n",
       "      <td>2848</td>\n",
       "      <td>2893</td>\n",
       "      <td>Doubt</td>\n",
       "      <td>(2848, 2893, Doubt)</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>789121265</td>\n",
       "      <td>Juanita Broaddrick: Senator Feinstein Had No I...</td>\n",
       "      <td>2926</td>\n",
       "      <td>3069</td>\n",
       "      <td>Whataboutism_Straw_Men_Red_Herring</td>\n",
       "      <td>(2926, 3069, Whataboutism_Straw_Men_Red_Herring)</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    article_id                                            content  start  \\\n",
       "0    762956953  Iran Admits To Aiding Al-Qaeda and Facilitatin...    630   \n",
       "1    787529309  The Last-Minute Character Assassination of Jud...     70   \n",
       "2    787529309  The Last-Minute Character Assassination of Jud...    288   \n",
       "3    787529309  The Last-Minute Character Assassination of Jud...    924   \n",
       "4    787529309  The Last-Minute Character Assassination of Jud...   2405   \n",
       "..         ...                                                ...    ...   \n",
       "95   789121265  Juanita Broaddrick: Senator Feinstein Had No I...   1969   \n",
       "96   789121265  Juanita Broaddrick: Senator Feinstein Had No I...   2018   \n",
       "97   789121265  Juanita Broaddrick: Senator Feinstein Had No I...   2566   \n",
       "98   789121265  Juanita Broaddrick: Senator Feinstein Had No I...   2848   \n",
       "99   789121265  Juanita Broaddrick: Senator Feinstein Had No I...   2926   \n",
       "\n",
       "     end                               label  \\\n",
       "0    669           Exaggeration_Minimisation   \n",
       "1     88                     Loaded_Language   \n",
       "2    320                     Loaded_Language   \n",
       "3    961                     Loaded_Language   \n",
       "4   2431                     Loaded_Language   \n",
       "..   ...                                 ...   \n",
       "95  1979                     Loaded_Language   \n",
       "96  2195  Whataboutism_Straw_Men_Red_Herring   \n",
       "97  2577                     Loaded_Language   \n",
       "98  2893                               Doubt   \n",
       "99  3069  Whataboutism_Straw_Men_Red_Herring   \n",
       "\n",
       "                                           start_end  article_length  \n",
       "0              (630, 669, Exaggeration_Minimisation)             392  \n",
       "1                          (70, 88, Loaded_Language)            1568  \n",
       "2                        (288, 320, Loaded_Language)            1568  \n",
       "3                        (924, 961, Loaded_Language)            1568  \n",
       "4                      (2405, 2431, Loaded_Language)            1568  \n",
       "..                                               ...             ...  \n",
       "95                     (1969, 1979, Loaded_Language)             710  \n",
       "96  (2018, 2195, Whataboutism_Straw_Men_Red_Herring)             710  \n",
       "97                     (2566, 2577, Loaded_Language)             710  \n",
       "98                               (2848, 2893, Doubt)             710  \n",
       "99  (2926, 3069, Whataboutism_Straw_Men_Red_Herring)             710  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_with_span.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def create_label_seq(row):\n",
    "    article_id = row.article_id\n",
    "    if (article_id == 762956953):\n",
    "        return []\n",
    "    article = row.content\n",
    "    print(article_id)\n",
    "    len_article = len(article.split(\" \"))\n",
    "    \n",
    "    article_labels_seq = []\n",
    "    article_span_seq = []\n",
    "    article_no_propaganda_seq = []\n",
    "    \n",
    "    for i in range(len_article):\n",
    "        article_labels_seq.append(\"O\")\n",
    "    \n",
    "    spans_for_article = list(set(spans[spans[\"article_id\"] == article_id].start_end.values.tolist()))\n",
    "    print(spans_for_article)\n",
    "    for start_end in spans_for_article:\n",
    "        start = start_end[0]\n",
    "        end = start_end[1]\n",
    "        propaganda = start_end[2]\n",
    "        for ix in range(start,end):\n",
    "            \n",
    "            \n",
    "            \n",
    "            new_tag = None\n",
    "            print(len(article_labels_seq),start,end)\n",
    "            current_tag = article_labels_seq[ix]\n",
    "            if current_tag == \"O\":\n",
    "                article_labels_seq[ix] = propaganda\n",
    "            else:\n",
    "                current_tags = current_tag.split(\",\")\n",
    "                current_tags.append(propaganda)\n",
    "                current_tag_string = \",\".join(current_tags)\n",
    "                article_labels_seq[ix] = current_tag_string\n",
    "    \n",
    "    return article_labels_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train_articles[\"label\"] = train_articles.apply(lambda x: create_label_seq(x),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1568"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_articles[train_articles[\"article_id\"] == 787529309].content[1].split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>label</th>\n",
       "      <th>start_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1539</td>\n",
       "      <td>787529309</td>\n",
       "      <td>70</td>\n",
       "      <td>88</td>\n",
       "      <td>Loaded_Language</td>\n",
       "      <td>(70, 88, Loaded_Language)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1540</td>\n",
       "      <td>787529309</td>\n",
       "      <td>288</td>\n",
       "      <td>320</td>\n",
       "      <td>Loaded_Language</td>\n",
       "      <td>(288, 320, Loaded_Language)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1541</td>\n",
       "      <td>787529309</td>\n",
       "      <td>924</td>\n",
       "      <td>961</td>\n",
       "      <td>Loaded_Language</td>\n",
       "      <td>(924, 961, Loaded_Language)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1542</td>\n",
       "      <td>787529309</td>\n",
       "      <td>2405</td>\n",
       "      <td>2431</td>\n",
       "      <td>Loaded_Language</td>\n",
       "      <td>(2405, 2431, Loaded_Language)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1543</td>\n",
       "      <td>787529309</td>\n",
       "      <td>2694</td>\n",
       "      <td>2708</td>\n",
       "      <td>Loaded_Language</td>\n",
       "      <td>(2694, 2708, Loaded_Language)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1544</td>\n",
       "      <td>787529309</td>\n",
       "      <td>3158</td>\n",
       "      <td>3173</td>\n",
       "      <td>Loaded_Language</td>\n",
       "      <td>(3158, 3173, Loaded_Language)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1545</td>\n",
       "      <td>787529309</td>\n",
       "      <td>8209</td>\n",
       "      <td>8232</td>\n",
       "      <td>Name_Calling_Labeling</td>\n",
       "      <td>(8209, 8232, Name_Calling_Labeling)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1546</td>\n",
       "      <td>787529309</td>\n",
       "      <td>8337</td>\n",
       "      <td>8366</td>\n",
       "      <td>Name_Calling_Labeling</td>\n",
       "      <td>(8337, 8366, Name_Calling_Labeling)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1547</td>\n",
       "      <td>787529309</td>\n",
       "      <td>8567</td>\n",
       "      <td>8586</td>\n",
       "      <td>Loaded_Language</td>\n",
       "      <td>(8567, 8586, Loaded_Language)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1548</td>\n",
       "      <td>787529309</td>\n",
       "      <td>8686</td>\n",
       "      <td>8711</td>\n",
       "      <td>Loaded_Language</td>\n",
       "      <td>(8686, 8711, Loaded_Language)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1549</td>\n",
       "      <td>787529309</td>\n",
       "      <td>9303</td>\n",
       "      <td>9384</td>\n",
       "      <td>Causal_Oversimplification</td>\n",
       "      <td>(9303, 9384, Causal_Oversimplification)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>787529309</td>\n",
       "      <td>9661</td>\n",
       "      <td>9697</td>\n",
       "      <td>Loaded_Language</td>\n",
       "      <td>(9661, 9697, Loaded_Language)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1551</td>\n",
       "      <td>787529309</td>\n",
       "      <td>16</td>\n",
       "      <td>40</td>\n",
       "      <td>Slogans</td>\n",
       "      <td>(16, 40, Slogans)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1552</td>\n",
       "      <td>787529309</td>\n",
       "      <td>5159</td>\n",
       "      <td>5195</td>\n",
       "      <td>Loaded_Language</td>\n",
       "      <td>(5159, 5195, Loaded_Language)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1553</td>\n",
       "      <td>787529309</td>\n",
       "      <td>323</td>\n",
       "      <td>347</td>\n",
       "      <td>Slogans</td>\n",
       "      <td>(323, 347, Slogans)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1554</td>\n",
       "      <td>787529309</td>\n",
       "      <td>2338</td>\n",
       "      <td>2357</td>\n",
       "      <td>Name_Calling_Labeling</td>\n",
       "      <td>(2338, 2357, Name_Calling_Labeling)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1555</td>\n",
       "      <td>787529309</td>\n",
       "      <td>5394</td>\n",
       "      <td>5414</td>\n",
       "      <td>Name_Calling_Labeling</td>\n",
       "      <td>(5394, 5414, Name_Calling_Labeling)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1556</td>\n",
       "      <td>787529309</td>\n",
       "      <td>6056</td>\n",
       "      <td>6347</td>\n",
       "      <td>Doubt</td>\n",
       "      <td>(6056, 6347, Doubt)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1557</td>\n",
       "      <td>787529309</td>\n",
       "      <td>6678</td>\n",
       "      <td>6784</td>\n",
       "      <td>Appeal_to_Authority</td>\n",
       "      <td>(6678, 6784, Appeal_to_Authority)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1558</td>\n",
       "      <td>787529309</td>\n",
       "      <td>7626</td>\n",
       "      <td>7677</td>\n",
       "      <td>Loaded_Language</td>\n",
       "      <td>(7626, 7677, Loaded_Language)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1559</td>\n",
       "      <td>787529309</td>\n",
       "      <td>7814</td>\n",
       "      <td>7853</td>\n",
       "      <td>Slogans</td>\n",
       "      <td>(7814, 7853, Slogans)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>787529309</td>\n",
       "      <td>8200</td>\n",
       "      <td>8310</td>\n",
       "      <td>Causal_Oversimplification</td>\n",
       "      <td>(8200, 8310, Causal_Oversimplification)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1561</td>\n",
       "      <td>787529309</td>\n",
       "      <td>2871</td>\n",
       "      <td>2877</td>\n",
       "      <td>Loaded_Language</td>\n",
       "      <td>(2871, 2877, Loaded_Language)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1562</td>\n",
       "      <td>787529309</td>\n",
       "      <td>9173</td>\n",
       "      <td>9282</td>\n",
       "      <td>Doubt</td>\n",
       "      <td>(9173, 9282, Doubt)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      article_id  start   end                      label  \\\n",
       "1539   787529309     70    88            Loaded_Language   \n",
       "1540   787529309    288   320            Loaded_Language   \n",
       "1541   787529309    924   961            Loaded_Language   \n",
       "1542   787529309   2405  2431            Loaded_Language   \n",
       "1543   787529309   2694  2708            Loaded_Language   \n",
       "1544   787529309   3158  3173            Loaded_Language   \n",
       "1545   787529309   8209  8232      Name_Calling_Labeling   \n",
       "1546   787529309   8337  8366      Name_Calling_Labeling   \n",
       "1547   787529309   8567  8586            Loaded_Language   \n",
       "1548   787529309   8686  8711            Loaded_Language   \n",
       "1549   787529309   9303  9384  Causal_Oversimplification   \n",
       "1550   787529309   9661  9697            Loaded_Language   \n",
       "1551   787529309     16    40                    Slogans   \n",
       "1552   787529309   5159  5195            Loaded_Language   \n",
       "1553   787529309    323   347                    Slogans   \n",
       "1554   787529309   2338  2357      Name_Calling_Labeling   \n",
       "1555   787529309   5394  5414      Name_Calling_Labeling   \n",
       "1556   787529309   6056  6347                      Doubt   \n",
       "1557   787529309   6678  6784        Appeal_to_Authority   \n",
       "1558   787529309   7626  7677            Loaded_Language   \n",
       "1559   787529309   7814  7853                    Slogans   \n",
       "1560   787529309   8200  8310  Causal_Oversimplification   \n",
       "1561   787529309   2871  2877            Loaded_Language   \n",
       "1562   787529309   9173  9282                      Doubt   \n",
       "\n",
       "                                    start_end  \n",
       "1539                (70, 88, Loaded_Language)  \n",
       "1540              (288, 320, Loaded_Language)  \n",
       "1541              (924, 961, Loaded_Language)  \n",
       "1542            (2405, 2431, Loaded_Language)  \n",
       "1543            (2694, 2708, Loaded_Language)  \n",
       "1544            (3158, 3173, Loaded_Language)  \n",
       "1545      (8209, 8232, Name_Calling_Labeling)  \n",
       "1546      (8337, 8366, Name_Calling_Labeling)  \n",
       "1547            (8567, 8586, Loaded_Language)  \n",
       "1548            (8686, 8711, Loaded_Language)  \n",
       "1549  (9303, 9384, Causal_Oversimplification)  \n",
       "1550            (9661, 9697, Loaded_Language)  \n",
       "1551                        (16, 40, Slogans)  \n",
       "1552            (5159, 5195, Loaded_Language)  \n",
       "1553                      (323, 347, Slogans)  \n",
       "1554      (2338, 2357, Name_Calling_Labeling)  \n",
       "1555      (5394, 5414, Name_Calling_Labeling)  \n",
       "1556                      (6056, 6347, Doubt)  \n",
       "1557        (6678, 6784, Appeal_to_Authority)  \n",
       "1558            (7626, 7677, Loaded_Language)  \n",
       "1559                    (7814, 7853, Slogans)  \n",
       "1560  (8200, 8310, Causal_Oversimplification)  \n",
       "1561            (2871, 2877, Loaded_Language)  \n",
       "1562                      (9173, 9282, Doubt)  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spans[spans[\"article_id\"] == 787529309]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['O', 'O'], dtype='<U1')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [\"O\",\"O\"]\n",
    "np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4, 5]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(3,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Approach 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import swifter\n",
    "path = r'/data/semeval-2020/task-11/datasets/train-tagged_article/'\n",
    "all_files = glob.glob(path + \"/*.txt\")\n",
    "\n",
    "content_tuple = []\n",
    "\n",
    "for filename in all_files:\n",
    "    file = open(filename)\n",
    "    content = \"\".join(file.readlines()).replace(\"\\n\",\" \")\n",
    "    article_id = filename.split(\"article\")[-1].split(\".txt\")[0]\n",
    "    content_tuple.append((article_id,content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "content_df = pd.DataFrame(content_tuple,columns=[\"article_id\",\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>762956953</td>\n",
       "      <td>Iran Admits To Aiding Al-Qaeda and Facilitatin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>787529309</td>\n",
       "      <td>The Last-Minute &lt;span-11 Character Assassinati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>999001296</td>\n",
       "      <td>Altered Election Documents Tied To Florida Dem...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  article_id                                            content\n",
       "0  762956953  Iran Admits To Aiding Al-Qaeda and Facilitatin...\n",
       "1  787529309  The Last-Minute <span-11 Character Assassinati...\n",
       "2  999001296  Altered Election Documents Tied To Florida Dem..."
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English   # updated , \n",
    "from transformers import BertTokenizer\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
    "nlp = English()\n",
    "nlp.add_pipe(nlp.create_pipe('sentencizer')) # updated\n",
    "tokenizer = Tokenizer(nlp.vocab)\n",
    "\n",
    "def get_technique_id(token):\n",
    "    results = {\"start_token\":[],\"end_token\":[]}\n",
    "\n",
    "    if \"<span\" in token:\n",
    "        results[\"start_token\"] = [i.replace(\"<span-\",\"\") for i in re.findall(\"<span-\\d+\",token)]\n",
    "\n",
    "    if \"-/span>\" in token:\n",
    "        results[\"end_token\"] = [i.replace(\"-/span>\",\"\") for i in re.findall(\"\\d+-/span>\",token)]\n",
    "\n",
    "    # return [res for res_array in results_start_span for res in res_array]\n",
    "    return results\n",
    "\n",
    "def get_propaganda_sequence(row):\n",
    "#     print(content)\n",
    "    content_lable_tup = []\n",
    "    content = row.content.replace(\"><\", \"> <\").replace(\">“<\", \"> <\") \\\n",
    "        .replace(\">(<\", \"> <\").replace(\">.<\", \"> <\") \\\n",
    "        .replace(\">\\'<\", \"> <\")\n",
    "    #     article_id = row.article_id\n",
    "    #     print(article_id)\n",
    "    label_seq = []\n",
    "    label_propaganda_seq = []\n",
    "    running_token = []\n",
    "    for sent in nlp(content).sents:\n",
    "        len_of_sentences = len(str(sent).split(\" \"))\n",
    "        tokens = sent.text.split(\" \")\n",
    "#         tokens = tokenizer.tokenize(str(sent))\n",
    "        for ix,token in enumerate(tokens):\n",
    "            token = token.strip()\n",
    "            modified_token = token\n",
    "            if \"span\" in token:\n",
    "                if \"-/span>\" in token:\n",
    "                    #             print(running_token)\n",
    "                    #             print(get_technique_id(token))\n",
    "                    for i in get_technique_id(token)[\"end_token\"]:\n",
    "                        running_token.remove(i)\n",
    "                    running_token = sorted(running_token)\n",
    "\n",
    "                    rest_of_token = re.sub(\"\\d+-/span>\", \"\", token.strip())\n",
    "                    if len(rest_of_token) > 1:\n",
    "                        split_toks = [i.text for i in nlp(rest_of_token)]\n",
    "                        for tok in split_toks:\n",
    "                            if len(running_token) == 0:\n",
    "                                label_propaganda_seq.append(\"O\")\n",
    "                                content_lable_tup.append((tok,\"O\"))\n",
    "                            else:\n",
    "                                label_propaganda_seq.append(\",\".join(running_token))\n",
    "                                content_lable_tup.append((tok, \",\".join(running_token)))\n",
    "\n",
    "                if \"<span\" in token:\n",
    "                    running_token = running_token + get_technique_id(token)[\"start_token\"]\n",
    "                    running_token = sorted(running_token)\n",
    "\n",
    "                    rest_of_token = re.sub(\"<span-\\d+\", \"\", token.strip())\n",
    "                    if len(rest_of_token) > 1:\n",
    "                        split_toks = [i.text for i in nlp(rest_of_token)]\n",
    "                        for tok in split_toks:\n",
    "                            if len(running_token) == 0:\n",
    "                                label_propaganda_seq.append(\"O\")\n",
    "                                content_lable_tup.append((tok, \"O\"))\n",
    "                            else:\n",
    "                                label_propaganda_seq.append(\",\".join(running_token))\n",
    "                                content_lable_tup.append((tok, \",\".join(running_token)))\n",
    "\n",
    "            else:\n",
    "                if len(token) > 0:\n",
    "                    split_toks = [i.text for i in nlp(token)]\n",
    "                    for tok in split_toks:\n",
    "                        if len(running_token) == 0:\n",
    "                            label_propaganda_seq.append(\"O\")\n",
    "                            content_lable_tup.append((tok, \"O\"))\n",
    "                        else:\n",
    "                            label_propaganda_seq.append(\",\".join(running_token))\n",
    "                            content_lable_tup.append((tok, \",\".join(running_token)))\n",
    "            if ix == len_of_sentences -1:\n",
    "                content_lable_tup[-1] = (content_lable_tup[-1][0] + \"$$$$$$\",content_lable_tup[-1][1])\n",
    "                    \n",
    "#     d = nlp(content)\n",
    "#     sentences = [sent.string.strip() for sent in d.sents]\n",
    "#     s = [i + \"$$$$$$\" for i in sentences]\n",
    "\n",
    "    # joined_content = \" \".join([i[0] for i in content_lable_tup])\n",
    "    # d = nlp(joined_content)\n",
    "    # sentences = [sent.string.strip() for sent in d.sents]\n",
    "    # s = [i + \"$$$$$$\" for i in sentences]\n",
    "#     print(content_lable_tup)\n",
    "#     for t in content_lable_tup:\n",
    "#         print(t[0])\n",
    "    new_content = [(re.sub(\"<span-\\d+\", \"\", re.sub(\"\\d+-/span>\", \"\", tup[0])) , tup[1]) for tup in content_lable_tup]\n",
    "\n",
    "    seq_to_return = [i for i in new_content if i[0] != \"\"]\n",
    "\n",
    "    return seq_to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get_propaganda_sequence(content_df[content_df[\"article_id\"] == \"736231219\"].iloc[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "a = nlp(\"This is a 'sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', \"'\", 'sentence']\n"
     ]
    }
   ],
   "source": [
    "print([i.text for i in a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start_token': ['11'], 'end_token': []}"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_technique_id(\"<span-11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get_propaganda_sequence({\"content\":content_df.iloc[2].content,\"article_id\":11})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raghavan/anaconda3/envs/semeval_2020/lib/python3.7/site-packages/tqdm/std.py:648: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "862375034e1241a2861f804a60471df0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=371, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "content_df[\"tagged_sequence_with_propaganda_types\"] = content_df.swifter.apply(get_propaganda_sequence,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'O'),\n",
       " ('Last', 'O'),\n",
       " ('-', 'O'),\n",
       " ('Minute', 'O'),\n",
       " ('Character', '11'),\n",
       " ('Assassination', '11'),\n",
       " ('of', 'O'),\n",
       " ('Judge', 'O'),\n",
       " ('Kavanaugh', 'O'),\n",
       " ('Using', 'O'),\n",
       " ('any', 'O'),\n",
       " ('despicable', '8'),\n",
       " ('tactic', '8'),\n",
       " ('at', 'O'),\n",
       " ('hand', 'O'),\n",
       " ('to', 'O'),\n",
       " ('derail', 'O'),\n",
       " ('Judge', 'O'),\n",
       " ('Brett', 'O'),\n",
       " ('Kavanaugh', 'O'),\n",
       " ('’s', 'O'),\n",
       " ('Supreme', 'O'),\n",
       " ('Court', 'O'),\n",
       " ('confirmation', 'O'),\n",
       " ('less', 'O'),\n",
       " ('than', 'O'),\n",
       " ('a', 'O'),\n",
       " ('week', 'O'),\n",
       " ('before', 'O'),\n",
       " ('the', 'O'),\n",
       " ('Senate', 'O'),\n",
       " ('Judiciary', 'O'),\n",
       " ('Committee', 'O'),\n",
       " ('is', 'O'),\n",
       " ('scheduled', 'O'),\n",
       " ('to', 'O'),\n",
       " ('vote', 'O'),\n",
       " ('on', 'O'),\n",
       " ('whether', 'O'),\n",
       " ('to', 'O'),\n",
       " ('approve', 'O'),\n",
       " ('his', 'O'),\n",
       " ('nomination', 'O'),\n",
       " (',', 'O'),\n",
       " ('Senate', 'O'),\n",
       " ('Democrats', 'O'),\n",
       " ('have', '8'),\n",
       " ('sunk', '8'),\n",
       " ('to', '8'),\n",
       " ('their', '8'),\n",
       " ('lowest', '8'),\n",
       " ('level', '8'),\n",
       " ('of', 'O'),\n",
       " ('character', '11'),\n",
       " ('assassination', '11'),\n",
       " ('yet', 'O'),\n",
       " ('.$$$$$$', 'O'),\n",
       " ('They', 'O'),\n",
       " ('have', 'O'),\n",
       " ('resorted', 'O'),\n",
       " ('to', 'O'),\n",
       " ('peddling', 'O'),\n",
       " ('an', 'O'),\n",
       " ('allegation', 'O'),\n",
       " ('of', 'O'),\n",
       " ('sexual', 'O'),\n",
       " ('misconduct', 'O'),\n",
       " ('against', 'O'),\n",
       " ('Judge', 'O'),\n",
       " ('Kavanaugh', 'O'),\n",
       " ('that', 'O'),\n",
       " ('supposedly', 'O'),\n",
       " ('occurred', 'O'),\n",
       " ('while', 'O'),\n",
       " ('the', 'O'),\n",
       " ('judge', 'O'),\n",
       " ('was', 'O'),\n",
       " ('in', 'O'),\n",
       " ('high', 'O'),\n",
       " ('school', 'O'),\n",
       " ('.$$$$$$', 'O'),\n",
       " ('The', 'O'),\n",
       " ('accuser', 'O'),\n",
       " ('had', 'O'),\n",
       " ('refused', 'O'),\n",
       " ('to', 'O'),\n",
       " ('identify', 'O'),\n",
       " ('herself', 'O'),\n",
       " ('before', 'O'),\n",
       " ('and', 'O'),\n",
       " ('during', 'O'),\n",
       " ('the', 'O'),\n",
       " ('Senate', 'O'),\n",
       " ('Judiciary', 'O'),\n",
       " ('Committee', 'O'),\n",
       " ('hearings', 'O'),\n",
       " ('.$$$$$$', 'O'),\n",
       " ('She', 'O'),\n",
       " ('conveniently', 'O'),\n",
       " ('waited', 'O'),\n",
       " ('until', 'O'),\n",
       " ('this', 'O'),\n",
       " ('Sunday', 'O'),\n",
       " ('to', 'O'),\n",
       " ('come', 'O'),\n",
       " ('forward', 'O'),\n",
       " ('via', 'O'),\n",
       " ('an', 'O'),\n",
       " ('on', 'O'),\n",
       " ('-', 'O'),\n",
       " ('the', 'O'),\n",
       " ('-', 'O'),\n",
       " ('record', 'O'),\n",
       " ('interview', 'O'),\n",
       " ('with', 'O'),\n",
       " ('the', 'O'),\n",
       " ('Washington', 'O'),\n",
       " ('Post', 'O'),\n",
       " ('.$$$$$$', 'O'),\n",
       " ('The', 'O'),\n",
       " ('accuser', 'O'),\n",
       " ('’s', 'O'),\n",
       " ('name', 'O'),\n",
       " ('is', 'O'),\n",
       " ('Christine', 'O'),\n",
       " ('Blasey', 'O'),\n",
       " ('Ford', 'O'),\n",
       " (',', 'O'),\n",
       " ('a', 'O'),\n",
       " ('registered', 'O'),\n",
       " ('Democrat', 'O'),\n",
       " ('who', 'O'),\n",
       " ('is', 'O'),\n",
       " ('currently', 'O'),\n",
       " ('a', 'O'),\n",
       " ('California', 'O'),\n",
       " ('professor', 'O'),\n",
       " ('teaching', 'O'),\n",
       " ('clinical', 'O'),\n",
       " ('psychology', 'O'),\n",
       " ('.$$$$$$', 'O'),\n",
       " ('Judge', 'O'),\n",
       " ('Kavanaugh', 'O'),\n",
       " ('issued', 'O'),\n",
       " ('a', 'O'),\n",
       " ('statement', 'O'),\n",
       " ('on', 'O'),\n",
       " ('Friday', 'O'),\n",
       " ('in', 'O'),\n",
       " ('which', 'O'),\n",
       " ('he', 'O'),\n",
       " ('said', 'O'),\n",
       " (',', 'O'),\n",
       " ('\"', 'O'),\n",
       " ('I', 'O'),\n",
       " ('categorically', '8'),\n",
       " ('and', '8'),\n",
       " ('unequivocally', '8'),\n",
       " ('deny', '8'),\n",
       " ('this', 'O'),\n",
       " ('allegation', 'O'),\n",
       " ('.$$$$$$', 'O'),\n",
       " ('I', 'O'),\n",
       " ('did', 'O'),\n",
       " ('not', 'O'),\n",
       " ('do', 'O'),\n",
       " ('this', 'O'),\n",
       " ('back', 'O'),\n",
       " ('in', 'O'),\n",
       " ('high', 'O'),\n",
       " ('school', 'O'),\n",
       " ('or', 'O'),\n",
       " ('at', 'O'),\n",
       " ('any', 'O'),\n",
       " ('time', 'O'),\n",
       " ('.', 'O'),\n",
       " ('\"$$$$$$', 'O'),\n",
       " ('Senator', 'O'),\n",
       " ('Dianne', 'O'),\n",
       " ('Feinstein', 'O'),\n",
       " ('(', 'O'),\n",
       " ('D', 'O'),\n",
       " ('-', 'O'),\n",
       " ('Calif', 'O'),\n",
       " ('.', 'O'),\n",
       " (')', 'O'),\n",
       " (',$$$$$$', 'O'),\n",
       " ('the', 'O'),\n",
       " ('ranking', 'O'),\n",
       " ('Democrat', 'O'),\n",
       " ('on', 'O'),\n",
       " ('the', 'O'),\n",
       " ('Senate', 'O'),\n",
       " ('Judiciary', 'O'),\n",
       " ('Committee', 'O'),\n",
       " ('that', 'O'),\n",
       " ('heard', 'O'),\n",
       " ('Judge', 'O'),\n",
       " ('Kavanaugh', 'O'),\n",
       " ('’s', 'O'),\n",
       " ('public', 'O'),\n",
       " ('testimony', 'O'),\n",
       " ('earlier', 'O'),\n",
       " ('this', 'O'),\n",
       " ('month', 'O'),\n",
       " ('during', 'O'),\n",
       " ('his', 'O'),\n",
       " ('Supreme', 'O'),\n",
       " ('Court', 'O'),\n",
       " ('confirmation', 'O'),\n",
       " ('hearing', 'O'),\n",
       " (',', 'O'),\n",
       " ('had', 'O'),\n",
       " ('received', 'O'),\n",
       " ('last', 'O'),\n",
       " ('July', 'O'),\n",
       " ('a', 'O'),\n",
       " ('copy', 'O'),\n",
       " ('of', 'O'),\n",
       " ('a', 'O'),\n",
       " ('letter', 'O'),\n",
       " ('written', 'O'),\n",
       " ('by', 'O'),\n",
       " ('the', 'O'),\n",
       " ('woman', 'O'),\n",
       " ('making', 'O'),\n",
       " ('the', 'O'),\n",
       " ('charge', 'O'),\n",
       " (',', 'O'),\n",
       " ('who', 'O'),\n",
       " ('we', 'O'),\n",
       " ('now', 'O'),\n",
       " ('know', 'O'),\n",
       " ('was', 'O'),\n",
       " ('Ms.', 'O'),\n",
       " ('Ford', 'O'),\n",
       " ('.$$$$$$', 'O'),\n",
       " ('Even', 'O'),\n",
       " ('though', 'O'),\n",
       " ('Senator', 'O'),\n",
       " ('Feinstein', 'O'),\n",
       " ('had', 'O'),\n",
       " ('the', 'O'),\n",
       " ('letter', 'O'),\n",
       " ('in', 'O'),\n",
       " ('hand', 'O'),\n",
       " (',', 'O'),\n",
       " ('she', 'O'),\n",
       " ('never', 'O'),\n",
       " ('brought', 'O'),\n",
       " ('up', 'O'),\n",
       " ('the', 'O'),\n",
       " ('charge', 'O'),\n",
       " ('during', 'O'),\n",
       " ('the', 'O'),\n",
       " ('public', 'O'),\n",
       " ('hearing', 'O'),\n",
       " (',', 'O'),\n",
       " ('nor', 'O'),\n",
       " ('during', 'O'),\n",
       " ('her', 'O'),\n",
       " ('own', 'O'),\n",
       " ('meeting', 'O'),\n",
       " ('with', 'O'),\n",
       " ('the', 'O'),\n",
       " ('judge', 'O'),\n",
       " ('.$$$$$$', 'O'),\n",
       " ('Instead', 'O'),\n",
       " (',', 'O'),\n",
       " ('Senator', 'O'),\n",
       " ('Feinstein', 'O'),\n",
       " ('sat', 'O'),\n",
       " ('on', 'O'),\n",
       " ('the', 'O'),\n",
       " ('letter', 'O'),\n",
       " ('until', 'O'),\n",
       " ('late', 'O'),\n",
       " ('last', 'O'),\n",
       " ('week', 'O'),\n",
       " (',', 'O'),\n",
       " ('when', 'O'),\n",
       " ('she', 'O'),\n",
       " ('issued', 'O'),\n",
       " ('a', 'O'),\n",
       " ('cryptic', 'O'),\n",
       " ('release', 'O'),\n",
       " ('stating', 'O'),\n",
       " ('that', 'O'),\n",
       " ('she', 'O'),\n",
       " ('had', 'O'),\n",
       " ('received', 'O'),\n",
       " ('the', 'O'),\n",
       " ('letter', 'O'),\n",
       " ('but', 'O'),\n",
       " ('did', 'O'),\n",
       " ('not', 'O'),\n",
       " ('want', 'O'),\n",
       " ('to', 'O'),\n",
       " ('give', 'O'),\n",
       " ('more', 'O'),\n",
       " ('details', 'O'),\n",
       " ('in', 'O'),\n",
       " ('deference', 'O'),\n",
       " ('to', 'O'),\n",
       " ('the', 'O'),\n",
       " ('woman', 'O'),\n",
       " ('’s', 'O'),\n",
       " ('wish', 'O'),\n",
       " ('to', 'O'),\n",
       " ('keep', 'O'),\n",
       " ('the', 'O'),\n",
       " ('matter', 'O'),\n",
       " ('confidential', 'O'),\n",
       " ('.$$$$$$', 'O'),\n",
       " ('Senator', 'O'),\n",
       " ('Feinstein', 'O'),\n",
       " ('turned', 'O'),\n",
       " ('the', 'O'),\n",
       " ('letter', 'O'),\n",
       " ('over', 'O'),\n",
       " ('to', 'O'),\n",
       " ('the', 'O'),\n",
       " ('FBI', 'O'),\n",
       " ('.$$$$$$', 'O'),\n",
       " ('The', 'O'),\n",
       " ('FBI', 'O'),\n",
       " ('placed', 'O'),\n",
       " ('the', 'O'),\n",
       " ('letter', 'O'),\n",
       " ('in', 'O'),\n",
       " ('its', 'O'),\n",
       " ('background', 'O'),\n",
       " ('file', 'O'),\n",
       " ('on', 'O'),\n",
       " ('Judge', 'O'),\n",
       " ('Kavanaugh', 'O'),\n",
       " ('but', 'O'),\n",
       " ('decided', 'O'),\n",
       " ('not', 'O'),\n",
       " ('to', 'O'),\n",
       " ('pursue', 'O'),\n",
       " ('any', 'O'),\n",
       " ('further', 'O'),\n",
       " ('investigation', 'O'),\n",
       " ('.$$$$$$', 'O'),\n",
       " ('Senator', 'O'),\n",
       " ('Feinstein', 'O'),\n",
       " ('had', 'O'),\n",
       " ('initially', 'O'),\n",
       " ('resisted', 'O'),\n",
       " ('sharing', 'O'),\n",
       " ('the', 'O'),\n",
       " ('contents', 'O'),\n",
       " ('of', 'O'),\n",
       " ('the', 'O'),\n",
       " ('letter', 'O'),\n",
       " ('with', 'O'),\n",
       " ('her', 'O'),\n",
       " ('fellow', 'O'),\n",
       " ('Democrat', 'O'),\n",
       " ('members', 'O'),\n",
       " ('of', 'O'),\n",
       " ('the', 'O'),\n",
       " ('Senate', 'O'),\n",
       " ('Judiciary', 'O'),\n",
       " ('Committee', 'O'),\n",
       " ('or', 'O'),\n",
       " ('to', 'O'),\n",
       " ('go', 'O'),\n",
       " ('public', 'O'),\n",
       " ('with', 'O'),\n",
       " ('its', 'O'),\n",
       " ('existence', 'O'),\n",
       " ('because', 'O'),\n",
       " ('“', 'O'),\n",
       " ('the', 'O'),\n",
       " ('incident', 'O'),\n",
       " ('was', 'O'),\n",
       " ('too', 'O'),\n",
       " ('distant', 'O'),\n",
       " ('in', 'O'),\n",
       " ('the', 'O'),\n",
       " ('past', 'O'),\n",
       " ('to', 'O'),\n",
       " ('merit', 'O'),\n",
       " ('public', 'O'),\n",
       " ('discussion', 'O'),\n",
       " ('”', 'O'),\n",
       " ('and', 'O'),\n",
       " ('she', 'O'),\n",
       " ('had', 'O'),\n",
       " ('already', 'O'),\n",
       " ('“', 'O'),\n",
       " ('taken', 'O'),\n",
       " ('care', 'O'),\n",
       " ('of', 'O'),\n",
       " ('it', 'O'),\n",
       " (',', 'O'),\n",
       " ('”', 'O'),\n",
       " ('according', 'O'),\n",
       " ('to', 'O'),\n",
       " ('a', 'O'),\n",
       " ('source', 'O'),\n",
       " ('quoted', 'O'),\n",
       " ('by', 'O'),\n",
       " ('The', 'O'),\n",
       " ('New', 'O'),\n",
       " ('Yorker', 'O'),\n",
       " ('.$$$$$$', 'O'),\n",
       " ('Nevertheless', 'O'),\n",
       " (',', 'O'),\n",
       " ('Senator', 'O'),\n",
       " ('Feinstein', 'O'),\n",
       " ('evidently', 'O'),\n",
       " ('bowed', 'O'),\n",
       " ('to', 'O'),\n",
       " ('pressure', 'O'),\n",
       " ('from', 'O'),\n",
       " ('her', 'O'),\n",
       " ('leftist', '9'),\n",
       " ('colleagues', '9'),\n",
       " ('to', 'O'),\n",
       " ('find', 'O'),\n",
       " ('a', 'O'),\n",
       " ('way', 'O'),\n",
       " ('to', 'O'),\n",
       " ('insert', 'O'),\n",
       " ('the', 'O'),\n",
       " ('allegation', 'O'),\n",
       " ('into', 'O'),\n",
       " ('the', 'O'),\n",
       " ('cesspool', '8'),\n",
       " ('of', '8'),\n",
       " ('public', '8'),\n",
       " ('gossip', '8'),\n",
       " ('at', 'O'),\n",
       " ('the', 'O'),\n",
       " ('eleventh', 'O'),\n",
       " ('hour', 'O'),\n",
       " ('.$$$$$$', 'O'),\n",
       " ('The', 'O'),\n",
       " ('New', 'O'),\n",
       " ('Yorker', 'O'),\n",
       " ('article', 'O'),\n",
       " (',', 'O'),\n",
       " ('written', 'O'),\n",
       " ('before', 'O'),\n",
       " ('Ms.', 'O'),\n",
       " ('Ford', 'O'),\n",
       " ('publicly', 'O'),\n",
       " ('identified', 'O'),\n",
       " ('herself', 'O'),\n",
       " (',', 'O'),\n",
       " ('provided', 'O'),\n",
       " ('some', 'O'),\n",
       " ('details', 'O'),\n",
       " ('regarding', 'O'),\n",
       " ('her', 'O'),\n",
       " ('allegation', 'O'),\n",
       " ('.$$$$$$', 'O'),\n",
       " ('However', 'O'),\n",
       " (',', 'O'),\n",
       " ('now', 'O'),\n",
       " ('Ms.', 'O'),\n",
       " ('Ford', 'O'),\n",
       " ('has', 'O'),\n",
       " ('decided', 'O'),\n",
       " ('to', 'O'),\n",
       " ('do', 'O'),\n",
       " ('what', 'O'),\n",
       " ('she', 'O'),\n",
       " ('called', 'O'),\n",
       " ('her', 'O'),\n",
       " ('“', 'O'),\n",
       " ('civic', 'O'),\n",
       " ('responsibility', 'O'),\n",
       " ('”', 'O'),\n",
       " ('and', 'O'),\n",
       " ('tell', 'O'),\n",
       " ('her', 'O'),\n",
       " ('own', 'O'),\n",
       " ('story', 'O'),\n",
       " ('publicly', 'O'),\n",
       " ('.$$$$$$', 'O'),\n",
       " ('How', '8'),\n",
       " ('convenient', '8'),\n",
       " ('coming', 'O'),\n",
       " ('just', 'O'),\n",
       " ('4', 'O'),\n",
       " ('days', 'O'),\n",
       " ('before', 'O'),\n",
       " ('the', 'O'),\n",
       " ('scheduled', 'O'),\n",
       " ('Senate', 'O'),\n",
       " ('Judiciary', 'O'),\n",
       " ('Committee', 'O'),\n",
       " ('vote', 'O'),\n",
       " ('!$$$$$$', 'O'),\n",
       " ('The', 'O'),\n",
       " ('whole', 'O'),\n",
       " ('sequence', 'O'),\n",
       " ('of', 'O'),\n",
       " ('events', 'O'),\n",
       " ('surrounding', 'O'),\n",
       " ('how', 'O'),\n",
       " ('this', 'O'),\n",
       " ('allegation', 'O'),\n",
       " ('has', 'O'),\n",
       " ('suddenly', 'O'),\n",
       " ('come', 'O'),\n",
       " ('to', 'O'),\n",
       " ('light', 'O'),\n",
       " ('reeks', '8'),\n",
       " ('of', 'O'),\n",
       " ('a', 'O'),\n",
       " ('set', 'O'),\n",
       " ('-', 'O'),\n",
       " ('up', 'O'),\n",
       " (',', 'O'),\n",
       " ('reminiscent', 'O'),\n",
       " ('of', 'O'),\n",
       " ('how', 'O'),\n",
       " ('Anita', 'O'),\n",
       " ('Hill', 'O'),\n",
       " ('surfaced', 'O'),\n",
       " ('in', 'O'),\n",
       " ('a', 'O'),\n",
       " ('last', 'O'),\n",
       " ('-', 'O'),\n",
       " ('minute', 'O'),\n",
       " ('attempt', 'O'),\n",
       " ('to', 'O'),\n",
       " ('derail', 'O'),\n",
       " ('Justice', 'O'),\n",
       " ('Clarence', 'O'),\n",
       " ('Thomas', 'O'),\n",
       " (\"'s\", 'O'),\n",
       " ('Supreme', 'O'),\n",
       " ('Court', 'O'),\n",
       " ('confirmation', 'O'),\n",
       " ('.$$$$$$', 'O'),\n",
       " ('Christine', 'O'),\n",
       " ('Blasey', 'O'),\n",
       " ('Ford', 'O'),\n",
       " ('claims', 'O'),\n",
       " (',', 'O'),\n",
       " ('according', 'O'),\n",
       " ('to', 'O'),\n",
       " ('the', 'O'),\n",
       " ('Washington', 'O'),\n",
       " ('Post', 'O'),\n",
       " ('article', 'O'),\n",
       " (',', 'O'),\n",
       " ('that', 'O'),\n",
       " ('“', 'O'),\n",
       " ('one', 'O'),\n",
       " ('summer', 'O'),\n",
       " ('in', 'O'),\n",
       " ('the', 'O'),\n",
       " ('early', 'O'),\n",
       " ('1980s', 'O'),\n",
       " (',', 'O'),\n",
       " ('Kavanaugh', 'O'),\n",
       " ('and', 'O'),\n",
       " ('a', 'O'),\n",
       " ('friend', 'O'),\n",
       " ('—', 'O'),\n",
       " ('both', 'O'),\n",
       " ('stumbling', '8'),\n",
       " ('drunk', '8'),\n",
       " (',', 'O'),\n",
       " ('’', 'O'),\n",
       " ('Ford', 'O'),\n",
       " ('alleges', 'O'),\n",
       " ('—', 'O'),\n",
       " ('corralled', 'O'),\n",
       " ('her', 'O'),\n",
       " ('into', 'O'),\n",
       " ('a', 'O'),\n",
       " ('bedroom', 'O'),\n",
       " ('during', 'O'),\n",
       " ('a', 'O'),\n",
       " ('gathering', 'O'),\n",
       " ('of', 'O'),\n",
       " ('teenagers', 'O'),\n",
       " ('at', 'O'),\n",
       " ('a', 'O'),\n",
       " ('house', 'O'),\n",
       " ('in', 'O'),\n",
       " ('Montgomery', 'O'),\n",
       " ('County', 'O'),\n",
       " ('.$$$$$$', 'O'),\n",
       " ('While', 'O'),\n",
       " ('his', 'O'),\n",
       " ('friend', 'O'),\n",
       " ('watched', 'O'),\n",
       " (',', 'O'),\n",
       " ('she', 'O'),\n",
       " ('said', 'O'),\n",
       " (',', 'O'),\n",
       " ('Kavanaugh', 'O'),\n",
       " ('pinned', 'O'),\n",
       " ('her', 'O'),\n",
       " ('to', 'O'),\n",
       " ('a', 'O'),\n",
       " ('bed', 'O'),\n",
       " ('on', 'O'),\n",
       " ('her', 'O'),\n",
       " ('back', 'O'),\n",
       " ('and', 'O'),\n",
       " ('groped', 'O'),\n",
       " ('her', 'O'),\n",
       " ('over', 'O'),\n",
       " ('her', 'O'),\n",
       " ('clothes', 'O'),\n",
       " (',', 'O'),\n",
       " ('grinding', 'O'),\n",
       " ('his', 'O'),\n",
       " ('body', 'O'),\n",
       " ('against', 'O'),\n",
       " ('hers', 'O'),\n",
       " ('and', 'O'),\n",
       " ('clumsily', 'O'),\n",
       " ('attempting', 'O'),\n",
       " ('to', 'O'),\n",
       " ('pull', 'O'),\n",
       " ('off', 'O'),\n",
       " ('her', 'O'),\n",
       " ('one', 'O'),\n",
       " ('-', 'O'),\n",
       " ('piece', 'O'),\n",
       " ('bathing', 'O'),\n",
       " ('suit', 'O'),\n",
       " ('and', 'O'),\n",
       " ('the', 'O'),\n",
       " ('clothing', 'O'),\n",
       " ('she', 'O'),\n",
       " ('wore', 'O'),\n",
       " ('over', 'O'),\n",
       " ('it', 'O'),\n",
       " ('.$$$$$$', 'O'),\n",
       " ('When', 'O'),\n",
       " ('she', 'O'),\n",
       " ('tried', 'O'),\n",
       " ('to', 'O'),\n",
       " ('scream', 'O'),\n",
       " (',', 'O'),\n",
       " ('she', 'O'),\n",
       " ('said', 'O'),\n",
       " (',', 'O'),\n",
       " ('he', 'O'),\n",
       " ('put', 'O'),\n",
       " ('his', 'O'),\n",
       " ('hand', 'O'),\n",
       " ('over', 'O'),\n",
       " ('her', 'O'),\n",
       " ('mouth', 'O'),\n",
       " ('.', 'O'),\n",
       " ('‘$$$$$$', 'O'),\n",
       " ('I', 'O'),\n",
       " ('thought', 'O'),\n",
       " ('he', 'O'),\n",
       " ('might', 'O'),\n",
       " ('inadvertently', 'O'),\n",
       " ('kill', 'O'),\n",
       " ('me', 'O'),\n",
       " (',', 'O'),\n",
       " ('’', 'O'),\n",
       " ('said', 'O'),\n",
       " ('Ford', 'O'),\n",
       " ('.', 'O'),\n",
       " ('‘$$$$$$', 'O'),\n",
       " ('He', 'O'),\n",
       " ('was', 'O'),\n",
       " ('trying', 'O'),\n",
       " ('to', 'O'),\n",
       " ('attack', 'O'),\n",
       " ('me', 'O'),\n",
       " ('and', 'O'),\n",
       " ('remove', 'O'),\n",
       " ('my', 'O'),\n",
       " ('clothing', 'O'),\n",
       " ('.', 'O'),\n",
       " ('’', 'O'),\n",
       " ('”$$$$$$', 'O'),\n",
       " ('Ms.', 'O'),\n",
       " ('Ford', 'O'),\n",
       " ('said', 'O'),\n",
       " ('she', 'O'),\n",
       " ('was', 'O'),\n",
       " ('able', 'O'),\n",
       " ('to', 'O'),\n",
       " ('escape', 'O'),\n",
       " ('the', 'O'),\n",
       " ('room', 'O'),\n",
       " ('and', 'O'),\n",
       " ('go', 'O'),\n",
       " ('home', 'O'),\n",
       " ('without', 'O'),\n",
       " ('any', 'O'),\n",
       " ('apparent', 'O'),\n",
       " ('further', 'O'),\n",
       " ('incident', 'O'),\n",
       " ('after', 'O'),\n",
       " ('“', 'O'),\n",
       " ('Kavanaugh', 'O'),\n",
       " ('’s', 'O'),\n",
       " ('friend', 'O'),\n",
       " ('and', 'O'),\n",
       " ('classmate', 'O'),\n",
       " ('at', 'O'),\n",
       " ('Georgetown', 'O'),\n",
       " ('Preparatory', 'O'),\n",
       " ('School', 'O'),\n",
       " (',', 'O'),\n",
       " ('Mark', 'O'),\n",
       " ('Judge', 'O'),\n",
       " (',', 'O'),\n",
       " ('jumped', 'O'),\n",
       " ('on', 'O'),\n",
       " ('top', 'O'),\n",
       " ('of', 'O'),\n",
       " ('them', 'O'),\n",
       " (',', 'O'),\n",
       " ('sending', 'O'),\n",
       " ('all', 'O'),\n",
       " ('three', 'O'),\n",
       " ('tumbling', 'O'),\n",
       " ('.', 'O'),\n",
       " ('”$$$$$$', 'O'),\n",
       " ('Here', 'O'),\n",
       " ('is', 'O'),\n",
       " ('where', 'O'),\n",
       " ('Ms.', 'O'),\n",
       " ('Ford', 'O'),\n",
       " ('’s', 'O'),\n",
       " ('story', 'O'),\n",
       " ('becomes', 'O'),\n",
       " ('quite', 'O'),\n",
       " ('murky', 'O'),\n",
       " ('and', 'O'),\n",
       " ('begins', 'O'),\n",
       " ('to', 'O'),\n",
       " ('fall', 'O'),\n",
       " ('apart', 'O'),\n",
       " ('.$$$$$$', 'O'),\n",
       " ('Although', 'O'),\n",
       " ('Ms.', 'O'),\n",
       " ('Ford', 'O'),\n",
       " ('believes', 'O'),\n",
       " ('the', 'O'),\n",
       " ('alleged', 'O'),\n",
       " ('incident', 'O'),\n",
       " ('occurred', 'O'),\n",
       " ('during', 'O'),\n",
       " ('the', 'O'),\n",
       " ('summer', 'O'),\n",
       " ('of', 'O'),\n",
       " ('1982', 'O'),\n",
       " (',', 'O'),\n",
       " ('she', 'O'),\n",
       " ('“', 'O'),\n",
       " ('said', 'O'),\n",
       " ('she', 'O'),\n",
       " ('does', 'O'),\n",
       " ('not', 'O'),\n",
       " ('remember', 'O'),\n",
       " ('some', 'O'),\n",
       " ('key', 'O'),\n",
       " ('details', 'O'),\n",
       " ('of', 'O'),\n",
       " ('the', 'O'),\n",
       " ('incident', 'O'),\n",
       " (',', 'O'),\n",
       " ('”', 'O'),\n",
       " ('according', 'O'),\n",
       " ('to', 'O'),\n",
       " ('the', 'O'),\n",
       " ('Washington', 'O'),\n",
       " ('Post', 'O'),\n",
       " ('article', 'O'),\n",
       " ('.$$$$$$', 'O'),\n",
       " ('For', 'O'),\n",
       " ('example', 'O'),\n",
       " (',', 'O'),\n",
       " ('Ms.', 'O'),\n",
       " ('Ford', 'O'),\n",
       " ('“', 'O'),\n",
       " ('said', 'O'),\n",
       " ('she', 'O'),\n",
       " ('does', 'O'),\n",
       " ('not', 'O'),\n",
       " ('remember', 'O'),\n",
       " ('how', 'O'),\n",
       " ('the', 'O'),\n",
       " ('gathering', 'O'),\n",
       " ('came', 'O'),\n",
       " ('together', 'O'),\n",
       " ('the', 'O'),\n",
       " ('night', 'O'),\n",
       " ('of', 'O'),\n",
       " ('the', 'O'),\n",
       " ('incident', 'O'),\n",
       " ('.', 'O'),\n",
       " ('”$$$$$$', 'O'),\n",
       " ('She', 'O'),\n",
       " ('also', 'O'),\n",
       " ('does', 'O'),\n",
       " ('not', 'O'),\n",
       " ('remember', 'O'),\n",
       " ('how', 'O'),\n",
       " ('she', 'O'),\n",
       " ('got', 'O'),\n",
       " ('home', 'O'),\n",
       " ('.$$$$$$', 'O'),\n",
       " ('Yet', 'O'),\n",
       " ('she', 'O'),\n",
       " ('claims', 'O'),\n",
       " ('to', 'O'),\n",
       " ('be', 'O'),\n",
       " ('absolutely', 'O'),\n",
       " ('certain', 'O'),\n",
       " ('that', 'O'),\n",
       " ('Kavanaugh', 'O'),\n",
       " (',', 'O'),\n",
       " ('whom', 'O'),\n",
       " ('she', 'O'),\n",
       " ('presumably', 'O'),\n",
       " ('knew', 'O'),\n",
       " ('only', 'O'),\n",
       " ('as', 'O'),\n",
       " ('an', 'O'),\n",
       " ('acquaintance', 'O'),\n",
       " ('and', 'O'),\n",
       " ('said', 'O'),\n",
       " ('she', 'O'),\n",
       " ('had', 'O'),\n",
       " ('not', 'O'),\n",
       " ('spoken', 'O'),\n",
       " ('to', 'O'),\n",
       " ('since', 'O'),\n",
       " ('the', 'O'),\n",
       " ('night', 'O'),\n",
       " ('the', 'O'),\n",
       " ('incident', 'O'),\n",
       " ('allegedly', 'O'),\n",
       " ('occurred', 'O'),\n",
       " (',', 'O'),\n",
       " ('was', 'O'),\n",
       " ('involved', 'O'),\n",
       " ('in', 'O'),\n",
       " ('the', 'O'),\n",
       " ('alleged', 'O'),\n",
       " ('incident', 'O'),\n",
       " ('.$$$$$$', 'O'),\n",
       " ('Ms.', 'O'),\n",
       " ('Ford', 'O'),\n",
       " ('admitted', 'O'),\n",
       " ('that', 'O'),\n",
       " ('she', 'O'),\n",
       " ('“', 'O'),\n",
       " ('told', 'O'),\n",
       " ('no', 'O'),\n",
       " ('one', 'O'),\n",
       " ('at', 'O'),\n",
       " ('the', 'O'),\n",
       " ('time', 'O'),\n",
       " ('what', 'O'),\n",
       " ('had', 'O'),\n",
       " ('happened', 'O'),\n",
       " ('to', 'O'),\n",
       " ('her', 'O'),\n",
       " ('.', 'O'),\n",
       " ('”$$$$$$', 'O'),\n",
       " ('In', 'O'),\n",
       " ('fact', 'O'),\n",
       " (',', 'O'),\n",
       " ('she', 'O'),\n",
       " ('said', 'O'),\n",
       " ('she', 'O'),\n",
       " ('recalled', 'O'),\n",
       " ('thinking', 'O'),\n",
       " (':', 'O'),\n",
       " ('“', 'O'),\n",
       " ('I', 'O'),\n",
       " ('’m', 'O'),\n",
       " ('not', 'O'),\n",
       " ('ever', 'O'),\n",
       " ('telling', 'O'),\n",
       " ('anyone', 'O'),\n",
       " ('this', 'O'),\n",
       " ('.$$$$$$', 'O'),\n",
       " ('This', 'O'),\n",
       " ('is', 'O'),\n",
       " ('nothing', 'O'),\n",
       " (',', 'O'),\n",
       " ('it', 'O'),\n",
       " ('did', 'O'),\n",
       " ('n’t', 'O'),\n",
       " ('happen', 'O'),\n",
       " (',', 'O'),\n",
       " ('and', 'O'),\n",
       " ('he', 'O'),\n",
       " ('did', 'O'),\n",
       " ('n’t', 'O'),\n",
       " ('rape', 'O'),\n",
       " ('me', 'O'),\n",
       " ('.', 'O'),\n",
       " ('”$$$$$$', 'O'),\n",
       " ('Even', 'O'),\n",
       " ('if', 'O'),\n",
       " ('one', 'O'),\n",
       " ('explains', 'O'),\n",
       " ('this', 'O'),\n",
       " ('behavior', 'O'),\n",
       " ('as', 'O'),\n",
       " ('the', 'O'),\n",
       " ('natural', 'O'),\n",
       " ('reaction', 'O'),\n",
       " ('of', 'O'),\n",
       " ('a', 'O'),\n",
       " ('frightened', 'O'),\n",
       " ('teenager', 'O'),\n",
       " ('to', 'O'),\n",
       " ('a', 'O'),\n",
       " ('highly', 'O'),\n",
       " ('traumatic', 'O'),\n",
       " ('incident', 'O'),\n",
       " (',', 'O'),\n",
       " ('that', 'O'),\n",
       " ('does', 'O'),\n",
       " ('not', 'O'),\n",
       " ('explain', 'O'),\n",
       " ('why', 'O'),\n",
       " (',', 'O'),\n",
       " ('by', 'O'),\n",
       " ('her', 'O'),\n",
       " ('own', 'O'),\n",
       " ('admission', 'O'),\n",
       " (',', 'O'),\n",
       " ('she', 'O'),\n",
       " ('“', 'O'),\n",
       " ('told', 'O'),\n",
       " ('no', 'O'),\n",
       " ('one', 'O'),\n",
       " ('of', 'O'),\n",
       " ('the', 'O'),\n",
       " ('incident', 'O'),\n",
       " ('in', 'O'),\n",
       " ('any', 'O'),\n",
       " ('detail', 'O'),\n",
       " ('until', 'O'),\n",
       " ('2012', 'O'),\n",
       " (',', 'O'),\n",
       " ('when', 'O'),\n",
       " ('she', 'O'),\n",
       " ('was', 'O'),\n",
       " ('in', 'O'),\n",
       " ('couples', 'O'),\n",
       " ('therapy', 'O'),\n",
       " ('with', 'O'),\n",
       " ('her', 'O'),\n",
       " ('husband', 'O'),\n",
       " (',', 'O'),\n",
       " ('”', 'O'),\n",
       " ('according', 'O'),\n",
       " ('to', 'O'),\n",
       " ('the', 'O'),\n",
       " ('Washington', 'O'),\n",
       " ('Post', 'O'),\n",
       " ('article', 'O'),\n",
       " ('.$$$$$$', 'O'),\n",
       " ('Most', 'O'),\n",
       " ('revealingly', 'O'),\n",
       " (',', 'O'),\n",
       " ('the', 'O'),\n",
       " ('article', 'O'),\n",
       " ('reported', 'O'),\n",
       " ('on', 'O'),\n",
       " ('a', 'O'),\n",
       " ('gaping', '8'),\n",
       " ('hole', '8'),\n",
       " ('in', '8'),\n",
       " ('the', '8'),\n",
       " ('therapist', '8'),\n",
       " ('’s', '8'),\n",
       " ('notes', '8'),\n",
       " ('portions', 'O'),\n",
       " ('of', 'O'),\n",
       " ('which', 'O'),\n",
       " ('were', 'O'),\n",
       " ('provided', 'O'),\n",
       " ('by', 'O'),\n",
       " ('Ms.', 'O'),\n",
       " ('Ford', 'O'),\n",
       " ('for', 'O'),\n",
       " ('the', 'O'),\n",
       " ('Washington', 'O'),\n",
       " ('Post', 'O'),\n",
       " ('’s', 'O'),\n",
       " ...]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_df[\"tagged_sequence_with_propaganda_types\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def propaganda_type_seq_to_simple_yes_or_no_seq(taggings):\n",
    "    simple_taggings = []\n",
    "    for i in taggings:\n",
    "        if i[1] != \"O\":\n",
    "            simple_taggings.append((i[0],\"I\"))\n",
    "        else:\n",
    "            simple_taggings.append(i)\n",
    "    return simple_taggings        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def propaganda_type_seq_to_simple_yes_or_no_seq_bio(taggings):\n",
    "    simple_taggings = []\n",
    "    for ix,i in enumerate(taggings):\n",
    "        if i[1] != \"O\" and taggings[ix-1][1] == \"O\" and ix > 1:\n",
    "            simple_taggings.append((i[0],\"B-I\"))\n",
    "        elif i[1] != \"O\":    \n",
    "            simple_taggings.append((i[0],\"I\"))\n",
    "        else:\n",
    "            simple_taggings.append(i)\n",
    "    return simple_taggings        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d729542e3624fc0b6535b57b9575d85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=371, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "content_df[\"tagged_sequence\"] = content_df.tagged_sequence_with_propaganda_types.swifter.apply(propaganda_type_seq_to_simple_yes_or_no_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in zip(content_df.iloc[1][\"tagged_sequence_with_propaganda_types\"],content_df.iloc[1][\"tagged_sequence\"]):\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train_df , test_df =  train_test_split(content_df,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "last_article = content_df[\"content\"][254]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Keith Ellison Defends Louis Farrakhan: \"He Had Something To Offer\"  Rep. Keith Ellison (D-MN), aka Hakim Muhammad, recently defended his ties to Nation of Islam leader Louis Farrakhan, who recently <span-8 paralleled Jews with termites 8-/span>. During a debate with Republican opponent Doug Wardlow, Ellison was asked about his previous support of Farrakhan, but then claims that he has distanced himself from Farrakhan. <span-8 Yeah, right, Hakim 8-/span>! Understand that Ellison attempts to tell the audience and his opponent that he has distanced himself from Farrakhan since the 1990s. Take a look at his comments. take our poll - story continues below Should military force be used to stop the caravan of migrants marching toward the U.S. border? Should military force be used to stop the caravan of migrants marching toward the U.S. border? Should military force be used to stop the caravan of migrants marching toward the U.S. border? * Yes, military force should be used. No, keep the military out of it. Email * Email This field is for validation purposes and should be left unchanged. Completing this poll grants you access to Freedom Outpost updates free of charge. You may opt out at anytime. You also agree to this site\\'s Privacy Policy and Terms of Use. “<span-6 I <span-8 absolutely, unqualifiedly denounce and reject 8-/span>the views of Louis Farrakhan 6-/span>,\" said Ellison. \"I’ve said that many, many years ago.” “Look, in the early 1990s, Louis Farrakhan was a person speaking the issues of African-American civil rights,\" Ellison added. \"At that time, he had some things, I thought, he had to offer.\" Ellison then concluded, \"He made it very clear in the early 90s that <span-6 his views and mine were absolutely incompatible 6-/span>, and I’ve been saying that ever since.” Keith, you\\'re lying. It\\'s clear from video evidence that Ellison and fellow Democrat Gregory Meeks had dinner with Farrakhan and Iranian leader President Hassan Rouhani in 2013. Take a look for yourself and understand how pathological liar and accused woman abuser Keith Ellison seeks to deceive you. In case you missed it, <span-2 here\\'s a still frame of Ellison just a few feet away from a man who has called on 10,000 blacks to stalk and murder white people 2-/span>. Both of these men have the same devil as their father because both men are following after the teaching of the Koran . One of them just actually has the nerve to say it. The other doesn\\'t. Maybe Ellison is attempting <span-8 to pull an Obama 8-/span>. Remember when Obama\\'s \"pastor,\" Jeremiah Wright uttered \"God damn, America!\"? Obama tried to say he had been in that church for years and never heard such things, which isn\\'t true. <span-2 Ellison is attempting to do that same. 2-/span> However, as Michael Ahrens of GOP.com tweeted, Ellison knew what kind of man Farrakhan was then and what kind of man he still is today. Ahrens tweeted, “In 1993, Farrakhan told women: “<span-3 You’re a failure if you can’t keep a man 3-/span>.” In 1994, Farrakhan said: “<span-6 Murder and lying comes easy for white people 6-/span>.” All this came *before* Ellison <span-8 praised him  8-/span>as “a role model” in 1995, and was photographed selling Farrakhan’s newspaper in 1998.” In 1993, Farrakhan told women: \"<span-10 <span-3 You\\'re a failure if you can\\'t keep a man10-/span> 3-/span>.\" In 1994, Farrakhan said: \"<span-10 <span-6 Murder and lying comes easy for white people10-/span> 6-/span>.\" All this came *before* Ellison <span-8 praised him  8-/span>as \"a role model\" in 1995, and was photographed selling Farrakhan\\'s newspaper in 1998. pic.twitter.com/5dvnDHTSoB — Michael Ahrens (@michael_ahrens) October 22, 2018 Ellison is a totalitarian-minded individual, who has been supported by Communists and Islamists alike. As the old saying goes, \"<span-3 <span-8 <span-1 If you like down with dogs, you\\'re going to get fleas3-/span>8-/span> 1-/span>.\" Consider Keith Ellison to be a flea-infested political con man. '"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get_propaganda_sequence(last_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train_tag_array = train_df.tagged_sequence.values.tolist()\n",
    "test_tag_array = test_df.tagged_sequence.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# final_string = \"\"\n",
    "# for i in train_tag_array:\n",
    "#     for k in i:\n",
    "#         final_string = final_string + k[0] + \" \" + k[1] + \"\\n\"\n",
    "#     final_string = final_string + \"\\n\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# with open('train_task.txt','w') as f:\n",
    "#     f.write(final_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test_final_string = \"\"\n",
    "# for i in test_tag_array:\n",
    "#     for k in i:\n",
    "#         test_final_string = final_string + k[0] + \" \" + k[1] + \"\\n\"\n",
    "#     test_final_string = final_string + \"\\n\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# with open('dev_task.txt','w') as f:\n",
    "#     f.write(test_final_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# train_df[\"article_length\"] = train_df.content.swifter.apply(lambda x:len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# max(train_df.article_length.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_string = \"\"\n",
    "count = len(train_tag_array)\n",
    "for i in train_tag_array:\n",
    "    final_string += \"SOA O\\nSOS O\\n\"\n",
    "    for k in i:\n",
    "        final_string = final_string + k[0].replace(\"$$$$$$\",\"\") + \" \" + k[1] + \"\\n\"\n",
    "        if \"$$$$$$\" in k[0]:\n",
    "            final_string = final_string + \"EOS O\\n\\nSOS O\\n\"\n",
    "    final_string += \"EOA O\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "with open('train_task.txt','w') as f:\n",
    "    f.write(final_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_final_string = \"\"\n",
    "for i in test_tag_array:\n",
    "    test_final_string += \"SOA O\\nSOS O\\n\"\n",
    "    for k in i:\n",
    "        test_final_string = test_final_string + k[0].replace(\"$$$$$$\",\"\") + \" \" + k[1] + \"\\n\"\n",
    "        if \"$$$$$$\" in k[0]:\n",
    "            test_final_string = test_final_string + \"EOS O\\n\\nSOS O\\n\"\n",
    "    test_final_string += \"EOA O\\n\\n\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "with open('dev_task.txt','w') as f:\n",
    "    f.write(test_final_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Prepare test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "dev_articles_path = \"/data/semeval-2020/task-11/datasets/dev-articles\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import swifter\n",
    "all_files = glob.glob(dev_articles_path + \"/*.txt\")\n",
    "\n",
    "dev_content_tuple = []\n",
    "\n",
    "for filename in all_files:\n",
    "    file = open(filename)\n",
    "    content = \"\".join(file.readlines()).replace(\"\\n\",\" \")\n",
    "    article_id = filename.split(\"article\")[-1].split(\".txt\")[0]\n",
    "    dev_content_tuple.append((article_id,content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('779309765',\n",
       " \"Unbelievable! Sharia New Mexico: Islamic compound jihadis RELEASED on bond after charges of “Islamophobia” and “racism” (Islam is not a race)  Editor's Note: Talk about injustice! There were remains of a 4-year-old boy found there, who allegedly died while they were performing some sort of Islamic ritual over him. The Bundys and their supporters got nearly two years in jail and no one hurt a single person! Shame on those who are supposed to uphold law and justice! Shame! Taos County Sheriff Jerry Hogrefe testified that they found children holding boxes of ammunition, and that one child was found with a gun…. Because sharia trumps dead children, school shooting training, kidnapping and jihad training. The children discovered at an “extremist Muslim” compound in New Mexico earlier this month were both trained to use firearms and taught multiple tactical techniques in order to kill teachers, law enforcement and other institution…. state prosecutors said on Monday. take our poll - story continues below Will Brett Kavanaugh be confirmed to the Supreme Court? Will Brett Kavanaugh be confirmed to the Supreme Court? Will Brett Kavanaugh be confirmed to the Supreme Court? * Yes, he will be confirmed. No, he will not be confirmed. Email * Comments This field is for validation purposes and should be left unchanged. Completing this poll grants you access to Freedom Outpost updates free of charge. You may opt out at anytime. You also agree to this site's Privacy Policy and Terms of Use. “Islamophobia” is a thought crushing device designed to silence any and critics and criticism of Islam. It is the tool in which the ummah enforces sharia blasphemy laws in the West. Waco – the Feds killed ’em all. Shot it up and burned it down. Fast forward to Islam in America — New Mexico compound jihadis released on bond after charges of racism and “Islamophobia” “THEIR LAWYER ARGUED THAT THERE WAS A DOUBLE STANDARD IN THE CASE BECAUSE HIS CLIENTS WERE MUSLIMS. HE ARGUED THAT IF THEY HAD BEEN CHRISTIAN AND WHITE, ‘WE MIGHT NOT BE HERE TODAY.’” Bu Jihad Watch, August 13, 2018: Seriously? If they had been Christian and white, stockpiling weapons and plotting school shootings, with the ringleader being the son of one of the most respected Christian preachers in the country, there wouldn’t have been news coverage of anything else for weeks. There would have been feature stories in the New York Times, the Washington Post, and the Wall Street Journal. CNN and MSNBC would be running special reports on toxic Christianity and the crisis in the churches. This incident, on the other hand, received very little coverage, and hardly any that touched on the Islamic aspects of the story. But Muslim claims of victimhood are so polished and reflexive by now, and the Leftist acceptance of them so matter-of-fact and instinctive, that Judge Sarah Backus fell right into line. We can only hope that no one dies because of her folly. “Breaking: Judge makes stunning decision in Muslim compound case after charges of racism,” by Carlos Garcia, The Blaze, August 13, 2018 (thanks to Robert): In a hearing Monday, a New Mexico judge found that suspects in a bizarre child abuse case were not a danger to the public, and released them on bond. Defense attorney blames Islamophobia Two Muslim men and three women are charged with 11 counts of child abuse each after police raided their compound in New Mexico and discovered 11 malnourished children living in squalor. Their lawyer argued that there was a double standard in the case because his clients were Muslims. He argued that if they had been Christian and white, “we might not be here today.” Despite law enforcement authorities saying that they believe that the children were being trained to attack innocents, and that the adults were radicalized, Judge Sarah Backus released the suspects. Prosecutors also said they obtained a letter from one of the suspects telling his brother to come to the compound and die like a martyr. The lawyer for the suspects said that there was no evidence that they were planning any kind of attacks. Taos County Sheriff Jerry Hogrefe testified that they found children holding boxes of ammunition, and that one child was found with a gun… Article posted with permission from Pamela Geller \")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_content_tuple[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_content_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from spacy.lang.en import English # updated\n",
    "from transformers import BertTokenizer\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
    "\n",
    "nlp = English()\n",
    "nlp.add_pipe(nlp.create_pipe('sentencizer')) # updated\n",
    "\n",
    "article_id_sentence = [(i[0],str(k)) for i in dev_content_tuple for k in nlp(i[1]).sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "dev_article_text = \"\"\n",
    "for i in dev_content_tuple:\n",
    "    dev_article_text += \"SOA\\n\"\n",
    "    for sent in nlp(i[1]).sents:\n",
    "        dev_article_text += \"SOS\\n\"\n",
    "        tokens = str(sent).split(\" \")\n",
    "#         tokens = tokenizer.tokenize(str(sent))\n",
    "        for token in tokens:\n",
    "            for tok in nlp(token):\n",
    "                dev_article_text = dev_article_text + tok.text + \"\\n\"\n",
    "        dev_article_text = dev_article_text + \"EOS\\n\\n\"\n",
    "    dev_article_text = dev_article_text + \"EOA\\n\\n\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# dev_article_text = \"\"\n",
    "# for combo in article_id_sentence:\n",
    "#     dev_article_text += \"SOA O\\n\"\n",
    "#     for token in combo[1].split(\" \"):\n",
    "#         dev_article_text = dev_article_text + token + \"\\n\"\n",
    "#     dev_article_text = dev_article_text + \"\\n\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "with open('test_task.txt',\"w\") as f:\n",
    "    f.write(dev_article_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SOA\\nSOS\\nUnbelievable\\n!\\nEOS'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_article_text.split(\"\\n\\n\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Post processing for bert transformers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "final_prediction = open(\"final_prediction.txt\").readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "article_ids = [tup[0] for tup in dev_content_tuple]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "article_prediction = []\n",
    "running_article = []\n",
    "for line in final_prediction:\n",
    "    if line.startswith(\"SOA\") and len(running_article) != 0:\n",
    "        article_prediction.append(running_article)\n",
    "        running_article = []\n",
    "    else: \n",
    "        running_article.append(line)\n",
    "article_prediction.append(running_article)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('787966255',\n",
       " \"Warrants Show Police Never Searched Amber Guyger’s Apartment, Now It’s Too Late, She’s ‘Vacated’ It  Dallas, TX — On Sunday, activists rallied around the Dallas Cowboy’s stadium to draw attention to the slaying of Botham Jean. They carried coffins and blocked traffic to expose the special treatment of Amber Guyger, the cop who has yet to even be fired for killing Jean. Now, as more details emerge, this special treatment has moved to a level that is even more insidious. Protest at AT&T Stadium pic.twitter.com/lu5VsGQByv — Allison Harris (@AllisonFox4News) September 16, 2018 take our poll - story continues below Who should replace Nikki Haley as our ambassador to the U.N.? Who should replace Nikki Haley as our ambassador to the U.N.? Who should replace Nikki Haley as our ambassador to the U.N.? * John Bolton Richard Grenell Dina Powell Heather Nauert Ivanka Trump Email * Email This field is for validation purposes and should be left unchanged. Completing this poll grants you access to Freedom Outpost updates free of charge. You may opt out at anytime. You also agree to this site's Privacy Policy and Terms of Use. From the beginning of this case, it was clear that Guyger was receiving special treatment from law enforcement. One of the most glaring instances showing her privilege was the fact that the Texas Rangers said in their report that Jean refused to obey Guyger’s “verbal commands.” Had anyone else but a cop walked into an apartment and killed an innocent man, do you believe that investigators would have said anything like this? Attorney Stephen Le Brocq, who operates a law firm in the North Texas area sums up the treatment of Guyger perfectly when he says that “The affidavit isn’t written objectively, not at the slightest. As stated before, they are usually wholly against the accused. An objective view of the information related by the officer would be proper, in my opinion. This affidavit states facts based upon the word of the person it seeks to accuse of criminal wrongdoing.” What’s more, according to WFAA, who obtained affidavits for all of the search warrants involved in the case, none of them involved the search of Guyger’s apartment. For those who don’t recall, police egregiously released the search warrant findings of Jean’s apartment on the day his family buried his dead body. They attempted to assassinate Jean’s character by claiming they found less than a half ounce of weed in his apartment. However, they failed miserably at it. One thing in particular, however, stood out to those paying attention and that is the fact the police didn’t release any information on what they found in Guyger’s apartment. According to the information currently available, that’s because they didn’t search it. According to WFAA, there were five search warrants issued in the case—none of which were for the killer’s apartment. As WFAA reports: Two of the warrants allowed investigators to remove the front door of Guyger and Jean’s apartment, their door locks and to download data for their door locks. An inventory return states that they removed both of their door lock and downloaded the data from the door locks. A third search warrant gave investigators the authority to enter Jean’s apartment and collect additional evidence. A return shows that investigators took photographs of his apartment, made videos of his apartment, conducted “laser measurements of firearm trajectory,” and collected “gunshot residue” from the door frame and kitchen wall of Jean’s apartment. A return for the fourth search warrant shows investigators seized video from the surveillance camera system in the apartment management’s office. A fifth search warrant gave investigators the authority to obtain all communications related to the incident in the possession of property management, as well as all surveillance video and all entry and access logs from 9 p.m. to 11 p.m. on the night of the shooting. An inventory return shows investigators seized a USB drive containing the video, an event log report for “linear access doors and gates,” an “elevator access door lock” report and a “lock audit report for both apartments. Now, even if police would try to search the killer cop’s apartment, it’s too late. On Sunday, apartment staff notified residents in an email that Guyger “has vacated her apartment and no longer resides at our community.” A manager at the complex declined to indicate exactly when Guyger moved out and if she left the premises voluntarily, the Dallas Morning News reports. While residents can certainly sleep better knowing that they don’t have to fear a killer cop walking into their apartment and murdering them, the family of Botham Jean likely sees this as one more instance of injustice. Mother of #BothamJean, Allison Jean, says the “smear” of her son is unacceptable. “It is time that we recognize that lives matter, my son’s life matters.” pic.twitter.com/UjyKRZ8XeG — Jack Highberger (@JackHighberger) September 14, 2018 Article posted with permission from The Free Thought Project \")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_content_tuple[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def create_equi_length_seq(line):\n",
    "    cleaned_line = line.replace(\"\\n\",\"\").split(\" \")\n",
    "    token = cleaned_line[0].strip()\n",
    "    if len(token) == 0 or token.startswith(\"SOA\") or token.startswith(\"SOS\") or token.startswith(\"EOA\") or token.startswith(\"EOS\"):\n",
    "        return (\" \",\" \")\n",
    "    token_label = cleaned_line[1].strip()\n",
    "    len_token = len(token)\n",
    "    full_token_label = []\n",
    "    for i in range(0,len_token):\n",
    "        full_token_label.append(token_label)\n",
    "    return (token,\"\".join(full_token_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('trust', 'OOOOO')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_equi_length_seq('trust O\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(' ', ' ')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_equi_length_seq(' \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "final_sequence_tups = []\n",
    "running_article = []\n",
    "for ap in article_prediction:\n",
    "    for word_tup in ap:\n",
    "        resized_tup = create_equi_length_seq(word_tup)\n",
    "        if (resized_tup[0] != \" \"):\n",
    "            running_article.append(resized_tup)\n",
    "    final_sequence_tups.append(running_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "final_prediction_seq = []\n",
    "for article_words_tup in final_sequence_tups:\n",
    "    label_seq = []\n",
    "    for word_tup in article_words_tup:\n",
    "        label_seq.append(word_tup[1])\n",
    "    final_prediction_seq.append(\" \".join(label_seq))\n",
    "    label_seq = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "article_final_sequence = list(zip(article_ids,final_prediction_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def get_spans_from_label_seq(article_id_label_seq_tup):\n",
    "    article_id = article_id_label_seq_tup[0]\n",
    "    label_sequence = article_id_label_seq_tup[1]\n",
    "    spans = []\n",
    "    current_running_start_span = None\n",
    "    is_span_running = False\n",
    "    for ix,label in enumerate(label_sequence):\n",
    "        if is_span_running:\n",
    "            if label == \"O\":\n",
    "                spans.append((current_running_start_span,ix-1))\n",
    "                current_running_start_span = None\n",
    "                is_span_running = False\n",
    "        else:\n",
    "            if label == \"I\":\n",
    "                current_running_start_span = ix\n",
    "                is_span_running = True\n",
    "    return article_id, spans            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('779309765', [(158816, 159110), (188194, 188281), (335245, 335661)])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_spans_from_label_seq(article_final_sequence[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# create_article_id_label_seqfor article_seq in article_final_sequence\n",
    "final_submission_list =  [get_spans_from_label_seq(article_tup) for article_tup in article_final_sequence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "final_submission_strings = []\n",
    "for fsl in final_submission_list:\n",
    "    article_id = fsl[0]\n",
    "    for span in fsl[1]:\n",
    "        final_submission_strings.append(str(article_id) + \"\\t\" + str(span[0]) + \"\\t\" + str(span[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "final_submission_content = \"\\n\".join(final_submission_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "final_submission_content = \"id\\tbegin_offset\\tend_offset\\n\" + final_submission_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "with open(\"final_submission.txt\",\"w\") as f:\n",
    "    f.writelines(final_submission_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "## Post processing for flair output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "final_prediction = open(\"/home/raghavan/projects/semeval2020/task11/notebooks/resources/taggers/example-ner/test.tsv\").readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "article_ids = [tup[0] for tup in dev_content_tuple]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "article_prediction = []\n",
    "running_article = []\n",
    "for line in final_prediction:\n",
    "    if line.startswith(\"SOA\") and len(running_article) != 0:\n",
    "        article_prediction.append(running_article)\n",
    "        running_article = []\n",
    "    else: \n",
    "        running_article.append(line)\n",
    "article_prediction.append(running_article)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('787966255',\n",
       " \"Warrants Show Police Never Searched Amber Guyger’s Apartment, Now It’s Too Late, She’s ‘Vacated’ It  Dallas, TX — On Sunday, activists rallied around the Dallas Cowboy’s stadium to draw attention to the slaying of Botham Jean. They carried coffins and blocked traffic to expose the special treatment of Amber Guyger, the cop who has yet to even be fired for killing Jean. Now, as more details emerge, this special treatment has moved to a level that is even more insidious. Protest at AT&T Stadium pic.twitter.com/lu5VsGQByv — Allison Harris (@AllisonFox4News) September 16, 2018 take our poll - story continues below Who should replace Nikki Haley as our ambassador to the U.N.? Who should replace Nikki Haley as our ambassador to the U.N.? Who should replace Nikki Haley as our ambassador to the U.N.? * John Bolton Richard Grenell Dina Powell Heather Nauert Ivanka Trump Email * Email This field is for validation purposes and should be left unchanged. Completing this poll grants you access to Freedom Outpost updates free of charge. You may opt out at anytime. You also agree to this site's Privacy Policy and Terms of Use. From the beginning of this case, it was clear that Guyger was receiving special treatment from law enforcement. One of the most glaring instances showing her privilege was the fact that the Texas Rangers said in their report that Jean refused to obey Guyger’s “verbal commands.” Had anyone else but a cop walked into an apartment and killed an innocent man, do you believe that investigators would have said anything like this? Attorney Stephen Le Brocq, who operates a law firm in the North Texas area sums up the treatment of Guyger perfectly when he says that “The affidavit isn’t written objectively, not at the slightest. As stated before, they are usually wholly against the accused. An objective view of the information related by the officer would be proper, in my opinion. This affidavit states facts based upon the word of the person it seeks to accuse of criminal wrongdoing.” What’s more, according to WFAA, who obtained affidavits for all of the search warrants involved in the case, none of them involved the search of Guyger’s apartment. For those who don’t recall, police egregiously released the search warrant findings of Jean’s apartment on the day his family buried his dead body. They attempted to assassinate Jean’s character by claiming they found less than a half ounce of weed in his apartment. However, they failed miserably at it. One thing in particular, however, stood out to those paying attention and that is the fact the police didn’t release any information on what they found in Guyger’s apartment. According to the information currently available, that’s because they didn’t search it. According to WFAA, there were five search warrants issued in the case—none of which were for the killer’s apartment. As WFAA reports: Two of the warrants allowed investigators to remove the front door of Guyger and Jean’s apartment, their door locks and to download data for their door locks. An inventory return states that they removed both of their door lock and downloaded the data from the door locks. A third search warrant gave investigators the authority to enter Jean’s apartment and collect additional evidence. A return shows that investigators took photographs of his apartment, made videos of his apartment, conducted “laser measurements of firearm trajectory,” and collected “gunshot residue” from the door frame and kitchen wall of Jean’s apartment. A return for the fourth search warrant shows investigators seized video from the surveillance camera system in the apartment management’s office. A fifth search warrant gave investigators the authority to obtain all communications related to the incident in the possession of property management, as well as all surveillance video and all entry and access logs from 9 p.m. to 11 p.m. on the night of the shooting. An inventory return shows investigators seized a USB drive containing the video, an event log report for “linear access doors and gates,” an “elevator access door lock” report and a “lock audit report for both apartments. Now, even if police would try to search the killer cop’s apartment, it’s too late. On Sunday, apartment staff notified residents in an email that Guyger “has vacated her apartment and no longer resides at our community.” A manager at the complex declined to indicate exactly when Guyger moved out and if she left the premises voluntarily, the Dallas Morning News reports. While residents can certainly sleep better knowing that they don’t have to fear a killer cop walking into their apartment and murdering them, the family of Botham Jean likely sees this as one more instance of injustice. Mother of #BothamJean, Allison Jean, says the “smear” of her son is unacceptable. “It is time that we recognize that lives matter, my son’s life matters.” pic.twitter.com/UjyKRZ8XeG — Jack Highberger (@JackHighberger) September 14, 2018 Article posted with permission from The Free Thought Project \")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_content_tuple[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def create_equi_length_seq(line):\n",
    "    cleaned_line = line.replace(\"\\n\",\"\").split(\" \")\n",
    "    print(cleaned_line)\n",
    "    token = cleaned_line[0].strip()\n",
    "    if len(token) == 0 or token.startswith(\"SOA\") or token.startswith(\"SOS\") or token.startswith(\"EOA\") or token.startswith(\"EOS\"):\n",
    "        return (\" \",\" \")\n",
    "    token_label = cleaned_line[2].strip()\n",
    "    len_token = len(token)\n",
    "    full_token_label = []\n",
    "    for i in range(0,len_token):\n",
    "        full_token_label.append(token_label)\n",
    "    return (token,\"\".join(full_token_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Unbelievable!', 'OOOOOOOOOOOOO')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_equi_length_seq('Unbelievable!  O 0.49536633491516113')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "final_sequence_tups = []\n",
    "running_article = []\n",
    "for ap in article_prediction:\n",
    "    for word_tup in ap:\n",
    "        resized_tup = create_equi_length_seq(word_tup)\n",
    "        if (resized_tup[0] != \" \"):\n",
    "            running_article.append(resized_tup)\n",
    "    final_sequence_tups.append(running_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "final_prediction_seq = []\n",
    "for article_words_tup in final_sequence_tups:\n",
    "    label_seq = []\n",
    "    for word_tup in article_words_tup:\n",
    "        label_seq.append(word_tup[1])\n",
    "    final_prediction_seq.append(\" \".join(label_seq))\n",
    "    label_seq = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "article_final_sequence = list(zip(article_ids,final_prediction_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def get_spans_from_label_seq(article_id_label_seq_tup):\n",
    "    article_id = article_id_label_seq_tup[0]\n",
    "    label_sequence = article_id_label_seq_tup[1]\n",
    "    spans = []\n",
    "    current_running_start_span = None\n",
    "    is_span_running = False\n",
    "    for ix,label in enumerate(label_sequence):\n",
    "        if is_span_running:\n",
    "            if label == \"O\":\n",
    "                spans.append((current_running_start_span,ix-1))\n",
    "                current_running_start_span = None\n",
    "                is_span_running = False\n",
    "        else:\n",
    "            if label == \"I\":\n",
    "                current_running_start_span = ix\n",
    "                is_span_running = True\n",
    "    return article_id, spans            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('779309765',\n",
       " [(615, 708),\n",
       "  (1500, 1602),\n",
       "  (2095, 2338),\n",
       "  (2692, 2831),\n",
       "  (2878, 2933),\n",
       "  (2936, 3025),\n",
       "  (7325, 7435),\n",
       "  (7582, 7692),\n",
       "  (7741, 7800),\n",
       "  (8070, 8167),\n",
       "  (8392, 8636),\n",
       "  (8913, 9050),\n",
       "  (9146, 9226),\n",
       "  (10223, 10294),\n",
       "  (10333, 10443),\n",
       "  (10910, 11274),\n",
       "  (11422, 11535),\n",
       "  (11550, 11617),\n",
       "  (11888, 11958),\n",
       "  (12019, 12076),\n",
       "  (12606, 12723),\n",
       "  (12867, 13308),\n",
       "  (13463, 13871),\n",
       "  (14214, 14349),\n",
       "  (14513, 14710),\n",
       "  (14866, 14928),\n",
       "  (14941, 15146),\n",
       "  (15417, 15652),\n",
       "  (17848, 18194),\n",
       "  (18220, 18271),\n",
       "  (18561, 18704),\n",
       "  (19065, 19437),\n",
       "  (20663, 20774),\n",
       "  (21357, 21465),\n",
       "  (21735, 21839),\n",
       "  (22980, 23065),\n",
       "  (23296, 23495),\n",
       "  (23517, 23622),\n",
       "  (23856, 24021),\n",
       "  (24481, 24649),\n",
       "  (24738, 24800),\n",
       "  (24832, 24950),\n",
       "  (25965, 26224),\n",
       "  (26933, 27037),\n",
       "  (27683, 27960),\n",
       "  (28153, 28307),\n",
       "  (28504, 28620),\n",
       "  (28958, 29117),\n",
       "  (29772, 29929),\n",
       "  (29985, 30237),\n",
       "  (30244, 30396),\n",
       "  (30437, 30712),\n",
       "  (30863, 30986),\n",
       "  (31039, 31305),\n",
       "  (31450, 31830),\n",
       "  (31988, 32152),\n",
       "  (32199, 32440),\n",
       "  (32573, 32875),\n",
       "  (34285, 34327),\n",
       "  (34345, 34574),\n",
       "  (36016, 36132),\n",
       "  (36357, 36384),\n",
       "  (36624, 36651),\n",
       "  (37458, 37591),\n",
       "  (39256, 39381),\n",
       "  (39532, 39616),\n",
       "  (39759, 39843),\n",
       "  (40663, 40747),\n",
       "  (40804, 40891),\n",
       "  (41305, 41443),\n",
       "  (41708, 41754),\n",
       "  (41793, 41834),\n",
       "  (41861, 41958),\n",
       "  (42127, 42425),\n",
       "  (42669, 42735),\n",
       "  (44644, 44705),\n",
       "  (44889, 44995),\n",
       "  (45188, 45307),\n",
       "  (47693, 47750),\n",
       "  (49014, 49092),\n",
       "  (49668, 49751),\n",
       "  (49765, 49873),\n",
       "  (49948, 50035),\n",
       "  (50073, 50163),\n",
       "  (50180, 50205),\n",
       "  (50331, 50401),\n",
       "  (50463, 50618),\n",
       "  (50684, 50767),\n",
       "  (51166, 51247),\n",
       "  (56669, 56718),\n",
       "  (56820, 56916),\n",
       "  (57036, 57137),\n",
       "  (57594, 57739),\n",
       "  (58981, 59274),\n",
       "  (59405, 59490),\n",
       "  (60029, 60090),\n",
       "  (60342, 60420),\n",
       "  (62157, 62367),\n",
       "  (62376, 62439),\n",
       "  (62474, 62567),\n",
       "  (62663, 62746),\n",
       "  (64746, 64896),\n",
       "  (65022, 65125),\n",
       "  (72231, 72414),\n",
       "  (72706, 72802),\n",
       "  (72813, 72997),\n",
       "  (73544, 73890),\n",
       "  (74103, 74374),\n",
       "  (75208, 75387),\n",
       "  (75394, 75535),\n",
       "  (75619, 75699),\n",
       "  (76195, 76321),\n",
       "  (76862, 77116),\n",
       "  (77364, 77870),\n",
       "  (77930, 77993),\n",
       "  (78013, 78173),\n",
       "  (78513, 79055),\n",
       "  (79124, 79217),\n",
       "  (79476, 79623),\n",
       "  (80012, 80277),\n",
       "  (80612, 80957),\n",
       "  (80998, 81263),\n",
       "  (81350, 81948),\n",
       "  (82021, 82218),\n",
       "  (82388, 82638),\n",
       "  (82782, 83218),\n",
       "  (83292, 83538),\n",
       "  (89122, 89213),\n",
       "  (89964, 90160),\n",
       "  (90337, 90503),\n",
       "  (91287, 91314),\n",
       "  (92530, 92581),\n",
       "  (92597, 92689),\n",
       "  (93203, 93289),\n",
       "  (93316, 93426),\n",
       "  (94611, 94849),\n",
       "  (94922, 95167),\n",
       "  (95999, 96284),\n",
       "  (96303, 96499),\n",
       "  (96571, 96842),\n",
       "  (97097, 97418),\n",
       "  (98761, 98886),\n",
       "  (99062, 99265),\n",
       "  (99509, 99775),\n",
       "  (99913, 100017),\n",
       "  (100135, 100518),\n",
       "  (101068, 101107),\n",
       "  (101506, 101604),\n",
       "  (102086, 102270),\n",
       "  (102870, 103048),\n",
       "  (104080, 104237),\n",
       "  (104698, 104835),\n",
       "  (105001, 105820),\n",
       "  (106037, 106357),\n",
       "  (106417, 106550),\n",
       "  (106993, 107189),\n",
       "  (107532, 107939),\n",
       "  (107993, 108176),\n",
       "  (108212, 108387),\n",
       "  (108667, 108954),\n",
       "  (109098, 109192),\n",
       "  (109234, 109522),\n",
       "  (109598, 109891),\n",
       "  (109905, 110203),\n",
       "  (110243, 110338),\n",
       "  (110459, 110656),\n",
       "  (110710, 111280),\n",
       "  (111616, 111704),\n",
       "  (111761, 111895),\n",
       "  (111900, 112039),\n",
       "  (115026, 115173),\n",
       "  (117434, 117616),\n",
       "  (118046, 118160),\n",
       "  (118845, 119018),\n",
       "  (119103, 119139),\n",
       "  (119682, 119926),\n",
       "  (120040, 120102),\n",
       "  (121357, 121544),\n",
       "  (123488, 123800),\n",
       "  (123806, 123903),\n",
       "  (123936, 124024),\n",
       "  (124823, 124929),\n",
       "  (125131, 125280),\n",
       "  (125404, 125452),\n",
       "  (125772, 125880),\n",
       "  (126167, 126340),\n",
       "  (126698, 126863),\n",
       "  (126952, 127079),\n",
       "  (127154, 127181),\n",
       "  (127656, 127716),\n",
       "  (128771, 128838),\n",
       "  (128874, 128941),\n",
       "  (129407, 129563),\n",
       "  (129581, 129780),\n",
       "  (129811, 130023),\n",
       "  (130026, 130278),\n",
       "  (130339, 130478),\n",
       "  (131243, 131390),\n",
       "  (131433, 131543),\n",
       "  (131645, 131865),\n",
       "  (131884, 132092),\n",
       "  (132168, 132308),\n",
       "  (132317, 132502),\n",
       "  (132586, 132729),\n",
       "  (133317, 134009),\n",
       "  (134194, 134349),\n",
       "  (136418, 136558),\n",
       "  (138139, 138187),\n",
       "  (138349, 138427),\n",
       "  (139106, 139234),\n",
       "  (141566, 141687),\n",
       "  (142893, 142927),\n",
       "  (142998, 143152),\n",
       "  (143651, 143769),\n",
       "  (144085, 144285),\n",
       "  (144573, 144694),\n",
       "  (144778, 144988),\n",
       "  (145650, 145736),\n",
       "  (146285, 146376),\n",
       "  (146444, 146545),\n",
       "  (146720, 146851),\n",
       "  (146924, 147103),\n",
       "  (147260, 147456),\n",
       "  (147687, 147788),\n",
       "  (147864, 148128),\n",
       "  (148144, 148244),\n",
       "  (148521, 148866),\n",
       "  (151073, 151105),\n",
       "  (151558, 151657),\n",
       "  (152662, 152868),\n",
       "  (152871, 152950),\n",
       "  (152956, 153114),\n",
       "  (153205, 153324),\n",
       "  (153525, 153718),\n",
       "  (153981, 154191),\n",
       "  (154289, 154482),\n",
       "  (154696, 155064),\n",
       "  (155582, 155708),\n",
       "  (155950, 156199),\n",
       "  (156347, 156409),\n",
       "  (156545, 156779),\n",
       "  (157018, 157148),\n",
       "  (162377, 162492),\n",
       "  (163229, 163331),\n",
       "  (165861, 165913),\n",
       "  (166505, 166599),\n",
       "  (167697, 167781),\n",
       "  (168644, 168899),\n",
       "  (170792, 170879),\n",
       "  (170940, 171042),\n",
       "  (171045, 171171),\n",
       "  (171249, 171311),\n",
       "  (171515, 171794),\n",
       "  (171841, 171965),\n",
       "  (172026, 172122),\n",
       "  (172163, 172268),\n",
       "  (172336, 172491),\n",
       "  (172507, 172766),\n",
       "  (173187, 173545),\n",
       "  (175207, 175439),\n",
       "  (175823, 175954),\n",
       "  (176184, 176457),\n",
       "  (176744, 176802),\n",
       "  (177192, 177338),\n",
       "  (177361, 177504),\n",
       "  (177580, 177849),\n",
       "  (177909, 178053),\n",
       "  (178234, 178434),\n",
       "  (178864, 178991),\n",
       "  (179008, 179147),\n",
       "  (179259, 179362),\n",
       "  (179729, 179907),\n",
       "  (180210, 180366),\n",
       "  (180492, 180556),\n",
       "  (180769, 180956),\n",
       "  (183517, 183660),\n",
       "  (186063, 186082),\n",
       "  (190044, 190127),\n",
       "  (190162, 190236),\n",
       "  (191308, 191430),\n",
       "  (192027, 192125),\n",
       "  (192131, 192326),\n",
       "  (192963, 193116),\n",
       "  (193151, 193194),\n",
       "  (193293, 193434),\n",
       "  (193504, 193561),\n",
       "  (195699, 195757),\n",
       "  (196430, 196532),\n",
       "  (196959, 197021),\n",
       "  (197052, 197132),\n",
       "  (197146, 197247),\n",
       "  (197341, 197420),\n",
       "  (198004, 198063),\n",
       "  (198201, 198287),\n",
       "  (199284, 199387),\n",
       "  (199502, 199745),\n",
       "  (200887, 201116),\n",
       "  (201473, 201555),\n",
       "  (204630, 204811),\n",
       "  (205179, 205206),\n",
       "  (205950, 206267),\n",
       "  (206449, 206589),\n",
       "  (206975, 207091),\n",
       "  (207208, 207235),\n",
       "  (207650, 207726),\n",
       "  (211596, 211754),\n",
       "  (212365, 212393),\n",
       "  (213018, 213175),\n",
       "  (213508, 213633),\n",
       "  (213637, 213744),\n",
       "  (215016, 215100),\n",
       "  (217400, 217520),\n",
       "  (220634, 220875),\n",
       "  (220893, 221069),\n",
       "  (222048, 222147),\n",
       "  (223091, 223167),\n",
       "  (224688, 224742),\n",
       "  (226354, 226424),\n",
       "  (227332, 227417),\n",
       "  (229523, 229560),\n",
       "  (232677, 232846),\n",
       "  (233564, 233670),\n",
       "  (233697, 233739),\n",
       "  (233885, 233963),\n",
       "  (234448, 234480),\n",
       "  (237626, 237669),\n",
       "  (238077, 238137),\n",
       "  (238437, 238761),\n",
       "  (239159, 239256),\n",
       "  (239321, 239455),\n",
       "  (239786, 239881),\n",
       "  (244055, 244115),\n",
       "  (246509, 246562),\n",
       "  (246611, 246712),\n",
       "  (248080, 248181),\n",
       "  (250434, 250576),\n",
       "  (250707, 250749),\n",
       "  (250752, 250950),\n",
       "  (251287, 251403),\n",
       "  (251635, 251884),\n",
       "  (256775, 256949),\n",
       "  (256976, 257155),\n",
       "  (257661, 257812),\n",
       "  (258038, 258103),\n",
       "  (258145, 258196),\n",
       "  (259414, 259620),\n",
       "  (259946, 260132),\n",
       "  (260229, 260442),\n",
       "  (260471, 260657),\n",
       "  (261253, 261395),\n",
       "  (261535, 261637),\n",
       "  (262617, 262680),\n",
       "  (262946, 263030),\n",
       "  (264803, 264977),\n",
       "  (266602, 266681),\n",
       "  (267288, 267406),\n",
       "  (268184, 268292),\n",
       "  (268375, 268529),\n",
       "  (269286, 269344),\n",
       "  (269456, 269499),\n",
       "  (269825, 269950),\n",
       "  (270010, 270135),\n",
       "  (270278, 270408),\n",
       "  (270416, 270696),\n",
       "  (271117, 271161),\n",
       "  (271183, 271259),\n",
       "  (272564, 272889),\n",
       "  (273589, 273674),\n",
       "  (273891, 274033),\n",
       "  (274117, 274268),\n",
       "  (274531, 274603),\n",
       "  (274749, 275623),\n",
       "  (275750, 275973),\n",
       "  (276060, 276133),\n",
       "  (276228, 276487),\n",
       "  (276860, 277290),\n",
       "  (277400, 277759),\n",
       "  (277837, 277862),\n",
       "  (278096, 278395),\n",
       "  (278404, 279194),\n",
       "  (279231, 279309),\n",
       "  (279692, 280091),\n",
       "  (280168, 280331),\n",
       "  (280412, 280671),\n",
       "  (280924, 281143),\n",
       "  (281160, 281266),\n",
       "  (281550, 282058),\n",
       "  (282170, 282309),\n",
       "  (283315, 283441),\n",
       "  (284040, 284110),\n",
       "  (284669, 284787),\n",
       "  (284924, 285742),\n",
       "  (285787, 286156),\n",
       "  (286237, 286453),\n",
       "  (287008, 287428),\n",
       "  (287451, 287716),\n",
       "  (287987, 288278),\n",
       "  (288437, 288647),\n",
       "  (288845, 288946),\n",
       "  (288991, 289220),\n",
       "  (289241, 289370),\n",
       "  (289450, 289579),\n",
       "  (289643, 289721),\n",
       "  (290164, 290231),\n",
       "  (290296, 290543),\n",
       "  (291608, 291705),\n",
       "  (291722, 291834),\n",
       "  (293739, 293821),\n",
       "  (294183, 294303),\n",
       "  (294836, 294910),\n",
       "  (297565, 297695),\n",
       "  (297743, 297849),\n",
       "  (300931, 301126),\n",
       "  (301942, 302009),\n",
       "  (302622, 302836),\n",
       "  (302893, 302956),\n",
       "  (303171, 303482),\n",
       "  (303623, 303865),\n",
       "  (304086, 304244),\n",
       "  (304710, 304823),\n",
       "  (306064, 306225),\n",
       "  (306305, 306465),\n",
       "  (307556, 307737),\n",
       "  (308167, 308265),\n",
       "  (310091, 310201),\n",
       "  (311486, 311798),\n",
       "  (314114, 314175),\n",
       "  (314404, 314641),\n",
       "  (314818, 315113),\n",
       "  (315290, 315447),\n",
       "  (315512, 315588),\n",
       "  (315965, 316250),\n",
       "  (316357, 316492),\n",
       "  (316712, 316825),\n",
       "  (316841, 316941),\n",
       "  (317006, 317120),\n",
       "  (317743, 317819),\n",
       "  (319118, 319163),\n",
       "  (319262, 319515),\n",
       "  (319894, 320058),\n",
       "  (320213, 320308),\n",
       "  (320448, 320491),\n",
       "  (322604, 322689),\n",
       "  (323394, 323520),\n",
       "  (323693, 323776),\n",
       "  (325245, 325382),\n",
       "  (325592, 325746),\n",
       "  (325769, 325835),\n",
       "  (325876, 326106),\n",
       "  (326283, 326384),\n",
       "  (327513, 327744),\n",
       "  (328340, 328497),\n",
       "  (328541, 328662),\n",
       "  (329251, 329316),\n",
       "  (329381, 329490),\n",
       "  (329699, 329821),\n",
       "  (330629, 330677),\n",
       "  (330859, 330947),\n",
       "  (331050, 331184),\n",
       "  (332385, 332491),\n",
       "  (333060, 333246),\n",
       "  (333289, 333395),\n",
       "  (333398, 333534),\n",
       "  (333747, 333924),\n",
       "  (334304, 334440),\n",
       "  (334876, 335096),\n",
       "  (335290, 335405),\n",
       "  (335636, 335812),\n",
       "  (335822, 335945),\n",
       "  (339435, 339813),\n",
       "  (341331, 341743),\n",
       "  (341986, 342097),\n",
       "  (342858, 343145),\n",
       "  (343231, 343374),\n",
       "  (343617, 343675),\n",
       "  (343902, 344003),\n",
       "  (344055, 344148),\n",
       "  (345083, 345231),\n",
       "  (348218, 348417),\n",
       "  (348460, 348499)])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_spans_from_label_seq(article_final_sequence[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# create_article_id_label_seqfor article_seq in article_final_sequence\n",
    "final_submission_list =  [get_spans_from_label_seq(article_tup) for article_tup in article_final_sequence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "final_submission_strings = []\n",
    "for fsl in final_submission_list:\n",
    "    article_id = fsl[0]\n",
    "    for span in fsl[1]:\n",
    "        final_submission_strings.append(str(article_id) + \"\\t\" + str(span[0]) + \"\\t\" + str(span[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "final_submission_content = \"\\n\".join(final_submission_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "final_submission_content = \"id\\tbegin_offset\\tend_offset\\n\" + final_submission_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "with open(\"final_submission_from_flair.txt\",\"w\") as f:\n",
    "    f.writelines(final_submission_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "## Shorten the submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "article_spans = open(\"final_submission.txt\",\"r\").readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "span_diff = 310\n",
    "new_article_spans = []\n",
    "for ix, article_span in enumerate(article_spans):\n",
    "    if ix == 0:\n",
    "        pass\n",
    "    elif ix==1:\n",
    "        new_article_spans.append(article_span.split(\"\\t\"))\n",
    "    else:\n",
    "        next_span_start_position =  int(article_span.split(\"\\t\")[1])\n",
    "        prev_span_end_position = int(new_article_spans[-1][2])\n",
    "        next_article_id =  int(article_span.split(\"\\t\")[0])\n",
    "        prev_article_id = int(new_article_spans[-1][0])        \n",
    "#         print(prev_span_end_position,next_span_start_position)\n",
    "        if (next_article_id == prev_article_id):\n",
    "            if (next_span_start_position - prev_span_end_position) < span_diff:\n",
    "                to_insert_span = [new_article_spans[-1][0],new_article_spans[-1][1],article_span.split(\"\\t\")[2]]\n",
    "                new_article_spans.pop()\n",
    "                new_article_spans.append(to_insert_span)\n",
    "            else:\n",
    "                new_article_spans.append(article_span.split(\"\\t\"))\n",
    "        else:\n",
    "            new_article_spans.append(article_span.split(\"\\t\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21675\n"
     ]
    }
   ],
   "source": [
    "print(len(new_article_spans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "article_span_strings = []\n",
    "for article_span in new_article_spans:\n",
    "    article_span_strings.append(\"\\t\".join(article_span))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "condensed_final_submission = \"\".join(article_span_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "with open(\"condensed_final_submission.txt\",\"w\") as f:\n",
    "    f.writelines(condensed_final_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "## Try out sentence piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "spm.SentencePieceTrainer.Train('--input=/data/semeval-2020/task-11/datasets/all.txt --model_prefix=v16000 --character_coverage=1 --vocab_size=16000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['▁Federalist'],\n",
       " ['▁Federal', 'ist'],\n",
       " ['▁Federal', 'is', 't'],\n",
       " ['▁Federal', 'i', 'st'],\n",
       " ['▁', 'Federal', 'ist']]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(\"v16000.model\")\n",
    "sp.NBestEncodeAsPieces(\"Federalist\",5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁', 'F', 'ed', 'e', 'ral', 'is', 't']\n",
      "['▁F', 'ed', 'era', 'l', 'is', 't']\n",
      "['▁Fed', 'e', 'r', 'a', 'l', 'i', 'st']\n",
      "['▁F', 'e', 'der', 'al', 'ist']\n",
      "['▁', 'Federal', 'is', 't']\n",
      "['▁', 'Federal', 'ist']\n",
      "['▁F', 'ed', 'er', 'ali', 'st']\n",
      "['▁', 'F', 'e', 'der', 'al', 'is', 't']\n",
      "['▁Fed', 'er', 'ali', 'st']\n",
      "['▁Federalist']\n"
     ]
    }
   ],
   "source": [
    "for n in range(10):\n",
    "    print(sp.SampleEncodeAsPieces('Federalist', -1, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading https://nlp.h-its.org/bpemb/en/en.wiki.bpe.vs10000.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400869/400869 [00:00<00:00, 637227.84B/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading https://nlp.h-its.org/bpemb/en/en.wiki.bpe.vs10000.d50.w2v.bin.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1924908/1924908 [00:01<00:00, 1923637.13B/s]\n",
      "/home/raghavan/anaconda3/envs/semeval_2020/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "from bpemb import BPEmb\n",
    "bpemb_en = BPEmb(lang=\"en\", dim=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁federal', 'ist']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpemb_en.encode(\"Federalist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BPEmb(lang=en, vs=10000, dim=50)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpemb_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "bt = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['donald']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bt.tokenize(\"Donald\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "## Join sentence level classification with span output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "final_submission = pd.read_csv(\"/home/raghavan/Downloads/final_submission.txt\",sep=\"\\t\")\n",
    "fast_text_output = pd.read_csv(\"/home/raghavan/Downloads/output_dev.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>begin_offset</th>\n",
       "      <th>end_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>779309765</td>\n",
       "      <td>111</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>779309765</td>\n",
       "      <td>142</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>779309765</td>\n",
       "      <td>409</td>\n",
       "      <td>454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>779309765</td>\n",
       "      <td>615</td>\n",
       "      <td>692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>779309765</td>\n",
       "      <td>1514</td>\n",
       "      <td>1526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  begin_offset  end_offset\n",
       "0  779309765           111         133\n",
       "1  779309765           142         150\n",
       "2  779309765           409         454\n",
       "3  779309765           615         692\n",
       "4  779309765          1514        1526"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_submission.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>article788271400.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>Are You Kidding Me, Ted Cruz?</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>article788271400.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>.Don't \"Blame The Police Officer\" Who Admitted...</td>\n",
       "      <td>31</td>\n",
       "      <td>98</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>article788271400.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>..Dallas, TX — In a repugnant and outright dis...</td>\n",
       "      <td>99</td>\n",
       "      <td>314</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>article788271400.txt</td>\n",
       "      <td>3</td>\n",
       "      <td>.During an interview over the weekend, Cruz sa...</td>\n",
       "      <td>315</td>\n",
       "      <td>472</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>article788271400.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>.FOX 26 asked Cruz to respond to his Democrati...</td>\n",
       "      <td>473</td>\n",
       "      <td>593</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             article_id  sentence_id  \\\n",
       "0  article788271400.txt            0   \n",
       "1  article788271400.txt            1   \n",
       "2  article788271400.txt            2   \n",
       "3  article788271400.txt            3   \n",
       "4  article788271400.txt            4   \n",
       "\n",
       "                                                text  start  end  label  \n",
       "0                      Are You Kidding Me, Ted Cruz?      1   30  False  \n",
       "1  .Don't \"Blame The Police Officer\" Who Admitted...     31   98  False  \n",
       "2  ..Dallas, TX — In a repugnant and outright dis...     99  314  False  \n",
       "3  .During an interview over the weekend, Cruz sa...    315  472  False  \n",
       "4  .FOX 26 asked Cruz to respond to his Democrati...    473  593  False  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_text_output.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raghavan/anaconda3/envs/semeval_2020/lib/python3.7/site-packages/tqdm/std.py:648: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "369dfc855d104b2789293daa33326125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=2934, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "final_submission[\"article_id\"] = final_submission[\"id\"]\n",
    "fast_text_output[\"article_file_name\"] = fast_text_output[\"article_id\"]\n",
    "fast_text_output[\"article_id\"] = fast_text_output[\"article_file_name\"].swifter.apply(lambda x: int(x.replace(\"article\",\"\").replace(\".txt\",\"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article_id            int64\n",
       "sentence_id           int64\n",
       "text                 object\n",
       "start                 int64\n",
       "end                   int64\n",
       "label                  bool\n",
       "article_file_name    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_text_output.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              int64\n",
       "begin_offset    int64\n",
       "end_offset      int64\n",
       "article_id      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_submission.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "fast_text_output_only_prop = fast_text_output[fast_text_output[\"label\"] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "fasttext_span_joined = fast_text_output_only_prop.merge(final_submission,on=\"article_id\",how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def is_span_with_in(row):\n",
    "#     print(row)\n",
    "    if (row.begin_offset >= row.start - 20) and (row.end_offset -20 <= row.end):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aea8aa70efb24ee198cb160de0f3a9e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=326880, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# fasttext_span_joined[\"is_span_within\"] = \n",
    "fasttext_span_joined[\"is_span_with\"] = fasttext_span_joined.swifter.apply(is_span_with_in,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "to_submit_row =  fasttext_span_joined[fasttext_span_joined[\"is_span_with\"] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>label</th>\n",
       "      <th>article_file_name</th>\n",
       "      <th>id</th>\n",
       "      <th>begin_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>is_span_with</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2282</td>\n",
       "      <td>788271400</td>\n",
       "      <td>32.0</td>\n",
       "      <td>.In Cruz’s eyes, Guyger going into an apartmen...</td>\n",
       "      <td>3314.0</td>\n",
       "      <td>3530.0</td>\n",
       "      <td>True</td>\n",
       "      <td>article788271400.txt</td>\n",
       "      <td>788271400</td>\n",
       "      <td>3445</td>\n",
       "      <td>3451</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3418</td>\n",
       "      <td>738447109</td>\n",
       "      <td>33.0</td>\n",
       "      <td>.While many are happy that Tillerson is gone, ...</td>\n",
       "      <td>3517.0</td>\n",
       "      <td>3790.0</td>\n",
       "      <td>True</td>\n",
       "      <td>article738447109.txt</td>\n",
       "      <td>738447109</td>\n",
       "      <td>3595</td>\n",
       "      <td>3632</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4553</td>\n",
       "      <td>778094905</td>\n",
       "      <td>31.0</td>\n",
       "      <td>.Political correctness needs to be thrown out ...</td>\n",
       "      <td>3544.0</td>\n",
       "      <td>3726.0</td>\n",
       "      <td>True</td>\n",
       "      <td>article778094905.txt</td>\n",
       "      <td>778094905</td>\n",
       "      <td>3595</td>\n",
       "      <td>3632</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6818</td>\n",
       "      <td>832908905</td>\n",
       "      <td>18.0</td>\n",
       "      <td>.“Attorney General Barr must not give Presiden...</td>\n",
       "      <td>2382.0</td>\n",
       "      <td>2662.0</td>\n",
       "      <td>True</td>\n",
       "      <td>article832908905.txt</td>\n",
       "      <td>832908905</td>\n",
       "      <td>2500</td>\n",
       "      <td>2510</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7954</td>\n",
       "      <td>832908905</td>\n",
       "      <td>19.0</td>\n",
       "      <td>.The Democratic leaders said Mueller’s investi...</td>\n",
       "      <td>2663.0</td>\n",
       "      <td>2917.0</td>\n",
       "      <td>True</td>\n",
       "      <td>article832908905.txt</td>\n",
       "      <td>832908905</td>\n",
       "      <td>2878</td>\n",
       "      <td>2922</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>301922</td>\n",
       "      <td>999000851</td>\n",
       "      <td>25.0</td>\n",
       "      <td>.This means that Acosta, or any other reporter...</td>\n",
       "      <td>3260.0</td>\n",
       "      <td>3467.0</td>\n",
       "      <td>True</td>\n",
       "      <td>article999000851.txt</td>\n",
       "      <td>999000851</td>\n",
       "      <td>3445</td>\n",
       "      <td>3451</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>306459</td>\n",
       "      <td>999000878</td>\n",
       "      <td>22.0</td>\n",
       "      <td>.Not only that, he used his hand to forcefully...</td>\n",
       "      <td>2825.0</td>\n",
       "      <td>2918.0</td>\n",
       "      <td>True</td>\n",
       "      <td>article999000878.txt</td>\n",
       "      <td>999000878</td>\n",
       "      <td>2878</td>\n",
       "      <td>2922</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310994</td>\n",
       "      <td>763280007</td>\n",
       "      <td>17.0</td>\n",
       "      <td>.Meanwhile, Britain has a steadily lengthening...</td>\n",
       "      <td>1497.0</td>\n",
       "      <td>1611.0</td>\n",
       "      <td>True</td>\n",
       "      <td>article763280007.txt</td>\n",
       "      <td>763280007</td>\n",
       "      <td>1514</td>\n",
       "      <td>1526</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310995</td>\n",
       "      <td>763280007</td>\n",
       "      <td>17.0</td>\n",
       "      <td>.Meanwhile, Britain has a steadily lengthening...</td>\n",
       "      <td>1497.0</td>\n",
       "      <td>1611.0</td>\n",
       "      <td>True</td>\n",
       "      <td>article763280007.txt</td>\n",
       "      <td>763280007</td>\n",
       "      <td>1543</td>\n",
       "      <td>1551</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>317811</td>\n",
       "      <td>763280007</td>\n",
       "      <td>33.0</td>\n",
       "      <td>.Theresa May and company obvious hope that oth...</td>\n",
       "      <td>3162.0</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>True</td>\n",
       "      <td>article763280007.txt</td>\n",
       "      <td>763280007</td>\n",
       "      <td>3151</td>\n",
       "      <td>3153</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        article_id  sentence_id  \\\n",
       "2282     788271400         32.0   \n",
       "3418     738447109         33.0   \n",
       "4553     778094905         31.0   \n",
       "6818     832908905         18.0   \n",
       "7954     832908905         19.0   \n",
       "...            ...          ...   \n",
       "301922   999000851         25.0   \n",
       "306459   999000878         22.0   \n",
       "310994   763280007         17.0   \n",
       "310995   763280007         17.0   \n",
       "317811   763280007         33.0   \n",
       "\n",
       "                                                     text   start     end  \\\n",
       "2282    .In Cruz’s eyes, Guyger going into an apartmen...  3314.0  3530.0   \n",
       "3418    .While many are happy that Tillerson is gone, ...  3517.0  3790.0   \n",
       "4553    .Political correctness needs to be thrown out ...  3544.0  3726.0   \n",
       "6818    .“Attorney General Barr must not give Presiden...  2382.0  2662.0   \n",
       "7954    .The Democratic leaders said Mueller’s investi...  2663.0  2917.0   \n",
       "...                                                   ...     ...     ...   \n",
       "301922  .This means that Acosta, or any other reporter...  3260.0  3467.0   \n",
       "306459  .Not only that, he used his hand to forcefully...  2825.0  2918.0   \n",
       "310994  .Meanwhile, Britain has a steadily lengthening...  1497.0  1611.0   \n",
       "310995  .Meanwhile, Britain has a steadily lengthening...  1497.0  1611.0   \n",
       "317811  .Theresa May and company obvious hope that oth...  3162.0  3400.0   \n",
       "\n",
       "       label     article_file_name         id  begin_offset  end_offset  \\\n",
       "2282    True  article788271400.txt  788271400          3445        3451   \n",
       "3418    True  article738447109.txt  738447109          3595        3632   \n",
       "4553    True  article778094905.txt  778094905          3595        3632   \n",
       "6818    True  article832908905.txt  832908905          2500        2510   \n",
       "7954    True  article832908905.txt  832908905          2878        2922   \n",
       "...      ...                   ...        ...           ...         ...   \n",
       "301922  True  article999000851.txt  999000851          3445        3451   \n",
       "306459  True  article999000878.txt  999000878          2878        2922   \n",
       "310994  True  article763280007.txt  763280007          1514        1526   \n",
       "310995  True  article763280007.txt  763280007          1543        1551   \n",
       "317811  True  article763280007.txt  763280007          3151        3153   \n",
       "\n",
       "        is_span_with  \n",
       "2282            True  \n",
       "3418            True  \n",
       "4553            True  \n",
       "6818            True  \n",
       "7954            True  \n",
       "...              ...  \n",
       "301922          True  \n",
       "306459          True  \n",
       "310994          True  \n",
       "310995          True  \n",
       "317811          True  \n",
       "\n",
       "[167 rows x 11 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_submit_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article_id           167\n",
       "sentence_id          167\n",
       "text                 167\n",
       "start                167\n",
       "end                  167\n",
       "label                167\n",
       "article_file_name    167\n",
       "id                   167\n",
       "begin_offset         167\n",
       "end_offset           167\n",
       "is_span_with         167\n",
       "dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_submit_row.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semeval2020",
   "language": "python",
   "name": "semeval2020"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

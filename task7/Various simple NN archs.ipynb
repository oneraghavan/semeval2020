{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"ready_to_serve_train.csv\")\n",
    "dev = pd.read_csv(\"ready_to_serve_dev.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>original</th>\n",
       "      <th>edit</th>\n",
       "      <th>grades</th>\n",
       "      <th>meanGrade</th>\n",
       "      <th>grade_round</th>\n",
       "      <th>grades_0</th>\n",
       "      <th>grades_1</th>\n",
       "      <th>grades_2</th>\n",
       "      <th>grades_3</th>\n",
       "      <th>grades_4</th>\n",
       "      <th>edited_head_line</th>\n",
       "      <th>original_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>14530</td>\n",
       "      <td>France is ‘ hunting down its citizens who join...</td>\n",
       "      <td>twins</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>france is hunting down its citizens who joined...</td>\n",
       "      <td>france is hunting down its citizens who joined...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>13034</td>\n",
       "      <td>Pentagon claims 2,000 % increase in Russian tr...</td>\n",
       "      <td>bowling</td>\n",
       "      <td>33110</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>pentagon claims 2,000 % increase in russian tr...</td>\n",
       "      <td>pentagon claims 2,000 % increase in russian tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8731</td>\n",
       "      <td>Iceland PM Calls Snap Vote as Pedophile Furor ...</td>\n",
       "      <td>party</td>\n",
       "      <td>22100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>iceland pm calls snap vote as pedophile furor ...</td>\n",
       "      <td>iceland pm calls snap vote as pedophile furor ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                           original     edit  grades  \\\n",
       "0  14530  France is ‘ hunting down its citizens who join...    twins   10000   \n",
       "1  13034  Pentagon claims 2,000 % increase in Russian tr...  bowling   33110   \n",
       "2   8731  Iceland PM Calls Snap Vote as Pedophile Furor ...    party   22100   \n",
       "\n",
       "   meanGrade  grade_round  grades_0  grades_1  grades_2  grades_3  grades_4  \\\n",
       "0        0.2            0         1         0         0         0         0   \n",
       "1        1.6            2         3         3         1         1         0   \n",
       "2        1.0            1         2         2         1         0         0   \n",
       "\n",
       "                                    edited_head_line  \\\n",
       "0  france is hunting down its citizens who joined...   \n",
       "1  pentagon claims 2,000 % increase in russian tr...   \n",
       "2  iceland pm calls snap vote as pedophile furor ...   \n",
       "\n",
       "                                    original_cleaned  \n",
       "0  france is hunting down its citizens who joined...  \n",
       "1  pentagon claims 2,000 % increase in russian tr...  \n",
       "2  iceland pm calls snap vote as pedophile furor ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(i.split(\" \")) for i in train[\"edited_head_line\"].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(i.split(\" \")) for i in dev[\"edited_head_line\"].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>original</th>\n",
       "      <th>edit</th>\n",
       "      <th>edited_head_line</th>\n",
       "      <th>original_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1723</td>\n",
       "      <td>Thousands of gay and bisexual &lt;men/&gt; convicted...</td>\n",
       "      <td>swans</td>\n",
       "      <td>thousands of gay and bisexual swans convicted ...</td>\n",
       "      <td>thousands of gay and bisexual men convicted of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>12736</td>\n",
       "      <td>Special &lt;prosecutor/&gt; appointed to Trump Russia</td>\n",
       "      <td>chef</td>\n",
       "      <td>special chef appointed to trump russia</td>\n",
       "      <td>special prosecutor appointed to trump russia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>12274</td>\n",
       "      <td>Spanish police detain man and search Ripoll ad...</td>\n",
       "      <td>squad</td>\n",
       "      <td>spanish police detain man and search ripoll ad...</td>\n",
       "      <td>spanish police detain man and search ripoll ad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                           original   edit  \\\n",
       "0   1723  Thousands of gay and bisexual <men/> convicted...  swans   \n",
       "1  12736    Special <prosecutor/> appointed to Trump Russia   chef   \n",
       "2  12274  Spanish police detain man and search Ripoll ad...  squad   \n",
       "\n",
       "                                    edited_head_line  \\\n",
       "0  thousands of gay and bisexual swans convicted ...   \n",
       "1             special chef appointed to trump russia   \n",
       "2  spanish police detain man and search ripoll ad...   \n",
       "\n",
       "                                    original_cleaned  \n",
       "0  thousands of gay and bisexual men convicted of...  \n",
       "1       special prosecutor appointed to trump russia  \n",
       "2  spanish police detain man and search ripoll ad...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "for train_index,test_index in skf.split(train,train[\"grades_0\"]):\n",
    "    train.iloc[train_index][[\"edited_head_line\",\"grades_0\"]].to_csv(\"train_grade0.csv\",index=False,header=False)\n",
    "    train.iloc[test_index][[\"edited_head_line\",\"grades_0\"]].to_csv(\"test_grade0.csv\",index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "dev.edited_head_line.to_csv(\"dev_edited.csv\",index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from torchtext import data\n",
    "spacy_en = spacy.load(\"en\")\n",
    "\n",
    "def tokenizer(text): # create a tokenizer function\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "TEXT = data.Field(sequential=True, tokenize=tokenizer, lower=True,fix_length=28)\n",
    "LABEL = data.Field(sequential=False, use_vocab=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train, val = data.TabularDataset.splits(\n",
    "        path='.', train='train_grade0.csv',\n",
    "        validation='test_grade0.csv', format='csv',\n",
    "        fields=[('Text', TEXT), ('Label', LABEL)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train,dev, vectors=\"fasttext.en.300d\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['france',\n",
       " 'is',\n",
       " 'hunting',\n",
       " 'down',\n",
       " 'its',\n",
       " 'citizens',\n",
       " 'who',\n",
       " 'joined',\n",
       " 'twins',\n",
       " '’',\n",
       " 'without',\n",
       " 'trial',\n",
       " 'in',\n",
       " 'iraq']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.examples[0].Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8600, 300])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "train_iter, val_iter = data.Iterator.splits(\n",
    "        (train, val), sort_key=lambda x: len(x.Text),\n",
    "        batch_sizes=(32, 32, 32), device=torch.device(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# from torch import nn\n",
    "# emb_dim = 300\n",
    "# vocab = TEXT.vocab\n",
    "# self.embed = nn.Embedding(len(vocab), emb_dim)\n",
    "# self.embed.weight.data.copy_(vocab.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8600, 300])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.itos[55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class SimpleLinearModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,vocab,max_seq_length):\n",
    "        super(SimpleLinearModel, self).__init__()\n",
    "        emb_dim = TEXT.vocab.vectors.shape[1]\n",
    "        self.embed = nn.Embedding(len(vocab), emb_dim)\n",
    "        self.embed.weight.data.copy_(vocab.vectors)\n",
    "        \n",
    "        self.linear1 = nn.Linear(emb_dim * max_seq_length,2000)\n",
    "        self.dropout = nn.Dropout(0.7)\n",
    "        self.linear2 = nn.Linear(2000,4)\n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        embeddings = self.embed(inputs)\n",
    "        return self.linear2(self.dropout(self.linear1(embeddings.reshape(32,8400))))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from simple_models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score , recall_score , f1_score\n",
    "def clip_gradient(model, clip_value):\n",
    "    params = list(filter(lambda p: p.grad is not None, model.parameters()))\n",
    "    for p in params:\n",
    "        p.grad.data.clamp_(-clip_value, clip_value)\n",
    "\n",
    "def train_model(model, train_iter, epoch):\n",
    "    total_epoch_loss = 0\n",
    "    total_epoch_acc = 0\n",
    "    total_epoch_pre = 0\n",
    "    total_epoch_recal = 0\n",
    "    total_epoch_f1 = 0\n",
    "    \n",
    "    model.cuda()\n",
    "    optim = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "    steps = 0\n",
    "    model.train()\n",
    "    for idx, batch in enumerate(train_iter):\n",
    "        text = batch.Text.T\n",
    "        target = batch.Label\n",
    "        target = torch.autograd.Variable(target).long()\n",
    "        if torch.cuda.is_available():\n",
    "            text = text.cuda()\n",
    "            target = target.cuda()\n",
    "        if (text.size()[0] is not 32):# One of the batch returned by BucketIterator has length different than 32.\n",
    "            continue\n",
    "        optim.zero_grad()\n",
    "        prediction = model(text)\n",
    "        loss = loss_fn(prediction, target)\n",
    "        num_corrects = (torch.max(prediction, 1)[1].view(target.size()).data == target.data).float().sum()\n",
    "        acc = 100.0 * num_corrects/len(batch)\n",
    "        predictions_classes = np.argmax(prediction.clone().cpu().detach().numpy(),axis=1)\n",
    "        target_classes = target.clone().cpu().detach().numpy()\n",
    "        ps = precision_score(predictions_classes,target_classes,average='micro')\n",
    "        rs = recall_score(predictions_classes,target_classes,average='micro')\n",
    "        f1_s = f1_score(predictions_classes,target_classes,average='micro')\n",
    "        loss.backward()\n",
    "#         clip_gradient(model, 1e-1)\n",
    "        optim.step()\n",
    "        steps += 1\n",
    "        \n",
    "        if steps % 100 == 0:\n",
    "            print (f'Epoch: {epoch+1}, Idx: {idx+1}, Training Loss: {loss.item():.4f}, Training Accuracy: {acc.item(): .2f}%')\n",
    "        \n",
    "        total_epoch_loss += loss.item()\n",
    "        total_epoch_acc += acc.item()\n",
    "        total_epoch_pre += ps\n",
    "        total_epoch_recal += rs\n",
    "        total_epoch_f1 += f1_s\n",
    "        \n",
    "    return total_epoch_loss/len(train_iter), total_epoch_acc/len(train_iter) , total_epoch_pre/len(train_iter) , total_epoch_recal/len(train_iter) ,total_epoch_f1/len(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def eval_model(model, val_iter):\n",
    "    total_epoch_loss = 0\n",
    "    total_epoch_acc = 0\n",
    "    total_epoch_pre = 0\n",
    "    total_epoch_recal = 0\n",
    "    total_epoch_f1 = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(val_iter):\n",
    "            text = batch.Text.T\n",
    "            if (text.size()[0] is not 32):\n",
    "                continue    \n",
    "            target = batch.Label\n",
    "            target = torch.autograd.Variable(target).long()\n",
    "            if torch.cuda.is_available():\n",
    "                text = text.cuda()\n",
    "                target = target.cuda()\n",
    "            prediction = model(text)\n",
    "            loss = loss_fn(prediction, target)\n",
    "            predictions_classes = np.argmax(prediction.clone().cpu().detach().numpy(),axis=1)\n",
    "            target_classes = target.clone().cpu().detach().numpy()\n",
    "\n",
    "            ps = precision_score(predictions_classes,target_classes,average='micro')\n",
    "            rs = recall_score(predictions_classes,target_classes,average='micro')\n",
    "            f1_s = f1_score(predictions_classes,target_classes,average='micro')\n",
    "\n",
    "            num_corrects = (torch.max(prediction, 1)[1].view(target.size()).data == target.data).sum()\n",
    "            acc = 100.0 * num_corrects/len(batch)\n",
    "            total_epoch_loss += loss.item()\n",
    "            total_epoch_acc += acc.item()\n",
    "            total_epoch_pre += ps\n",
    "            total_epoch_recal += rs\n",
    "            total_epoch_f1 += f1_s\n",
    "\n",
    "            \n",
    "    return total_epoch_loss/len(val_iter), total_epoch_acc/len(val_iter) ,total_epoch_pre/len(val_iter) , total_epoch_recal/len(val_iter) ,total_epoch_f1/len(val_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Try Various simple model archs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Simple linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# learning_rate = 1e-7\n",
    "# batch_size = 32\n",
    "# output_size = 2\n",
    "# hidden_size = 256\n",
    "# embedding_length = 300\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# model = SimpleLinearModel(TEXT.vocab,28)\n",
    "# loss_fn = F.cross_entropy\n",
    "# print(model)\n",
    "# for epoch in range(10):\n",
    "#     train_loss, train_acc , train_precision, train_recall , train_f1 = train_model(model, train_iter, epoch)\n",
    "#     val_loss, val_acc , val_precision, val_recall , val_f1= eval_model(model, val_iter)\n",
    "    \n",
    "#     print(f'Epoch: {epoch+1:01}, Train Loss: {train_loss:.3f}, Train Acc: {train_acc:.2f}%, Train Prec: {train_precision:.2f},Train Recal: {train_recall:.2f},Train F1: {train_f1:.2f},\\\n",
    "#            Val. Loss: {val_loss:3f}, Val. Acc: {val_acc:.2f}, Val Prec: {val_precision:.2f}, Val Recal: {val_recall:.2f}, Val F1: {val_f1:.2f}')\n",
    " \n",
    "# #     print(f'Epoch: {epoch+1:02}, Train Loss: {train_loss:.3f}, Train Acc: {train_acc:.2f}%, Val. Loss: {val_loss:3f}, Val. Acc: {val_acc:.2f}%')\n",
    "\n",
    "# # test_loss, test_acc = eval_model(model, test_iter)\n",
    "# # print(f'Test Loss: {test_loss:.3f}, Test Acc: {test_acc:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Conv model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# learning_rate = 1e-7\n",
    "# batch_size = 32\n",
    "# output_size = 4\n",
    "# hidden_size = 256\n",
    "# embedding_length = 300\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# model = CNN(batch_size,output_size,1,1,[5,3,1],1,1,0.7,TEXT.vocab)\n",
    "# loss_fn = F.cross_entropy\n",
    "# print(model)\n",
    "# for epoch in range(10):\n",
    "#     train_loss, train_acc , train_precision, train_recall , train_f1 = train_model(model, train_iter, epoch)\n",
    "#     val_loss, val_acc , val_precision, val_recall , val_f1= eval_model(model, val_iter)\n",
    "    \n",
    "#     print(f'Epoch: {epoch+1:01}, Train Loss: {train_loss:.3f}, Train Acc: {train_acc:.2f}%, Train Prec: {train_precision:.2f},Train Recal: {train_recall:.2f},Train F1: {train_f1:.2f},\\\n",
    "#            Val. Loss: {val_loss:3f}, Val. Acc: {val_acc:.2f}, Val Prec: {val_precision:.2f}, Val Recal: {val_recall:.2f}, Val F1: {val_f1:.2f}')\n",
    " \n",
    "# #     print(f'Epoch: {epoch+1:02}, Train Loss: {train_loss:.3f}, Train Acc: {train_acc:.2f}%, Val. Loss: {val_loss:3f}, Val. Acc: {val_acc:.2f}%')\n",
    "\n",
    "# # test_loss, test_acc = eval_model(model, test_iter)\n",
    "# # print(f'Test Loss: {test_loss:.3f}, Test Acc: {test_acc:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## LSTM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMClassifier(\n",
      "  (word_embeddings): Embedding(8600, 300)\n",
      "  (lstm): LSTM(300, 256)\n",
      "  (label): Linear(in_features=256, out_features=4, bias=True)\n",
      ")\n",
      "Epoch: 1, Idx: 100, Training Loss: 1.1504, Training Accuracy:  53.12%\n",
      "Epoch: 1, Train Loss: 1.236, Train Acc: 35.68%, Train Prec: 0.36,Train Recal: 0.36,Train F1: 0.36,           Val. Loss: 1.235837, Val. Acc: 37.62, Val Prec: 0.38, Val Recal: 0.38, Val F1: 0.38\n",
      "Epoch: 2, Idx: 100, Training Loss: 1.1952, Training Accuracy:  53.12%\n",
      "Epoch: 2, Train Loss: 1.228, Train Acc: 37.50%, Train Prec: 0.38,Train Recal: 0.38,Train F1: 0.38,           Val. Loss: 1.227356, Val. Acc: 37.62, Val Prec: 0.38, Val Recal: 0.38, Val F1: 0.38\n",
      "Epoch: 3, Idx: 100, Training Loss: 1.1660, Training Accuracy:  46.88%\n",
      "Epoch: 3, Train Loss: 1.224, Train Acc: 37.46%, Train Prec: 0.37,Train Recal: 0.37,Train F1: 0.37,           Val. Loss: 1.225438, Val. Acc: 37.62, Val Prec: 0.38, Val Recal: 0.38, Val F1: 0.38\n",
      "Epoch: 4, Idx: 100, Training Loss: 1.2109, Training Accuracy:  43.75%\n",
      "Epoch: 4, Train Loss: 1.182, Train Acc: 40.00%, Train Prec: 0.40,Train Recal: 0.40,Train F1: 0.40,           Val. Loss: 1.259385, Val. Acc: 33.80, Val Prec: 0.34, Val Recal: 0.34, Val F1: 0.34\n",
      "Epoch: 5, Idx: 100, Training Loss: 1.1500, Training Accuracy:  40.62%\n",
      "Epoch: 5, Train Loss: 1.108, Train Acc: 44.72%, Train Prec: 0.45,Train Recal: 0.45,Train F1: 0.45,           Val. Loss: 1.300065, Val. Acc: 34.81, Val Prec: 0.35, Val Recal: 0.35, Val F1: 0.35\n",
      "Epoch: 6, Idx: 100, Training Loss: 1.2426, Training Accuracy:  34.38%\n",
      "Epoch: 6, Train Loss: 1.021, Train Acc: 48.61%, Train Prec: 0.49,Train Recal: 0.49,Train F1: 0.49,           Val. Loss: 1.348420, Val. Acc: 35.82, Val Prec: 0.36, Val Recal: 0.36, Val F1: 0.36\n",
      "Epoch: 7, Idx: 100, Training Loss: 1.1262, Training Accuracy:  56.25%\n",
      "Epoch: 7, Train Loss: 0.945, Train Acc: 51.26%, Train Prec: 0.51,Train Recal: 0.51,Train F1: 0.51,           Val. Loss: 1.510939, Val. Acc: 35.12, Val Prec: 0.35, Val Recal: 0.35, Val F1: 0.35\n",
      "Epoch: 8, Idx: 100, Training Loss: 0.9108, Training Accuracy:  43.75%\n",
      "Epoch: 8, Train Loss: 0.898, Train Acc: 52.67%, Train Prec: 0.53,Train Recal: 0.53,Train F1: 0.53,           Val. Loss: 1.580741, Val. Acc: 33.26, Val Prec: 0.33, Val Recal: 0.33, Val F1: 0.33\n",
      "Epoch: 9, Idx: 100, Training Loss: 0.7984, Training Accuracy:  53.12%\n",
      "Epoch: 9, Train Loss: 0.831, Train Acc: 54.86%, Train Prec: 0.55,Train Recal: 0.55,Train F1: 0.55,           Val. Loss: 1.707137, Val. Acc: 35.18, Val Prec: 0.35, Val Recal: 0.35, Val F1: 0.35\n",
      "Epoch: 10, Idx: 100, Training Loss: 0.8142, Training Accuracy:  53.12%\n",
      "Epoch: 10, Train Loss: 0.775, Train Acc: 57.04%, Train Prec: 0.57,Train Recal: 0.57,Train F1: 0.57,           Val. Loss: 1.915517, Val. Acc: 35.97, Val Prec: 0.36, Val Recal: 0.36, Val F1: 0.36\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "learning_rate = 5e-7\n",
    "batch_size = 32\n",
    "output_size = 4\n",
    "hidden_size = 256\n",
    "embedding_length = 300\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model = LSTMClassifier(batch_size,output_size,256,TEXT.vocab)\n",
    "loss_fn = F.cross_entropy\n",
    "print(model)\n",
    "for epoch in range(10):\n",
    "    train_loss, train_acc , train_precision, train_recall , train_f1 = train_model(model, train_iter, epoch)\n",
    "    val_loss, val_acc , val_precision, val_recall , val_f1= eval_model(model, val_iter)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:01}, Train Loss: {train_loss:.3f}, Train Acc: {train_acc:.2f}%, Train Prec: {train_precision:.2f},Train Recal: {train_recall:.2f},Train F1: {train_f1:.2f},\\\n",
    "           Val. Loss: {val_loss:3f}, Val. Acc: {val_acc:.2f}, Val Prec: {val_precision:.2f}, Val Recal: {val_recall:.2f}, Val F1: {val_f1:.2f}')\n",
    " \n",
    "#     print(f'Epoch: {epoch+1:02}, Train Loss: {train_loss:.3f}, Train Acc: {train_acc:.2f}%, Val. Loss: {val_loss:3f}, Val. Acc: {val_acc:.2f}%')\n",
    "\n",
    "# test_loss, test_acc = eval_model(model, test_iter)\n",
    "# print(f'Test Loss: {test_loss:.3f}, Test Acc: {test_acc:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semeval2020",
   "language": "python",
   "name": "semeval2020"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

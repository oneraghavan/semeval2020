{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from transformers import BertConfig , BertTokenizer , BertForSequenceClassification\n",
    "from transformers import RobertaConfig , RobertaTokenizer , RobertaForSequenceClassification\n",
    "import torch\n",
    "\n",
    "MODEL_CLASSES = {\n",
    "    \"bert\": (BertConfig, BertForSequenceClassification, BertTokenizer),\n",
    "    \"roberta\": (RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model_type = \"bert\"\n",
    "model_base = \"bert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "config_class, model_class, tokenizer_class = MODEL_CLASSES[model_type]\n",
    "config = config_class.from_pretrained(model_base)\n",
    "tokenizer = tokenizer_class.from_pretrained(model_base,do_lower_case=True)\n",
    "model = model_class.from_pretrained(model_base)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import swifter\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', -1)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "train = pd.read_csv(\"ready_to_serve_train.csv\")\n",
    "dev = pd.read_csv(\"ready_to_serve_dev.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>original</th>\n",
       "      <th>edit</th>\n",
       "      <th>grades</th>\n",
       "      <th>meanGrade</th>\n",
       "      <th>grade_round</th>\n",
       "      <th>grades_0</th>\n",
       "      <th>grades_1</th>\n",
       "      <th>grades_2</th>\n",
       "      <th>grades_3</th>\n",
       "      <th>grades_4</th>\n",
       "      <th>edited_head_line</th>\n",
       "      <th>original_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>14530</td>\n",
       "      <td>France is ‘ hunting down its citizens who joined &lt;Isis/&gt; ’ without trial in Iraq</td>\n",
       "      <td>twins</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>france is hunting down its citizens who joined twins ’ without trial in iraq</td>\n",
       "      <td>france is hunting down its citizens who joined isis ’ without trial in iraq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>13034</td>\n",
       "      <td>Pentagon claims 2,000 % increase in Russian trolls after &lt;Syria/&gt; strikes . What does that mean ?</td>\n",
       "      <td>bowling</td>\n",
       "      <td>33110</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>pentagon claims 2,000 % increase in russian trolls after bowling strikes . what does that mean ?</td>\n",
       "      <td>pentagon claims 2,000 % increase in russian trolls after syria strikes . what does that mean ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8731</td>\n",
       "      <td>Iceland PM Calls Snap Vote as Pedophile Furor Crashes &lt;Coalition/&gt;</td>\n",
       "      <td>party</td>\n",
       "      <td>22100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>iceland pm calls snap vote as pedophile furor crashes party</td>\n",
       "      <td>iceland pm calls snap vote as pedophile furor crashes coalition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>76</td>\n",
       "      <td>In an apparent first , Iran and Israel &lt;engage/&gt; each other militarily</td>\n",
       "      <td>slap</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>in an apparent first , iran and israel slap each other militarily</td>\n",
       "      <td>in an apparent first , iran and israel engage each other militarily</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6164</td>\n",
       "      <td>Trump was told weeks ago that Flynn misled &lt;Vice/&gt; President .</td>\n",
       "      <td>school</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>trump was told weeks ago that flynn misled school president .</td>\n",
       "      <td>trump was told weeks ago that flynn misled vice president .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>8832</td>\n",
       "      <td>All 22 &lt;promises/&gt; Trump made in his speech to Congress , in one chart</td>\n",
       "      <td>sounds</td>\n",
       "      <td>22200</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>all 22 sounds trump made in his speech to congress , in one chart</td>\n",
       "      <td>all 22 promises trump made in his speech to congress , in one chart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>12174</td>\n",
       "      <td>New DOJ alert system will flag &lt;crimes/&gt; against police</td>\n",
       "      <td>laughter</td>\n",
       "      <td>32100</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>new doj alert system will flag laughter against police</td>\n",
       "      <td>new doj alert system will flag crimes against police</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3731</td>\n",
       "      <td>As Someone Who Grew Up Among Fundamentalist &lt;Christians/&gt; In The US , I 'm Surprised Anyone 's Surprised About Roy Moore</td>\n",
       "      <td>morons</td>\n",
       "      <td>21110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>as someone who grew up among fundamentalist morons in the us , i m surprised anyone 's surprised about roy moore</td>\n",
       "      <td>as someone who grew up among fundamentalist christians in the us , i m surprised anyone 's surprised about roy moore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>6554</td>\n",
       "      <td>Canadians may pay more taxes than Americans , but here 's what they get for their &lt;money/&gt;</td>\n",
       "      <td>loonies</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>canadians may pay more taxes than americans , but here 's what they get for their loonies</td>\n",
       "      <td>canadians may pay more taxes than americans , but here 's what they get for their money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>14191</td>\n",
       "      <td>Dutch minister resigns in drug baron &lt;row/&gt;</td>\n",
       "      <td>blow</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dutch minister resigns in drug baron blow</td>\n",
       "      <td>dutch minister resigns in drug baron row</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>14268</td>\n",
       "      <td>Dozens dead in possible gas &lt;attack/&gt; in Syria ; regime denies allegation</td>\n",
       "      <td>bloating</td>\n",
       "      <td>22100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dozens dead in possible gas bloating in syria ; regime denies allegation</td>\n",
       "      <td>dozens dead in possible gas attack in syria ; regime denies allegation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>6524</td>\n",
       "      <td>How Trump Just Made &lt;America/&gt; Less Safe</td>\n",
       "      <td>Pilates</td>\n",
       "      <td>11110</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>how trump just made pilates less safe</td>\n",
       "      <td>how trump just made america less safe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>7614</td>\n",
       "      <td>Trump 's 2nd Nominee for &lt;Army/&gt; Secretary Withdraws</td>\n",
       "      <td>Class</td>\n",
       "      <td>22100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>trump 's 2nd nominee for class secretary withdraws</td>\n",
       "      <td>trump 's 2nd nominee for army secretary withdraws</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>12786</td>\n",
       "      <td>The GOP just ca n’t &lt;escape/&gt; the ’80s</td>\n",
       "      <td>remember</td>\n",
       "      <td>33100</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>the gop just ca n’t remember the ’ 80s</td>\n",
       "      <td>the gop just ca n’t escape the ’ 80s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>14458</td>\n",
       "      <td>Mississippi law endorses anti-LGBT bias , attorneys &lt;argue/&gt;</td>\n",
       "      <td>confused</td>\n",
       "      <td>11100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mississippi law endorses anti - lgbt bias , attorneys confused</td>\n",
       "      <td>mississippi law endorses anti - lgbt bias , attorneys argue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>14549</td>\n",
       "      <td>' Chibok &lt;girls/&gt; ' reunited with families</td>\n",
       "      <td>salamis</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>chibok salamis reunited with families</td>\n",
       "      <td>chibok girls reunited with families</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>9469</td>\n",
       "      <td>Bill aiming to &lt;protect/&gt; Christians , other minority groups in Pakistan may soon be law</td>\n",
       "      <td>marry</td>\n",
       "      <td>21100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bill aiming to marry christians , other minority groups in pakistan may soon be law</td>\n",
       "      <td>bill aiming to protect christians , other minority groups in pakistan may soon be law</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2357</td>\n",
       "      <td>Pulled Over in a Rental Car , With &lt;Heroin/&gt; in the Trunk</td>\n",
       "      <td>Junk</td>\n",
       "      <td>22211</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>pulled over in a rental car , with junk in the trunk</td>\n",
       "      <td>pulled over in a rental car , with heroin in the trunk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>9653</td>\n",
       "      <td>US &lt;diplomat/&gt; forced to leave New Zealand after being involved in ' serious criminal incident '</td>\n",
       "      <td>president</td>\n",
       "      <td>32110</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>us president forced to leave new zealand after being involved in serious criminal incident</td>\n",
       "      <td>us diplomat forced to leave new zealand after being involved in serious criminal incident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>6822</td>\n",
       "      <td>Erdogan Rejects Arab Demands ; Turkish &lt;Troops/&gt; Stay in Qatar</td>\n",
       "      <td>Turkeys</td>\n",
       "      <td>22110</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>erdogan rejects arab demands ; turkish turkeys stay in qatar</td>\n",
       "      <td>erdogan rejects arab demands ; turkish troops stay in qatar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>8552</td>\n",
       "      <td>Mark Cuban Wants Constitution Changed to Make &lt;Health/&gt; Care a ‘ Right ’</td>\n",
       "      <td>eyebrow</td>\n",
       "      <td>22211</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mark cuban wants constitution changed to make eyebrow care a right ’</td>\n",
       "      <td>mark cuban wants constitution changed to make health care a right ’</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1415</td>\n",
       "      <td>Russian Trolls Would Love the ' Honest &lt;Ads/&gt; Act '</td>\n",
       "      <td>hotdogs</td>\n",
       "      <td>21110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>russian trolls would love the honest hotdogs act</td>\n",
       "      <td>russian trolls would love the honest ads act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>14113</td>\n",
       "      <td>Questions about Trump &lt;overwhelm/&gt; Republican Sen. Chuck Grassley 's event in Iowa</td>\n",
       "      <td>stupefy</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>questions about trump stupefy republican sen. chuck grassley 's event in iowa</td>\n",
       "      <td>questions about trump overwhelm republican sen. chuck grassley 's event in iowa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>10792</td>\n",
       "      <td>$ 2.7 billion Christmas &lt;lottery/&gt; in Spain [ Video ]</td>\n",
       "      <td>cookies</td>\n",
       "      <td>21110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>$ 2.7 billion christmas cookies in spain [ video ]</td>\n",
       "      <td>$ 2.7 billion christmas lottery in spain [ video ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>8475</td>\n",
       "      <td>US imposes metal tariffs on key &lt;allies/&gt;</td>\n",
       "      <td>holes</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>us imposes metal tariffs on key holes</td>\n",
       "      <td>us imposes metal tariffs on key allies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>14282</td>\n",
       "      <td>What we learned from enduring a week-long news cycle about &lt;Alex Jones/&gt;</td>\n",
       "      <td>pudding</td>\n",
       "      <td>22111</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>what we learned from enduring a week - long news cycle about pudding</td>\n",
       "      <td>what we learned from enduring a week - long news cycle about alex jones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>12583</td>\n",
       "      <td>Oregon : 20-Year-Old Sues Kroger for &lt;Refusing/&gt; to Sell Him Shotgun Shells</td>\n",
       "      <td>trying</td>\n",
       "      <td>22100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>oregon : 20-year - old sues kroger for trying to sell him shotgun shells</td>\n",
       "      <td>oregon : 20-year - old sues kroger for refusing to sell him shotgun shells</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>11124</td>\n",
       "      <td>If America is Great Again , Why Is the &lt;Dollar/&gt; Slowly Sinking ?</td>\n",
       "      <td>intelligence</td>\n",
       "      <td>22210</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>if america is great again , why is the intelligence slowly sinking ?</td>\n",
       "      <td>if america is great again , why is the dollar slowly sinking ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>2426</td>\n",
       "      <td>&lt;Roseanne Barr/&gt; quits Twitter after offending with statements about former Obama aide Valerie Jarrett , Chelsea Clinton</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>3211100000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>everyone quits twitter after offending with statements about former obama aide valerie jarrett , chelsea clinton</td>\n",
       "      <td>roseanne barr quits twitter after offending with statements about former obama aide valerie jarrett , chelsea clinton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>9662</td>\n",
       "      <td>Trump avoids pointing to Saudis ’ human &lt;rights/&gt; failings</td>\n",
       "      <td>pyramid</td>\n",
       "      <td>32110</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>trump avoids pointing to saudis ’ human pyramid failings</td>\n",
       "      <td>trump avoids pointing to saudis ’ human rights failings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>7723</td>\n",
       "      <td>An American &lt;Journalist/&gt; Is Facing A Felony Trial This Week — In The United States</td>\n",
       "      <td>clown</td>\n",
       "      <td>22000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>an american clown is facing a felony trial this week — in the united states</td>\n",
       "      <td>an american journalist is facing a felony trial this week — in the united states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>6089</td>\n",
       "      <td>4 &lt;soldiers/&gt; killed in Nagorno-Karabakh fighting : Officials</td>\n",
       "      <td>pizzas</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4 pizzas killed in nagorno - karabakh fighting : officials</td>\n",
       "      <td>4 soldiers killed in nagorno - karabakh fighting : officials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>8345</td>\n",
       "      <td>Italian &lt;President/&gt; Blocks Eurosceptic Coalition Govt</td>\n",
       "      <td>dog</td>\n",
       "      <td>21000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>italian dog blocks eurosceptic coalition govt</td>\n",
       "      <td>italian president blocks eurosceptic coalition govt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>2372</td>\n",
       "      <td>Canada 's Trudeau decides not to &lt;poke/&gt; U.S. ' grizzly bear ' for now</td>\n",
       "      <td>tickle</td>\n",
       "      <td>31111</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>canada 's trudeau decides not to tickle u.s. grizzly bear for now</td>\n",
       "      <td>canada 's trudeau decides not to poke u.s. grizzly bear for now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>11433</td>\n",
       "      <td>Lebanon LGBT scene empowered despite &lt;crackdown/&gt;</td>\n",
       "      <td>carnival</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>lebanon lgbt scene empowered despite carnival</td>\n",
       "      <td>lebanon lgbt scene empowered despite crackdown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>4026</td>\n",
       "      <td>Paul Manafort spokesman &lt;responds/&gt; to wiretapping report</td>\n",
       "      <td>dances</td>\n",
       "      <td>21100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>paul manafort spokesman dances to wiretapping report</td>\n",
       "      <td>paul manafort spokesman responds to wiretapping report</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>10483</td>\n",
       "      <td>When will Donald Trump and Kim Jong-un &lt;meet/&gt; and what will they discuss ?</td>\n",
       "      <td>tango</td>\n",
       "      <td>32110</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>when will donald trump and kim jong - un tango and what will they discuss ?</td>\n",
       "      <td>when will donald trump and kim jong - un meet and what will they discuss ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>11197</td>\n",
       "      <td>France , U.S. committed to wiping out &lt;Islamic State/&gt;</td>\n",
       "      <td>boogers</td>\n",
       "      <td>11100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>france , u.s. committed to wiping out boogers</td>\n",
       "      <td>france , u.s. committed to wiping out islamic state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>3833</td>\n",
       "      <td>Bill Kristol was once the voice of the Republican Party . Now he 's one of &lt;Trump/&gt; 's biggest opponents</td>\n",
       "      <td>voice</td>\n",
       "      <td>11100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bill kristol was once the voice of the republican party . now he 's one of voice 's biggest opponents</td>\n",
       "      <td>bill kristol was once the voice of the republican party . now he 's one of trump 's biggest opponents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>10636</td>\n",
       "      <td>TSA tightens electronics screening for domestic &lt;flights/&gt;</td>\n",
       "      <td>beers</td>\n",
       "      <td>11111</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>tsa tightens electronics screening for domestic beers</td>\n",
       "      <td>tsa tightens electronics screening for domestic flights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>13768</td>\n",
       "      <td>South Korea conducts &lt;missile/&gt; drill after North Korea nuclear test rattles globe</td>\n",
       "      <td>fire</td>\n",
       "      <td>11000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>south korea conducts fire drill after north korea nuclear test rattles globe</td>\n",
       "      <td>south korea conducts missile drill after north korea nuclear test rattles globe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>13019</td>\n",
       "      <td>Newly released Howard Stern Show tapes feature Donald Trump &lt;admitting/&gt; to psychological problems</td>\n",
       "      <td>aspiring</td>\n",
       "      <td>32100</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>newly released howard stern show tapes feature donald trump aspiring to psychological problems</td>\n",
       "      <td>newly released howard stern show tapes feature donald trump admitting to psychological problems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>13757</td>\n",
       "      <td>Trump consults NRA and Congress as he ponders gun &lt;policy/&gt;</td>\n",
       "      <td>purchase</td>\n",
       "      <td>32100</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>trump consults nra and congress as he ponders gun purchase</td>\n",
       "      <td>trump consults nra and congress as he ponders gun policy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>5732</td>\n",
       "      <td>Fox 's James Murdoch rebukes &lt;Trump/&gt; over Charlottesville</td>\n",
       "      <td>grits</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>fox 's james murdoch rebukes grits over charlottesville</td>\n",
       "      <td>fox 's james murdoch rebukes trump over charlottesville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>3218</td>\n",
       "      <td>Facebook defends &lt;advertising/&gt; ' principles ' after Russia , discrimination</td>\n",
       "      <td>kindergarten</td>\n",
       "      <td>22111</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>facebook defends kindergarten principles after russia , discrimination</td>\n",
       "      <td>facebook defends advertising principles after russia , discrimination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>13489</td>\n",
       "      <td>Meet the wealthy &lt;donors/&gt; pouring millions into the 2018 elections</td>\n",
       "      <td>sadists</td>\n",
       "      <td>11100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>meet the wealthy sadists pouring millions into the 2018 elections</td>\n",
       "      <td>meet the wealthy donors pouring millions into the 2018 elections</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>11660</td>\n",
       "      <td>Jared Kushner is the Real &lt;President/&gt;</td>\n",
       "      <td>Enemy</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>jared kushner is the real enemy</td>\n",
       "      <td>jared kushner is the real president</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>11614</td>\n",
       "      <td>Deputy FBI Director McCabe &lt;steps/&gt; down</td>\n",
       "      <td>boogies</td>\n",
       "      <td>33200</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>deputy fbi director mccabe boogies down</td>\n",
       "      <td>deputy fbi director mccabe steps down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>3274</td>\n",
       "      <td>Kelly wo n't commit to defending DACA in &lt;court/&gt;</td>\n",
       "      <td>space</td>\n",
       "      <td>33100</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>kelly wo n't commit to defending daca in space</td>\n",
       "      <td>kelly wo n't commit to defending daca in court</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>6953</td>\n",
       "      <td>House GOP gives Trump leeway over whether to block Schiff &lt;memo/&gt;</td>\n",
       "      <td>goal</td>\n",
       "      <td>32100</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>house gop gives trump leeway over whether to block schiff goal</td>\n",
       "      <td>house gop gives trump leeway over whether to block schiff memo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>13443</td>\n",
       "      <td>Rand Paul : Saudi Arabia ’s Role in Backing &lt;Terrorism/&gt; Raises Concerns with $ 100 Billion Arms Deal</td>\n",
       "      <td>Turpentine</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>rand paul : saudi arabia ’s role in backing turpentine raises concerns with $ 100 billion arms deal</td>\n",
       "      <td>rand paul : saudi arabia ’s role in backing terrorism raises concerns with $ 100 billion arms deal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>7008</td>\n",
       "      <td>Las Vegas &lt;professor/&gt; tells students Donald Trump incites violence after mass shooting</td>\n",
       "      <td>casino</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>las vegas casino tells students donald trump incites violence after mass shooting</td>\n",
       "      <td>las vegas professor tells students donald trump incites violence after mass shooting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>13131</td>\n",
       "      <td>The legal battle over Trump ’s &lt;immigration/&gt; ban , explained</td>\n",
       "      <td>happiness</td>\n",
       "      <td>33111</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>the legal battle over trump ’s happiness ban , explained</td>\n",
       "      <td>the legal battle over trump ’s immigration ban , explained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>8813</td>\n",
       "      <td>Republicans &lt;unveil/&gt; harder-line fix for DACA</td>\n",
       "      <td>destroy</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>republicans destroy harder - line fix for daca</td>\n",
       "      <td>republicans unveil harder - line fix for daca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>10022</td>\n",
       "      <td>Trump has the upper hand in North Korea &lt;talks/&gt;</td>\n",
       "      <td>handshake</td>\n",
       "      <td>21100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>trump has the upper hand in north korea handshake</td>\n",
       "      <td>trump has the upper hand in north korea talks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>3795</td>\n",
       "      <td>Brazil 's Temer accused of passive &lt;corruption/&gt; by police</td>\n",
       "      <td>aggressiveness</td>\n",
       "      <td>32000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>brazil 's temer accused of passive aggressiveness by police</td>\n",
       "      <td>brazil 's temer accused of passive corruption by police</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>8704</td>\n",
       "      <td>A closer look at Trump ’s potential Supreme &lt;Court/&gt; nominees</td>\n",
       "      <td>Music</td>\n",
       "      <td>11000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a closer look at trump ’s potential supreme music nominees</td>\n",
       "      <td>a closer look at trump ’s potential supreme court nominees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>2434</td>\n",
       "      <td>The Koch Brothers ’ most loyal &lt;servants/&gt; are serving in Donald Trump ’s White House</td>\n",
       "      <td>paychecks</td>\n",
       "      <td>11000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>the koch brothers ’ most loyal paychecks are serving in donald trump ’s white house</td>\n",
       "      <td>the koch brothers ’ most loyal servants are serving in donald trump ’s white house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>2961</td>\n",
       "      <td>Trump meets with Mnuchin in ' first stages ' of &lt;tax/&gt; reform planning</td>\n",
       "      <td>barbershop</td>\n",
       "      <td>22210</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>trump meets with mnuchin in first stages of barbershop reform planning</td>\n",
       "      <td>trump meets with mnuchin in first stages of tax reform planning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>7453</td>\n",
       "      <td>Affirmative-action hypocrisy : Foes hope to use Asian-Americans to &lt;attack/&gt; racial diversity on campus</td>\n",
       "      <td>hunt</td>\n",
       "      <td>21000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>affirmative - action hypocrisy : foes hope to use asian - americans to hunt racial diversity on campus</td>\n",
       "      <td>affirmative - action hypocrisy : foes hope to use asian - americans to attack racial diversity on campus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>11688</td>\n",
       "      <td>Texas authorities found the body of a small &lt;child/&gt; whilst searching for a missing 3-year-old</td>\n",
       "      <td>bird</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>texas authorities found the body of a small bird whilst searching for a missing 3-year - old</td>\n",
       "      <td>texas authorities found the body of a small child whilst searching for a missing 3-year - old</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>827</td>\n",
       "      <td>New Orleans takes down 1st of 4 Confederate &lt;statues/&gt;</td>\n",
       "      <td>birds</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>new orleans takes down 1st of 4 confederate birds</td>\n",
       "      <td>new orleans takes down 1st of 4 confederate statues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>11320</td>\n",
       "      <td>Steve King Warns Trump : DACA Illegal Aliens Can not Be Legalized ‘ Without Sacrificing the &lt;Rule/&gt; of Law ’</td>\n",
       "      <td>seesaw</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>steve king warns trump : daca illegal aliens can not be legalized without sacrificing the seesaw of law ’</td>\n",
       "      <td>steve king warns trump : daca illegal aliens can not be legalized without sacrificing the rule of law ’</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>2802</td>\n",
       "      <td>Trump invites Coast Guard members to West Palm Beach golf &lt;club/&gt;</td>\n",
       "      <td>ball</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>trump invites coast guard members to west palm beach golf ball</td>\n",
       "      <td>trump invites coast guard members to west palm beach golf club</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>1391</td>\n",
       "      <td>US suspects Niger villager &lt;betrayed/&gt; Army troops</td>\n",
       "      <td>scared</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>us suspects niger villager scared army troops</td>\n",
       "      <td>us suspects niger villager betrayed army troops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>11967</td>\n",
       "      <td>5 takeaways from Alabama 's startling special &lt;election/&gt;</td>\n",
       "      <td>potato</td>\n",
       "      <td>21100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5 takeaways from alabama 's startling special potato</td>\n",
       "      <td>5 takeaways from alabama 's startling special election</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>7780</td>\n",
       "      <td>This Is n't ' Another Watergate ' But It Plays As One On TV – And On &lt;Twitter/&gt;</td>\n",
       "      <td>Vaudeville</td>\n",
       "      <td>11000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>this is n't another watergate but it plays as one on tv – and on vaudeville</td>\n",
       "      <td>this is n't another watergate but it plays as one on tv – and on twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>4340</td>\n",
       "      <td>Former Obama officials are defending the White House doctor as he takes heat for saying Trump is in ' excellent ' &lt;health/&gt;</td>\n",
       "      <td>company</td>\n",
       "      <td>21000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>former obama officials are defending the white house doctor as he takes heat for saying trump is in excellent company</td>\n",
       "      <td>former obama officials are defending the white house doctor as he takes heat for saying trump is in excellent health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>8891</td>\n",
       "      <td>If America is Great Again , Why Is the &lt;Dollar/&gt; Slowly Sinking ?</td>\n",
       "      <td>continent</td>\n",
       "      <td>32100</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>if america is great again , why is the continent slowly sinking ?</td>\n",
       "      <td>if america is great again , why is the dollar slowly sinking ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>2857</td>\n",
       "      <td>Fox News guest offensively slams &lt;John McCain/&gt; to claim torture works</td>\n",
       "      <td>poetry</td>\n",
       "      <td>32100</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>fox news guest offensively slams poetry to claim torture works</td>\n",
       "      <td>fox news guest offensively slams john mccain to claim torture works</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>5116</td>\n",
       "      <td>Trump border wall : Texans receiving letters about their &lt;land/&gt;</td>\n",
       "      <td>barbecue</td>\n",
       "      <td>32222</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>trump border wall : texans receiving letters about their barbecue</td>\n",
       "      <td>trump border wall : texans receiving letters about their land</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>6487</td>\n",
       "      <td>Not even Trump can &lt;control/&gt; the GOP base</td>\n",
       "      <td>Afford</td>\n",
       "      <td>22100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>not even trump can afford the gop base</td>\n",
       "      <td>not even trump can control the gop base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>8735</td>\n",
       "      <td>Spicer defends Trump : &lt;Issues/&gt; are ' evolving towards the president 's position '</td>\n",
       "      <td>Aliens</td>\n",
       "      <td>22111</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>spicer defends trump : aliens are evolving towards the president 's position</td>\n",
       "      <td>spicer defends trump : issues are evolving towards the president 's position</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>4479</td>\n",
       "      <td>California Republican Rep. Ed Royce wo n't seek &lt;reelection/&gt; , creating bigger opening for Democrats</td>\n",
       "      <td>dessert</td>\n",
       "      <td>22111</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>california republican rep. ed royce wo n't seek dessert , creating bigger opening for democrats</td>\n",
       "      <td>california republican rep. ed royce wo n't seek reelection , creating bigger opening for democrats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>566</td>\n",
       "      <td>London Hit By Suspected &lt;Terror/&gt; Attack Days Before Election , PM Says</td>\n",
       "      <td>asthma</td>\n",
       "      <td>31000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>london hit by suspected asthma attack days before election , pm says</td>\n",
       "      <td>london hit by suspected terror attack days before election , pm says</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>11849</td>\n",
       "      <td>Massachusetts city council passes resolution calling for Donald Trump 's &lt;impeachment/&gt;</td>\n",
       "      <td>IQ</td>\n",
       "      <td>21111</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>massachusetts city council passes resolution calling for donald trump 's iq</td>\n",
       "      <td>massachusetts city council passes resolution calling for donald trump 's impeachment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>13650</td>\n",
       "      <td>U.S. cyber &lt;bill/&gt; would shift power away from spy agency</td>\n",
       "      <td>Robots</td>\n",
       "      <td>22110</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>u.s. cyber robots would shift power away from spy agency</td>\n",
       "      <td>u.s. cyber bill would shift power away from spy agency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>10024</td>\n",
       "      <td>Trump &lt;releases/&gt; some 2005 tax info ahead of Rachel Maddow report</td>\n",
       "      <td>shreds</td>\n",
       "      <td>32200</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>trump shreds some 2005 tax info ahead of rachel maddow report</td>\n",
       "      <td>trump releases some 2005 tax info ahead of rachel maddow report</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>6026</td>\n",
       "      <td>Russian spy : &lt;police officer/&gt; left seriously ill by attack named as Sergeant Nick Bailey</td>\n",
       "      <td>sable</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>russian spy : sable left seriously ill by attack named as sergeant nick bailey</td>\n",
       "      <td>russian spy : police officer left seriously ill by attack named as sergeant nick bailey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>13001</td>\n",
       "      <td>Almost No One Likes The New GOP &lt;Health/&gt; Care Bill | The Huffington Post</td>\n",
       "      <td>mascara</td>\n",
       "      <td>31000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>almost no one likes the new gop mascara care bill | the huffington post</td>\n",
       "      <td>almost no one likes the new gop health care bill | the huffington post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>8947</td>\n",
       "      <td>Trump to Dems : Of course I colluded , big &lt;deal/&gt; ! I fuck my daughters too</td>\n",
       "      <td>time</td>\n",
       "      <td>21000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>trump to dems : of course i colluded , big time ! i fuck my daughters too</td>\n",
       "      <td>trump to dems : of course i colluded , big deal ! i fuck my daughters too</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>12546</td>\n",
       "      <td>Trump goes easy on slaughterhouse exec who employed hundreds of illegal &lt;workers/&gt;</td>\n",
       "      <td>cupcakes</td>\n",
       "      <td>21100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>trump goes easy on slaughterhouse exec who employed hundreds of illegal cupcakes</td>\n",
       "      <td>trump goes easy on slaughterhouse exec who employed hundreds of illegal workers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>11016</td>\n",
       "      <td>How Steve Bannon &lt;became/&gt; the face of a political movement with roots in Los Angeles</td>\n",
       "      <td>slapped</td>\n",
       "      <td>21100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>how steve bannon slapped the face of a political movement with roots in los angeles</td>\n",
       "      <td>how steve bannon became the face of a political movement with roots in los angeles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>12236</td>\n",
       "      <td>FBI Deputy Director Andrew McCabe reportedly felt pressured to &lt;leave/&gt; by Director Christopher Wray</td>\n",
       "      <td>dance</td>\n",
       "      <td>2221111000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>fbi deputy director andrew mccabe reportedly felt pressured to dance by director christopher wray</td>\n",
       "      <td>fbi deputy director andrew mccabe reportedly felt pressured to leave by director christopher wray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>4535</td>\n",
       "      <td>Markets Right Now : Mideast &lt;markets/&gt; suffer modest drop</td>\n",
       "      <td>puppies</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>markets right now : mideast puppies suffer modest drop</td>\n",
       "      <td>markets right now : mideast markets suffer modest drop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>4087</td>\n",
       "      <td>The Nunes memo , explained with &lt;diagrams/&gt;</td>\n",
       "      <td>puppets</td>\n",
       "      <td>33211</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>the nunes memo , explained with puppets</td>\n",
       "      <td>the nunes memo , explained with diagrams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>3719</td>\n",
       "      <td>Trump says he 'll allow Japan , South Korea to buy more military &lt;equipment/&gt; from the U.S.</td>\n",
       "      <td>pornography</td>\n",
       "      <td>32220</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>trump says he 'll allow japan , south korea to buy more military pornography from the u.s.</td>\n",
       "      <td>trump says he 'll allow japan , south korea to buy more military equipment from the u.s.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>1787</td>\n",
       "      <td>Former presidents raise $ 31 million for &lt;hurricane/&gt; relief fund</td>\n",
       "      <td>president</td>\n",
       "      <td>22210</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>former presidents raise $ 31 million for president relief fund</td>\n",
       "      <td>former presidents raise $ 31 million for hurricane relief fund</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>10559</td>\n",
       "      <td>President Trump ’s ‘ impulsive ’ &lt;problem/&gt;</td>\n",
       "      <td>tweeting</td>\n",
       "      <td>32100</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>president trump ’s impulsive ’ tweeting</td>\n",
       "      <td>president trump ’s impulsive ’ problem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>4282</td>\n",
       "      <td>Stocks close lower as Trump &lt;says/&gt; China trade talks may not be successful</td>\n",
       "      <td>mocking</td>\n",
       "      <td>11100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>stocks close lower as trump mocking china trade talks may not be successful</td>\n",
       "      <td>stocks close lower as trump says china trade talks may not be successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>192</td>\n",
       "      <td>Britain First leaders found guilty of anti-Muslim &lt;hate/&gt; crime</td>\n",
       "      <td>cupcake</td>\n",
       "      <td>22110</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>britain first leaders found guilty of anti - muslim cupcake crime</td>\n",
       "      <td>britain first leaders found guilty of anti - muslim hate crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>9146</td>\n",
       "      <td>Trump Says New York Suspect ’s &lt;Visa/&gt; Was a ‘ Chuck Schumer Beauty ’</td>\n",
       "      <td>toupee</td>\n",
       "      <td>32211</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>trump says new york suspect ’s toupee was a chuck schumer beauty ’</td>\n",
       "      <td>trump says new york suspect ’s visa was a chuck schumer beauty ’</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>13044</td>\n",
       "      <td>Catholic priest caught driving 13-year-old &lt;girl/&gt; to motel after paying 16-year-old pimp</td>\n",
       "      <td>car</td>\n",
       "      <td>21110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>catholic priest caught driving 13-year - old car to motel after paying 16-year - old pimp</td>\n",
       "      <td>catholic priest caught driving 13-year - old girl to motel after paying 16-year - old pimp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>11468</td>\n",
       "      <td>Can Democrat Doug Jones &lt;pull/&gt; off an upset in Alabama ?</td>\n",
       "      <td>wiggle</td>\n",
       "      <td>21000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>can democrat doug jones wiggle off an upset in alabama ?</td>\n",
       "      <td>can democrat doug jones pull off an upset in alabama ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>6747</td>\n",
       "      <td>Revised UK child sexual ' consent ' rules provoke &lt;backlash/&gt;</td>\n",
       "      <td>applause</td>\n",
       "      <td>11000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>revised uk child sexual consent rules provoke applause</td>\n",
       "      <td>revised uk child sexual consent rules provoke backlash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>10883</td>\n",
       "      <td>How Kim Jong Un ‘ Baited ’ &lt;Trump/&gt; Into Canceling The North Korea Summit</td>\n",
       "      <td>fish</td>\n",
       "      <td>21100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>how kim jong un baited ’ fish into canceling the north korea summit</td>\n",
       "      <td>how kim jong un baited ’ trump into canceling the north korea summit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>2661</td>\n",
       "      <td>U.S. Secretary of State Mike Pompeo says ' sonic attack ' in China similar to reported &lt;Cuba/&gt; incident</td>\n",
       "      <td>hedgehog</td>\n",
       "      <td>31100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>u.s. secretary of state mike pompeo says sonic attack in china similar to reported hedgehog incident</td>\n",
       "      <td>u.s. secretary of state mike pompeo says sonic attack in china similar to reported cuba incident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>6553</td>\n",
       "      <td>Dick 's Sporting Goods no longer sells assault-style &lt;rifles/&gt; and raises age to 21</td>\n",
       "      <td>baseballs</td>\n",
       "      <td>11000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dick 's sporting goods no longer sells assault - style baseballs and raises age to 21</td>\n",
       "      <td>dick 's sporting goods no longer sells assault - style rifles and raises age to 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>6217</td>\n",
       "      <td>Iran Calls Trump 's &lt;Response/&gt; to Attacks ‘ Repugnant ’</td>\n",
       "      <td>Assist</td>\n",
       "      <td>11000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>iran calls trump 's assist to attacks repugnant ’</td>\n",
       "      <td>iran calls trump 's response to attacks repugnant ’</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>8825</td>\n",
       "      <td>Trump Promises Business Leaders Major Border Tax , &lt;Rule/&gt; Cuts</td>\n",
       "      <td>Finger</td>\n",
       "      <td>32211</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>trump promises business leaders major border tax , finger cuts</td>\n",
       "      <td>trump promises business leaders major border tax , rule cuts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  \\\n",
       "0   14530   \n",
       "1   13034   \n",
       "2   8731    \n",
       "3   76      \n",
       "4   6164    \n",
       "5   8832    \n",
       "6   12174   \n",
       "7   3731    \n",
       "8   6554    \n",
       "9   14191   \n",
       "10  14268   \n",
       "11  6524    \n",
       "12  7614    \n",
       "13  12786   \n",
       "14  14458   \n",
       "15  14549   \n",
       "16  9469    \n",
       "17  2357    \n",
       "18  9653    \n",
       "19  6822    \n",
       "20  8552    \n",
       "21  1415    \n",
       "22  14113   \n",
       "23  10792   \n",
       "24  8475    \n",
       "25  14282   \n",
       "26  12583   \n",
       "27  11124   \n",
       "28  2426    \n",
       "29  9662    \n",
       "30  7723    \n",
       "31  6089    \n",
       "32  8345    \n",
       "33  2372    \n",
       "34  11433   \n",
       "35  4026    \n",
       "36  10483   \n",
       "37  11197   \n",
       "38  3833    \n",
       "39  10636   \n",
       "40  13768   \n",
       "41  13019   \n",
       "42  13757   \n",
       "43  5732    \n",
       "44  3218    \n",
       "45  13489   \n",
       "46  11660   \n",
       "47  11614   \n",
       "48  3274    \n",
       "49  6953    \n",
       "50  13443   \n",
       "51  7008    \n",
       "52  13131   \n",
       "53  8813    \n",
       "54  10022   \n",
       "55  3795    \n",
       "56  8704    \n",
       "57  2434    \n",
       "58  2961    \n",
       "59  7453    \n",
       "60  11688   \n",
       "61  827     \n",
       "62  11320   \n",
       "63  2802    \n",
       "64  1391    \n",
       "65  11967   \n",
       "66  7780    \n",
       "67  4340    \n",
       "68  8891    \n",
       "69  2857    \n",
       "70  5116    \n",
       "71  6487    \n",
       "72  8735    \n",
       "73  4479    \n",
       "74  566     \n",
       "75  11849   \n",
       "76  13650   \n",
       "77  10024   \n",
       "78  6026    \n",
       "79  13001   \n",
       "80  8947    \n",
       "81  12546   \n",
       "82  11016   \n",
       "83  12236   \n",
       "84  4535    \n",
       "85  4087    \n",
       "86  3719    \n",
       "87  1787    \n",
       "88  10559   \n",
       "89  4282    \n",
       "90  192     \n",
       "91  9146    \n",
       "92  13044   \n",
       "93  11468   \n",
       "94  6747    \n",
       "95  10883   \n",
       "96  2661    \n",
       "97  6553    \n",
       "98  6217    \n",
       "99  8825    \n",
       "\n",
       "                                                                                                                        original  \\\n",
       "0   France is ‘ hunting down its citizens who joined <Isis/> ’ without trial in Iraq                                               \n",
       "1   Pentagon claims 2,000 % increase in Russian trolls after <Syria/> strikes . What does that mean ?                              \n",
       "2   Iceland PM Calls Snap Vote as Pedophile Furor Crashes <Coalition/>                                                             \n",
       "3   In an apparent first , Iran and Israel <engage/> each other militarily                                                         \n",
       "4   Trump was told weeks ago that Flynn misled <Vice/> President .                                                                 \n",
       "5   All 22 <promises/> Trump made in his speech to Congress , in one chart                                                         \n",
       "6   New DOJ alert system will flag <crimes/> against police                                                                        \n",
       "7   As Someone Who Grew Up Among Fundamentalist <Christians/> In The US , I 'm Surprised Anyone 's Surprised About Roy Moore       \n",
       "8   Canadians may pay more taxes than Americans , but here 's what they get for their <money/>                                     \n",
       "9   Dutch minister resigns in drug baron <row/>                                                                                    \n",
       "10  Dozens dead in possible gas <attack/> in Syria ; regime denies allegation                                                      \n",
       "11  How Trump Just Made <America/> Less Safe                                                                                       \n",
       "12  Trump 's 2nd Nominee for <Army/> Secretary Withdraws                                                                           \n",
       "13  The GOP just ca n’t <escape/> the ’80s                                                                                         \n",
       "14  Mississippi law endorses anti-LGBT bias , attorneys <argue/>                                                                   \n",
       "15  ' Chibok <girls/> ' reunited with families                                                                                     \n",
       "16  Bill aiming to <protect/> Christians , other minority groups in Pakistan may soon be law                                       \n",
       "17  Pulled Over in a Rental Car , With <Heroin/> in the Trunk                                                                      \n",
       "18  US <diplomat/> forced to leave New Zealand after being involved in ' serious criminal incident '                               \n",
       "19  Erdogan Rejects Arab Demands ; Turkish <Troops/> Stay in Qatar                                                                 \n",
       "20  Mark Cuban Wants Constitution Changed to Make <Health/> Care a ‘ Right ’                                                       \n",
       "21  Russian Trolls Would Love the ' Honest <Ads/> Act '                                                                            \n",
       "22  Questions about Trump <overwhelm/> Republican Sen. Chuck Grassley 's event in Iowa                                             \n",
       "23  $ 2.7 billion Christmas <lottery/> in Spain [ Video ]                                                                          \n",
       "24  US imposes metal tariffs on key <allies/>                                                                                      \n",
       "25  What we learned from enduring a week-long news cycle about <Alex Jones/>                                                       \n",
       "26  Oregon : 20-Year-Old Sues Kroger for <Refusing/> to Sell Him Shotgun Shells                                                    \n",
       "27  If America is Great Again , Why Is the <Dollar/> Slowly Sinking ?                                                              \n",
       "28   <Roseanne Barr/> quits Twitter after offending with statements about former Obama aide Valerie Jarrett , Chelsea Clinton      \n",
       "29  Trump avoids pointing to Saudis ’ human <rights/> failings                                                                     \n",
       "30  An American <Journalist/> Is Facing A Felony Trial This Week — In The United States                                            \n",
       "31  4 <soldiers/> killed in Nagorno-Karabakh fighting : Officials                                                                  \n",
       "32  Italian <President/> Blocks Eurosceptic Coalition Govt                                                                         \n",
       "33  Canada 's Trudeau decides not to <poke/> U.S. ' grizzly bear ' for now                                                         \n",
       "34  Lebanon LGBT scene empowered despite <crackdown/>                                                                              \n",
       "35  Paul Manafort spokesman <responds/> to wiretapping report                                                                      \n",
       "36  When will Donald Trump and Kim Jong-un <meet/> and what will they discuss ?                                                    \n",
       "37  France , U.S. committed to wiping out <Islamic State/>                                                                         \n",
       "38  Bill Kristol was once the voice of the Republican Party . Now he 's one of <Trump/> 's biggest opponents                       \n",
       "39  TSA tightens electronics screening for domestic <flights/>                                                                     \n",
       "40  South Korea conducts <missile/> drill after North Korea nuclear test rattles globe                                             \n",
       "41  Newly released Howard Stern Show tapes feature Donald Trump <admitting/> to psychological problems                             \n",
       "42  Trump consults NRA and Congress as he ponders gun <policy/>                                                                    \n",
       "43  Fox 's James Murdoch rebukes <Trump/> over Charlottesville                                                                     \n",
       "44  Facebook defends <advertising/> ' principles ' after Russia , discrimination                                                   \n",
       "45  Meet the wealthy <donors/> pouring millions into the 2018 elections                                                            \n",
       "46  Jared Kushner is the Real <President/>                                                                                         \n",
       "47  Deputy FBI Director McCabe <steps/> down                                                                                       \n",
       "48  Kelly wo n't commit to defending DACA in <court/>                                                                              \n",
       "49  House GOP gives Trump leeway over whether to block Schiff <memo/>                                                              \n",
       "50  Rand Paul : Saudi Arabia ’s Role in Backing <Terrorism/> Raises Concerns with $ 100 Billion Arms Deal                          \n",
       "51  Las Vegas <professor/> tells students Donald Trump incites violence after mass shooting                                        \n",
       "52  The legal battle over Trump ’s <immigration/> ban , explained                                                                  \n",
       "53  Republicans <unveil/> harder-line fix for DACA                                                                                 \n",
       "54  Trump has the upper hand in North Korea <talks/>                                                                               \n",
       "55  Brazil 's Temer accused of passive <corruption/> by police                                                                     \n",
       "56  A closer look at Trump ’s potential Supreme <Court/> nominees                                                                  \n",
       "57  The Koch Brothers ’ most loyal <servants/> are serving in Donald Trump ’s White House                                          \n",
       "58  Trump meets with Mnuchin in ' first stages ' of <tax/> reform planning                                                         \n",
       "59  Affirmative-action hypocrisy : Foes hope to use Asian-Americans to <attack/> racial diversity on campus                        \n",
       "60  Texas authorities found the body of a small <child/> whilst searching for a missing 3-year-old                                 \n",
       "61  New Orleans takes down 1st of 4 Confederate <statues/>                                                                         \n",
       "62  Steve King Warns Trump : DACA Illegal Aliens Can not Be Legalized ‘ Without Sacrificing the <Rule/> of Law ’                   \n",
       "63  Trump invites Coast Guard members to West Palm Beach golf <club/>                                                              \n",
       "64  US suspects Niger villager <betrayed/> Army troops                                                                             \n",
       "65  5 takeaways from Alabama 's startling special <election/>                                                                      \n",
       "66  This Is n't ' Another Watergate ' But It Plays As One On TV – And On <Twitter/>                                                \n",
       "67  Former Obama officials are defending the White House doctor as he takes heat for saying Trump is in ' excellent ' <health/>    \n",
       "68  If America is Great Again , Why Is the <Dollar/> Slowly Sinking ?                                                              \n",
       "69  Fox News guest offensively slams <John McCain/> to claim torture works                                                         \n",
       "70  Trump border wall : Texans receiving letters about their <land/>                                                               \n",
       "71  Not even Trump can <control/> the GOP base                                                                                     \n",
       "72  Spicer defends Trump : <Issues/> are ' evolving towards the president 's position '                                            \n",
       "73  California Republican Rep. Ed Royce wo n't seek <reelection/> , creating bigger opening for Democrats                          \n",
       "74  London Hit By Suspected <Terror/> Attack Days Before Election , PM Says                                                        \n",
       "75  Massachusetts city council passes resolution calling for Donald Trump 's <impeachment/>                                        \n",
       "76  U.S. cyber <bill/> would shift power away from spy agency                                                                      \n",
       "77  Trump <releases/> some 2005 tax info ahead of Rachel Maddow report                                                             \n",
       "78  Russian spy : <police officer/> left seriously ill by attack named as Sergeant Nick Bailey                                     \n",
       "79  Almost No One Likes The New GOP <Health/> Care Bill | The Huffington Post                                                      \n",
       "80  Trump to Dems : Of course I colluded , big <deal/> ! I fuck my daughters too                                                   \n",
       "81  Trump goes easy on slaughterhouse exec who employed hundreds of illegal <workers/>                                             \n",
       "82  How Steve Bannon <became/> the face of a political movement with roots in Los Angeles                                          \n",
       "83  FBI Deputy Director Andrew McCabe reportedly felt pressured to <leave/> by Director Christopher Wray                           \n",
       "84  Markets Right Now : Mideast <markets/> suffer modest drop                                                                      \n",
       "85  The Nunes memo , explained with <diagrams/>                                                                                    \n",
       "86  Trump says he 'll allow Japan , South Korea to buy more military <equipment/> from the U.S.                                    \n",
       "87  Former presidents raise $ 31 million for <hurricane/> relief fund                                                              \n",
       "88  President Trump ’s ‘ impulsive ’ <problem/>                                                                                    \n",
       "89  Stocks close lower as Trump <says/> China trade talks may not be successful                                                    \n",
       "90  Britain First leaders found guilty of anti-Muslim <hate/> crime                                                                \n",
       "91  Trump Says New York Suspect ’s <Visa/> Was a ‘ Chuck Schumer Beauty ’                                                          \n",
       "92  Catholic priest caught driving 13-year-old <girl/> to motel after paying 16-year-old pimp                                      \n",
       "93  Can Democrat Doug Jones <pull/> off an upset in Alabama ?                                                                      \n",
       "94  Revised UK child sexual ' consent ' rules provoke <backlash/>                                                                  \n",
       "95  How Kim Jong Un ‘ Baited ’ <Trump/> Into Canceling The North Korea Summit                                                      \n",
       "96  U.S. Secretary of State Mike Pompeo says ' sonic attack ' in China similar to reported <Cuba/> incident                        \n",
       "97  Dick 's Sporting Goods no longer sells assault-style <rifles/> and raises age to 21                                            \n",
       "98  Iran Calls Trump 's <Response/> to Attacks ‘ Repugnant ’                                                                       \n",
       "99  Trump Promises Business Leaders Major Border Tax , <Rule/> Cuts                                                                \n",
       "\n",
       "              edit  \\\n",
       "0   twins            \n",
       "1   bowling          \n",
       "2   party            \n",
       "3   slap             \n",
       "4   school           \n",
       "5   sounds           \n",
       "6   laughter         \n",
       "7   morons           \n",
       "8   loonies          \n",
       "9   blow             \n",
       "10  bloating         \n",
       "11  Pilates          \n",
       "12  Class            \n",
       "13  remember         \n",
       "14  confused         \n",
       "15  salamis          \n",
       "16  marry            \n",
       "17  Junk             \n",
       "18  president        \n",
       "19  Turkeys          \n",
       "20  eyebrow          \n",
       "21  hotdogs          \n",
       "22  stupefy          \n",
       "23  cookies          \n",
       "24  holes            \n",
       "25  pudding          \n",
       "26  trying           \n",
       "27  intelligence     \n",
       "28  Everyone         \n",
       "29  pyramid          \n",
       "30  clown            \n",
       "31  pizzas           \n",
       "32  dog              \n",
       "33  tickle           \n",
       "34  carnival         \n",
       "35  dances           \n",
       "36  tango            \n",
       "37  boogers          \n",
       "38  voice            \n",
       "39  beers            \n",
       "40  fire             \n",
       "41  aspiring         \n",
       "42  purchase         \n",
       "43  grits            \n",
       "44  kindergarten     \n",
       "45  sadists          \n",
       "46  Enemy            \n",
       "47  boogies          \n",
       "48  space            \n",
       "49  goal             \n",
       "50  Turpentine       \n",
       "51  casino           \n",
       "52  happiness        \n",
       "53  destroy          \n",
       "54  handshake        \n",
       "55  aggressiveness   \n",
       "56  Music            \n",
       "57  paychecks        \n",
       "58  barbershop       \n",
       "59  hunt             \n",
       "60  bird             \n",
       "61  birds            \n",
       "62  seesaw           \n",
       "63  ball             \n",
       "64  scared           \n",
       "65  potato           \n",
       "66  Vaudeville       \n",
       "67  company          \n",
       "68  continent        \n",
       "69  poetry           \n",
       "70  barbecue         \n",
       "71  Afford           \n",
       "72  Aliens           \n",
       "73  dessert          \n",
       "74  asthma           \n",
       "75  IQ               \n",
       "76  Robots           \n",
       "77  shreds           \n",
       "78  sable            \n",
       "79  mascara          \n",
       "80  time             \n",
       "81  cupcakes         \n",
       "82  slapped          \n",
       "83  dance            \n",
       "84  puppies          \n",
       "85  puppets          \n",
       "86  pornography      \n",
       "87  president        \n",
       "88  tweeting         \n",
       "89  mocking          \n",
       "90  cupcake          \n",
       "91  toupee           \n",
       "92  car              \n",
       "93  wiggle           \n",
       "94  applause         \n",
       "95  fish             \n",
       "96  hedgehog         \n",
       "97  baseballs        \n",
       "98  Assist           \n",
       "99  Finger           \n",
       "\n",
       "        grades  \\\n",
       "0   10000        \n",
       "1   33110        \n",
       "2   22100        \n",
       "3   20000        \n",
       "4   0            \n",
       "5   22200        \n",
       "6   32100        \n",
       "7   21110        \n",
       "8   10000        \n",
       "9   0            \n",
       "10  22100        \n",
       "11  11110        \n",
       "12  22100        \n",
       "13  33100        \n",
       "14  11100        \n",
       "15  10000        \n",
       "16  21100        \n",
       "17  22211        \n",
       "18  32110        \n",
       "19  22110        \n",
       "20  22211        \n",
       "21  21110        \n",
       "22  20000        \n",
       "23  21110        \n",
       "24  10000        \n",
       "25  22111        \n",
       "26  22100        \n",
       "27  22210        \n",
       "28  3211100000   \n",
       "29  32110        \n",
       "30  22000        \n",
       "31  10000        \n",
       "32  21000        \n",
       "33  31111        \n",
       "34  10000        \n",
       "35  21100        \n",
       "36  32110        \n",
       "37  11100        \n",
       "38  11100        \n",
       "39  11111        \n",
       "40  11000        \n",
       "41  32100        \n",
       "42  32100        \n",
       "43  10000        \n",
       "44  22111        \n",
       "45  11100        \n",
       "46  0            \n",
       "47  33200        \n",
       "48  33100        \n",
       "49  32100        \n",
       "50  10000        \n",
       "51  0            \n",
       "52  33111        \n",
       "53  10000        \n",
       "54  21100        \n",
       "55  32000        \n",
       "56  11000        \n",
       "57  11000        \n",
       "58  22210        \n",
       "59  21000        \n",
       "60  10000        \n",
       "61  0            \n",
       "62  10000        \n",
       "63  20000        \n",
       "64  20000        \n",
       "65  21100        \n",
       "66  11000        \n",
       "67  21000        \n",
       "68  32100        \n",
       "69  32100        \n",
       "70  32222        \n",
       "71  22100        \n",
       "72  22111        \n",
       "73  22111        \n",
       "74  31000        \n",
       "75  21111        \n",
       "76  22110        \n",
       "77  32200        \n",
       "78  10000        \n",
       "79  31000        \n",
       "80  21000        \n",
       "81  21100        \n",
       "82  21100        \n",
       "83  2221111000   \n",
       "84  10000        \n",
       "85  33211        \n",
       "86  32220        \n",
       "87  22210        \n",
       "88  32100        \n",
       "89  11100        \n",
       "90  22110        \n",
       "91  32211        \n",
       "92  21110        \n",
       "93  21000        \n",
       "94  11000        \n",
       "95  21100        \n",
       "96  31100        \n",
       "97  11000        \n",
       "98  11000        \n",
       "99  32211        \n",
       "\n",
       "    meanGrade  \\\n",
       "0   0.2         \n",
       "1   1.6         \n",
       "2   1.0         \n",
       "3   0.4         \n",
       "4   0.0         \n",
       "5   1.2         \n",
       "6   1.2         \n",
       "7   1.0         \n",
       "8   0.2         \n",
       "9   0.0         \n",
       "10  1.0         \n",
       "11  0.8         \n",
       "12  1.0         \n",
       "13  1.4         \n",
       "14  0.6         \n",
       "15  0.2         \n",
       "16  0.8         \n",
       "17  1.6         \n",
       "18  1.4         \n",
       "19  1.2         \n",
       "20  1.6         \n",
       "21  1.0         \n",
       "22  0.4         \n",
       "23  1.0         \n",
       "24  0.2         \n",
       "25  1.4         \n",
       "26  1.0         \n",
       "27  1.4         \n",
       "28  0.8         \n",
       "29  1.4         \n",
       "30  0.8         \n",
       "31  0.2         \n",
       "32  0.6         \n",
       "33  1.4         \n",
       "34  0.2         \n",
       "35  0.8         \n",
       "36  1.4         \n",
       "37  0.6         \n",
       "38  0.6         \n",
       "39  1.0         \n",
       "40  0.4         \n",
       "41  1.2         \n",
       "42  1.2         \n",
       "43  0.2         \n",
       "44  1.4         \n",
       "45  0.6         \n",
       "46  0.0         \n",
       "47  1.6         \n",
       "48  1.4         \n",
       "49  1.2         \n",
       "50  0.2         \n",
       "51  0.0         \n",
       "52  1.8         \n",
       "53  0.2         \n",
       "54  0.8         \n",
       "55  1.0         \n",
       "56  0.4         \n",
       "57  0.4         \n",
       "58  1.4         \n",
       "59  0.6         \n",
       "60  0.2         \n",
       "61  0.0         \n",
       "62  0.2         \n",
       "63  0.4         \n",
       "64  0.4         \n",
       "65  0.8         \n",
       "66  0.4         \n",
       "67  0.6         \n",
       "68  1.2         \n",
       "69  1.2         \n",
       "70  2.2         \n",
       "71  1.0         \n",
       "72  1.4         \n",
       "73  1.4         \n",
       "74  0.8         \n",
       "75  1.2         \n",
       "76  1.2         \n",
       "77  1.4         \n",
       "78  0.2         \n",
       "79  0.8         \n",
       "80  0.6         \n",
       "81  0.8         \n",
       "82  0.8         \n",
       "83  1.0         \n",
       "84  0.2         \n",
       "85  2.0         \n",
       "86  1.8         \n",
       "87  1.4         \n",
       "88  1.2         \n",
       "89  0.6         \n",
       "90  1.2         \n",
       "91  1.8         \n",
       "92  1.0         \n",
       "93  0.6         \n",
       "94  0.4         \n",
       "95  0.8         \n",
       "96  1.0         \n",
       "97  0.4         \n",
       "98  0.4         \n",
       "99  1.8         \n",
       "\n",
       "    grade_round  \\\n",
       "0   0             \n",
       "1   2             \n",
       "2   1             \n",
       "3   0             \n",
       "4   0             \n",
       "5   1             \n",
       "6   1             \n",
       "7   1             \n",
       "8   0             \n",
       "9   0             \n",
       "10  1             \n",
       "11  1             \n",
       "12  1             \n",
       "13  1             \n",
       "14  1             \n",
       "15  0             \n",
       "16  1             \n",
       "17  2             \n",
       "18  1             \n",
       "19  1             \n",
       "20  2             \n",
       "21  1             \n",
       "22  0             \n",
       "23  1             \n",
       "24  0             \n",
       "25  1             \n",
       "26  1             \n",
       "27  1             \n",
       "28  1             \n",
       "29  1             \n",
       "30  1             \n",
       "31  0             \n",
       "32  1             \n",
       "33  1             \n",
       "34  0             \n",
       "35  1             \n",
       "36  1             \n",
       "37  1             \n",
       "38  1             \n",
       "39  1             \n",
       "40  0             \n",
       "41  1             \n",
       "42  1             \n",
       "43  0             \n",
       "44  1             \n",
       "45  1             \n",
       "46  0             \n",
       "47  2             \n",
       "48  1             \n",
       "49  1             \n",
       "50  0             \n",
       "51  0             \n",
       "52  2             \n",
       "53  0             \n",
       "54  1             \n",
       "55  1             \n",
       "56  0             \n",
       "57  0             \n",
       "58  1             \n",
       "59  1             \n",
       "60  0             \n",
       "61  0             \n",
       "62  0             \n",
       "63  0             \n",
       "64  0             \n",
       "65  1             \n",
       "66  0             \n",
       "67  1             \n",
       "68  1             \n",
       "69  1             \n",
       "70  2             \n",
       "71  1             \n",
       "72  1             \n",
       "73  1             \n",
       "74  1             \n",
       "75  1             \n",
       "76  1             \n",
       "77  1             \n",
       "78  0             \n",
       "79  1             \n",
       "80  1             \n",
       "81  1             \n",
       "82  1             \n",
       "83  1             \n",
       "84  0             \n",
       "85  2             \n",
       "86  2             \n",
       "87  1             \n",
       "88  1             \n",
       "89  1             \n",
       "90  1             \n",
       "91  2             \n",
       "92  1             \n",
       "93  1             \n",
       "94  0             \n",
       "95  1             \n",
       "96  1             \n",
       "97  0             \n",
       "98  0             \n",
       "99  2             \n",
       "\n",
       "    grades_0  \\\n",
       "0   1          \n",
       "1   3          \n",
       "2   2          \n",
       "3   2          \n",
       "4   0          \n",
       "5   2          \n",
       "6   3          \n",
       "7   2          \n",
       "8   1          \n",
       "9   0          \n",
       "10  2          \n",
       "11  1          \n",
       "12  2          \n",
       "13  3          \n",
       "14  1          \n",
       "15  1          \n",
       "16  2          \n",
       "17  2          \n",
       "18  3          \n",
       "19  2          \n",
       "20  2          \n",
       "21  2          \n",
       "22  2          \n",
       "23  2          \n",
       "24  1          \n",
       "25  2          \n",
       "26  2          \n",
       "27  2          \n",
       "28  3          \n",
       "29  3          \n",
       "30  2          \n",
       "31  1          \n",
       "32  2          \n",
       "33  3          \n",
       "34  1          \n",
       "35  2          \n",
       "36  3          \n",
       "37  1          \n",
       "38  1          \n",
       "39  1          \n",
       "40  1          \n",
       "41  3          \n",
       "42  3          \n",
       "43  1          \n",
       "44  2          \n",
       "45  1          \n",
       "46  0          \n",
       "47  3          \n",
       "48  3          \n",
       "49  3          \n",
       "50  1          \n",
       "51  0          \n",
       "52  3          \n",
       "53  1          \n",
       "54  2          \n",
       "55  3          \n",
       "56  1          \n",
       "57  1          \n",
       "58  2          \n",
       "59  2          \n",
       "60  1          \n",
       "61  0          \n",
       "62  1          \n",
       "63  2          \n",
       "64  2          \n",
       "65  2          \n",
       "66  1          \n",
       "67  2          \n",
       "68  3          \n",
       "69  3          \n",
       "70  3          \n",
       "71  2          \n",
       "72  2          \n",
       "73  2          \n",
       "74  3          \n",
       "75  2          \n",
       "76  2          \n",
       "77  3          \n",
       "78  1          \n",
       "79  3          \n",
       "80  2          \n",
       "81  2          \n",
       "82  2          \n",
       "83  2          \n",
       "84  1          \n",
       "85  3          \n",
       "86  3          \n",
       "87  2          \n",
       "88  3          \n",
       "89  1          \n",
       "90  2          \n",
       "91  3          \n",
       "92  2          \n",
       "93  2          \n",
       "94  1          \n",
       "95  2          \n",
       "96  3          \n",
       "97  1          \n",
       "98  1          \n",
       "99  3          \n",
       "\n",
       "    grades_1  \\\n",
       "0   0          \n",
       "1   3          \n",
       "2   2          \n",
       "3   0          \n",
       "4   0          \n",
       "5   2          \n",
       "6   2          \n",
       "7   1          \n",
       "8   0          \n",
       "9   0          \n",
       "10  2          \n",
       "11  1          \n",
       "12  2          \n",
       "13  3          \n",
       "14  1          \n",
       "15  0          \n",
       "16  1          \n",
       "17  2          \n",
       "18  2          \n",
       "19  2          \n",
       "20  2          \n",
       "21  1          \n",
       "22  0          \n",
       "23  1          \n",
       "24  0          \n",
       "25  2          \n",
       "26  2          \n",
       "27  2          \n",
       "28  2          \n",
       "29  2          \n",
       "30  2          \n",
       "31  0          \n",
       "32  1          \n",
       "33  1          \n",
       "34  0          \n",
       "35  1          \n",
       "36  2          \n",
       "37  1          \n",
       "38  1          \n",
       "39  1          \n",
       "40  1          \n",
       "41  2          \n",
       "42  2          \n",
       "43  0          \n",
       "44  2          \n",
       "45  1          \n",
       "46  0          \n",
       "47  3          \n",
       "48  3          \n",
       "49  2          \n",
       "50  0          \n",
       "51  0          \n",
       "52  3          \n",
       "53  0          \n",
       "54  1          \n",
       "55  2          \n",
       "56  1          \n",
       "57  1          \n",
       "58  2          \n",
       "59  1          \n",
       "60  0          \n",
       "61  0          \n",
       "62  0          \n",
       "63  0          \n",
       "64  0          \n",
       "65  1          \n",
       "66  1          \n",
       "67  1          \n",
       "68  2          \n",
       "69  2          \n",
       "70  2          \n",
       "71  2          \n",
       "72  2          \n",
       "73  2          \n",
       "74  1          \n",
       "75  1          \n",
       "76  2          \n",
       "77  2          \n",
       "78  0          \n",
       "79  1          \n",
       "80  1          \n",
       "81  1          \n",
       "82  1          \n",
       "83  2          \n",
       "84  0          \n",
       "85  3          \n",
       "86  2          \n",
       "87  2          \n",
       "88  2          \n",
       "89  1          \n",
       "90  2          \n",
       "91  2          \n",
       "92  1          \n",
       "93  1          \n",
       "94  1          \n",
       "95  1          \n",
       "96  1          \n",
       "97  1          \n",
       "98  1          \n",
       "99  2          \n",
       "\n",
       "    grades_2  \\\n",
       "0   0          \n",
       "1   1          \n",
       "2   1          \n",
       "3   0          \n",
       "4   0          \n",
       "5   2          \n",
       "6   1          \n",
       "7   1          \n",
       "8   0          \n",
       "9   0          \n",
       "10  1          \n",
       "11  1          \n",
       "12  1          \n",
       "13  1          \n",
       "14  1          \n",
       "15  0          \n",
       "16  1          \n",
       "17  2          \n",
       "18  1          \n",
       "19  1          \n",
       "20  2          \n",
       "21  1          \n",
       "22  0          \n",
       "23  1          \n",
       "24  0          \n",
       "25  1          \n",
       "26  1          \n",
       "27  2          \n",
       "28  1          \n",
       "29  1          \n",
       "30  0          \n",
       "31  0          \n",
       "32  0          \n",
       "33  1          \n",
       "34  0          \n",
       "35  1          \n",
       "36  1          \n",
       "37  1          \n",
       "38  1          \n",
       "39  1          \n",
       "40  0          \n",
       "41  1          \n",
       "42  1          \n",
       "43  0          \n",
       "44  1          \n",
       "45  1          \n",
       "46  0          \n",
       "47  2          \n",
       "48  1          \n",
       "49  1          \n",
       "50  0          \n",
       "51  0          \n",
       "52  1          \n",
       "53  0          \n",
       "54  1          \n",
       "55  0          \n",
       "56  0          \n",
       "57  0          \n",
       "58  2          \n",
       "59  0          \n",
       "60  0          \n",
       "61  0          \n",
       "62  0          \n",
       "63  0          \n",
       "64  0          \n",
       "65  1          \n",
       "66  0          \n",
       "67  0          \n",
       "68  1          \n",
       "69  1          \n",
       "70  2          \n",
       "71  1          \n",
       "72  1          \n",
       "73  1          \n",
       "74  0          \n",
       "75  1          \n",
       "76  1          \n",
       "77  2          \n",
       "78  0          \n",
       "79  0          \n",
       "80  0          \n",
       "81  1          \n",
       "82  1          \n",
       "83  2          \n",
       "84  0          \n",
       "85  2          \n",
       "86  2          \n",
       "87  2          \n",
       "88  1          \n",
       "89  1          \n",
       "90  1          \n",
       "91  2          \n",
       "92  1          \n",
       "93  0          \n",
       "94  0          \n",
       "95  1          \n",
       "96  1          \n",
       "97  0          \n",
       "98  0          \n",
       "99  2          \n",
       "\n",
       "    grades_3  \\\n",
       "0   0          \n",
       "1   1          \n",
       "2   0          \n",
       "3   0          \n",
       "4   0          \n",
       "5   0          \n",
       "6   0          \n",
       "7   1          \n",
       "8   0          \n",
       "9   0          \n",
       "10  0          \n",
       "11  1          \n",
       "12  0          \n",
       "13  0          \n",
       "14  0          \n",
       "15  0          \n",
       "16  0          \n",
       "17  1          \n",
       "18  1          \n",
       "19  1          \n",
       "20  1          \n",
       "21  1          \n",
       "22  0          \n",
       "23  1          \n",
       "24  0          \n",
       "25  1          \n",
       "26  0          \n",
       "27  1          \n",
       "28  1          \n",
       "29  1          \n",
       "30  0          \n",
       "31  0          \n",
       "32  0          \n",
       "33  1          \n",
       "34  0          \n",
       "35  0          \n",
       "36  1          \n",
       "37  0          \n",
       "38  0          \n",
       "39  1          \n",
       "40  0          \n",
       "41  0          \n",
       "42  0          \n",
       "43  0          \n",
       "44  1          \n",
       "45  0          \n",
       "46  0          \n",
       "47  0          \n",
       "48  0          \n",
       "49  0          \n",
       "50  0          \n",
       "51  0          \n",
       "52  1          \n",
       "53  0          \n",
       "54  0          \n",
       "55  0          \n",
       "56  0          \n",
       "57  0          \n",
       "58  1          \n",
       "59  0          \n",
       "60  0          \n",
       "61  0          \n",
       "62  0          \n",
       "63  0          \n",
       "64  0          \n",
       "65  0          \n",
       "66  0          \n",
       "67  0          \n",
       "68  0          \n",
       "69  0          \n",
       "70  2          \n",
       "71  0          \n",
       "72  1          \n",
       "73  1          \n",
       "74  0          \n",
       "75  1          \n",
       "76  1          \n",
       "77  0          \n",
       "78  0          \n",
       "79  0          \n",
       "80  0          \n",
       "81  0          \n",
       "82  0          \n",
       "83  1          \n",
       "84  0          \n",
       "85  1          \n",
       "86  2          \n",
       "87  1          \n",
       "88  0          \n",
       "89  0          \n",
       "90  1          \n",
       "91  1          \n",
       "92  1          \n",
       "93  0          \n",
       "94  0          \n",
       "95  0          \n",
       "96  0          \n",
       "97  0          \n",
       "98  0          \n",
       "99  1          \n",
       "\n",
       "    grades_4  \\\n",
       "0   0          \n",
       "1   0          \n",
       "2   0          \n",
       "3   0          \n",
       "4   0          \n",
       "5   0          \n",
       "6   0          \n",
       "7   0          \n",
       "8   0          \n",
       "9   0          \n",
       "10  0          \n",
       "11  0          \n",
       "12  0          \n",
       "13  0          \n",
       "14  0          \n",
       "15  0          \n",
       "16  0          \n",
       "17  1          \n",
       "18  0          \n",
       "19  0          \n",
       "20  1          \n",
       "21  0          \n",
       "22  0          \n",
       "23  0          \n",
       "24  0          \n",
       "25  1          \n",
       "26  0          \n",
       "27  0          \n",
       "28  1          \n",
       "29  0          \n",
       "30  0          \n",
       "31  0          \n",
       "32  0          \n",
       "33  1          \n",
       "34  0          \n",
       "35  0          \n",
       "36  0          \n",
       "37  0          \n",
       "38  0          \n",
       "39  1          \n",
       "40  0          \n",
       "41  0          \n",
       "42  0          \n",
       "43  0          \n",
       "44  1          \n",
       "45  0          \n",
       "46  0          \n",
       "47  0          \n",
       "48  0          \n",
       "49  0          \n",
       "50  0          \n",
       "51  0          \n",
       "52  1          \n",
       "53  0          \n",
       "54  0          \n",
       "55  0          \n",
       "56  0          \n",
       "57  0          \n",
       "58  0          \n",
       "59  0          \n",
       "60  0          \n",
       "61  0          \n",
       "62  0          \n",
       "63  0          \n",
       "64  0          \n",
       "65  0          \n",
       "66  0          \n",
       "67  0          \n",
       "68  0          \n",
       "69  0          \n",
       "70  2          \n",
       "71  0          \n",
       "72  1          \n",
       "73  1          \n",
       "74  0          \n",
       "75  1          \n",
       "76  0          \n",
       "77  0          \n",
       "78  0          \n",
       "79  0          \n",
       "80  0          \n",
       "81  0          \n",
       "82  0          \n",
       "83  1          \n",
       "84  0          \n",
       "85  1          \n",
       "86  0          \n",
       "87  0          \n",
       "88  0          \n",
       "89  0          \n",
       "90  0          \n",
       "91  1          \n",
       "92  0          \n",
       "93  0          \n",
       "94  0          \n",
       "95  0          \n",
       "96  0          \n",
       "97  0          \n",
       "98  0          \n",
       "99  1          \n",
       "\n",
       "                                                                                                         edited_head_line  \\\n",
       "0   france is hunting down its citizens who joined twins ’ without trial in iraq                                            \n",
       "1   pentagon claims 2,000 % increase in russian trolls after bowling strikes . what does that mean ?                        \n",
       "2   iceland pm calls snap vote as pedophile furor crashes party                                                             \n",
       "3   in an apparent first , iran and israel slap each other militarily                                                       \n",
       "4   trump was told weeks ago that flynn misled school president .                                                           \n",
       "5   all 22 sounds trump made in his speech to congress , in one chart                                                       \n",
       "6   new doj alert system will flag laughter against police                                                                  \n",
       "7   as someone who grew up among fundamentalist morons in the us , i m surprised anyone 's surprised about roy moore        \n",
       "8   canadians may pay more taxes than americans , but here 's what they get for their loonies                               \n",
       "9   dutch minister resigns in drug baron blow                                                                               \n",
       "10  dozens dead in possible gas bloating in syria ; regime denies allegation                                                \n",
       "11  how trump just made pilates less safe                                                                                   \n",
       "12  trump 's 2nd nominee for class secretary withdraws                                                                      \n",
       "13  the gop just ca n’t remember the ’ 80s                                                                                  \n",
       "14  mississippi law endorses anti - lgbt bias , attorneys confused                                                          \n",
       "15  chibok salamis reunited with families                                                                                   \n",
       "16  bill aiming to marry christians , other minority groups in pakistan may soon be law                                     \n",
       "17  pulled over in a rental car , with junk in the trunk                                                                    \n",
       "18  us president forced to leave new zealand after being involved in serious criminal incident                              \n",
       "19  erdogan rejects arab demands ; turkish turkeys stay in qatar                                                            \n",
       "20  mark cuban wants constitution changed to make eyebrow care a right ’                                                    \n",
       "21  russian trolls would love the honest hotdogs act                                                                        \n",
       "22  questions about trump stupefy republican sen. chuck grassley 's event in iowa                                           \n",
       "23  $ 2.7 billion christmas cookies in spain [ video ]                                                                      \n",
       "24  us imposes metal tariffs on key holes                                                                                   \n",
       "25  what we learned from enduring a week - long news cycle about pudding                                                    \n",
       "26  oregon : 20-year - old sues kroger for trying to sell him shotgun shells                                                \n",
       "27  if america is great again , why is the intelligence slowly sinking ?                                                    \n",
       "28    everyone quits twitter after offending with statements about former obama aide valerie jarrett , chelsea clinton      \n",
       "29  trump avoids pointing to saudis ’ human pyramid failings                                                                \n",
       "30  an american clown is facing a felony trial this week — in the united states                                             \n",
       "31  4 pizzas killed in nagorno - karabakh fighting : officials                                                              \n",
       "32  italian dog blocks eurosceptic coalition govt                                                                           \n",
       "33  canada 's trudeau decides not to tickle u.s. grizzly bear for now                                                       \n",
       "34  lebanon lgbt scene empowered despite carnival                                                                           \n",
       "35  paul manafort spokesman dances to wiretapping report                                                                    \n",
       "36  when will donald trump and kim jong - un tango and what will they discuss ?                                             \n",
       "37  france , u.s. committed to wiping out boogers                                                                           \n",
       "38  bill kristol was once the voice of the republican party . now he 's one of voice 's biggest opponents                   \n",
       "39  tsa tightens electronics screening for domestic beers                                                                   \n",
       "40  south korea conducts fire drill after north korea nuclear test rattles globe                                            \n",
       "41  newly released howard stern show tapes feature donald trump aspiring to psychological problems                          \n",
       "42  trump consults nra and congress as he ponders gun purchase                                                              \n",
       "43  fox 's james murdoch rebukes grits over charlottesville                                                                 \n",
       "44  facebook defends kindergarten principles after russia , discrimination                                                  \n",
       "45  meet the wealthy sadists pouring millions into the 2018 elections                                                       \n",
       "46  jared kushner is the real enemy                                                                                         \n",
       "47  deputy fbi director mccabe boogies down                                                                                 \n",
       "48  kelly wo n't commit to defending daca in space                                                                          \n",
       "49  house gop gives trump leeway over whether to block schiff goal                                                          \n",
       "50  rand paul : saudi arabia ’s role in backing turpentine raises concerns with $ 100 billion arms deal                     \n",
       "51  las vegas casino tells students donald trump incites violence after mass shooting                                       \n",
       "52  the legal battle over trump ’s happiness ban , explained                                                                \n",
       "53  republicans destroy harder - line fix for daca                                                                          \n",
       "54  trump has the upper hand in north korea handshake                                                                       \n",
       "55  brazil 's temer accused of passive aggressiveness by police                                                             \n",
       "56  a closer look at trump ’s potential supreme music nominees                                                              \n",
       "57  the koch brothers ’ most loyal paychecks are serving in donald trump ’s white house                                     \n",
       "58  trump meets with mnuchin in first stages of barbershop reform planning                                                  \n",
       "59  affirmative - action hypocrisy : foes hope to use asian - americans to hunt racial diversity on campus                  \n",
       "60  texas authorities found the body of a small bird whilst searching for a missing 3-year - old                            \n",
       "61  new orleans takes down 1st of 4 confederate birds                                                                       \n",
       "62  steve king warns trump : daca illegal aliens can not be legalized without sacrificing the seesaw of law ’               \n",
       "63  trump invites coast guard members to west palm beach golf ball                                                          \n",
       "64  us suspects niger villager scared army troops                                                                           \n",
       "65  5 takeaways from alabama 's startling special potato                                                                    \n",
       "66  this is n't another watergate but it plays as one on tv – and on vaudeville                                             \n",
       "67  former obama officials are defending the white house doctor as he takes heat for saying trump is in excellent company   \n",
       "68  if america is great again , why is the continent slowly sinking ?                                                       \n",
       "69  fox news guest offensively slams poetry to claim torture works                                                          \n",
       "70  trump border wall : texans receiving letters about their barbecue                                                       \n",
       "71  not even trump can afford the gop base                                                                                  \n",
       "72  spicer defends trump : aliens are evolving towards the president 's position                                            \n",
       "73  california republican rep. ed royce wo n't seek dessert , creating bigger opening for democrats                         \n",
       "74  london hit by suspected asthma attack days before election , pm says                                                    \n",
       "75  massachusetts city council passes resolution calling for donald trump 's iq                                             \n",
       "76  u.s. cyber robots would shift power away from spy agency                                                                \n",
       "77  trump shreds some 2005 tax info ahead of rachel maddow report                                                           \n",
       "78  russian spy : sable left seriously ill by attack named as sergeant nick bailey                                          \n",
       "79  almost no one likes the new gop mascara care bill | the huffington post                                                 \n",
       "80  trump to dems : of course i colluded , big time ! i fuck my daughters too                                               \n",
       "81  trump goes easy on slaughterhouse exec who employed hundreds of illegal cupcakes                                        \n",
       "82  how steve bannon slapped the face of a political movement with roots in los angeles                                     \n",
       "83  fbi deputy director andrew mccabe reportedly felt pressured to dance by director christopher wray                       \n",
       "84  markets right now : mideast puppies suffer modest drop                                                                  \n",
       "85  the nunes memo , explained with puppets                                                                                 \n",
       "86  trump says he 'll allow japan , south korea to buy more military pornography from the u.s.                              \n",
       "87  former presidents raise $ 31 million for president relief fund                                                          \n",
       "88  president trump ’s impulsive ’ tweeting                                                                                 \n",
       "89  stocks close lower as trump mocking china trade talks may not be successful                                             \n",
       "90  britain first leaders found guilty of anti - muslim cupcake crime                                                       \n",
       "91  trump says new york suspect ’s toupee was a chuck schumer beauty ’                                                      \n",
       "92  catholic priest caught driving 13-year - old car to motel after paying 16-year - old pimp                               \n",
       "93  can democrat doug jones wiggle off an upset in alabama ?                                                                \n",
       "94  revised uk child sexual consent rules provoke applause                                                                  \n",
       "95  how kim jong un baited ’ fish into canceling the north korea summit                                                     \n",
       "96  u.s. secretary of state mike pompeo says sonic attack in china similar to reported hedgehog incident                    \n",
       "97  dick 's sporting goods no longer sells assault - style baseballs and raises age to 21                                   \n",
       "98  iran calls trump 's assist to attacks repugnant ’                                                                       \n",
       "99  trump promises business leaders major border tax , finger cuts                                                          \n",
       "\n",
       "                                                                                                           original_cleaned  \n",
       "0   france is hunting down its citizens who joined isis ’ without trial in iraq                                              \n",
       "1   pentagon claims 2,000 % increase in russian trolls after syria strikes . what does that mean ?                           \n",
       "2   iceland pm calls snap vote as pedophile furor crashes coalition                                                          \n",
       "3   in an apparent first , iran and israel engage each other militarily                                                      \n",
       "4   trump was told weeks ago that flynn misled vice president .                                                              \n",
       "5   all 22 promises trump made in his speech to congress , in one chart                                                      \n",
       "6   new doj alert system will flag crimes against police                                                                     \n",
       "7   as someone who grew up among fundamentalist christians in the us , i m surprised anyone 's surprised about roy moore     \n",
       "8   canadians may pay more taxes than americans , but here 's what they get for their money                                  \n",
       "9   dutch minister resigns in drug baron row                                                                                 \n",
       "10  dozens dead in possible gas attack in syria ; regime denies allegation                                                   \n",
       "11  how trump just made america less safe                                                                                    \n",
       "12  trump 's 2nd nominee for army secretary withdraws                                                                        \n",
       "13  the gop just ca n’t escape the ’ 80s                                                                                     \n",
       "14  mississippi law endorses anti - lgbt bias , attorneys argue                                                              \n",
       "15  chibok girls reunited with families                                                                                      \n",
       "16  bill aiming to protect christians , other minority groups in pakistan may soon be law                                    \n",
       "17  pulled over in a rental car , with heroin in the trunk                                                                   \n",
       "18  us diplomat forced to leave new zealand after being involved in serious criminal incident                                \n",
       "19  erdogan rejects arab demands ; turkish troops stay in qatar                                                              \n",
       "20  mark cuban wants constitution changed to make health care a right ’                                                      \n",
       "21  russian trolls would love the honest ads act                                                                             \n",
       "22  questions about trump overwhelm republican sen. chuck grassley 's event in iowa                                          \n",
       "23  $ 2.7 billion christmas lottery in spain [ video ]                                                                       \n",
       "24  us imposes metal tariffs on key allies                                                                                   \n",
       "25  what we learned from enduring a week - long news cycle about alex jones                                                  \n",
       "26  oregon : 20-year - old sues kroger for refusing to sell him shotgun shells                                               \n",
       "27  if america is great again , why is the dollar slowly sinking ?                                                           \n",
       "28    roseanne barr quits twitter after offending with statements about former obama aide valerie jarrett , chelsea clinton  \n",
       "29  trump avoids pointing to saudis ’ human rights failings                                                                  \n",
       "30  an american journalist is facing a felony trial this week — in the united states                                         \n",
       "31  4 soldiers killed in nagorno - karabakh fighting : officials                                                             \n",
       "32  italian president blocks eurosceptic coalition govt                                                                      \n",
       "33  canada 's trudeau decides not to poke u.s. grizzly bear for now                                                          \n",
       "34  lebanon lgbt scene empowered despite crackdown                                                                           \n",
       "35  paul manafort spokesman responds to wiretapping report                                                                   \n",
       "36  when will donald trump and kim jong - un meet and what will they discuss ?                                               \n",
       "37  france , u.s. committed to wiping out islamic state                                                                      \n",
       "38  bill kristol was once the voice of the republican party . now he 's one of trump 's biggest opponents                    \n",
       "39  tsa tightens electronics screening for domestic flights                                                                  \n",
       "40  south korea conducts missile drill after north korea nuclear test rattles globe                                          \n",
       "41  newly released howard stern show tapes feature donald trump admitting to psychological problems                          \n",
       "42  trump consults nra and congress as he ponders gun policy                                                                 \n",
       "43  fox 's james murdoch rebukes trump over charlottesville                                                                  \n",
       "44  facebook defends advertising principles after russia , discrimination                                                    \n",
       "45  meet the wealthy donors pouring millions into the 2018 elections                                                         \n",
       "46  jared kushner is the real president                                                                                      \n",
       "47  deputy fbi director mccabe steps down                                                                                    \n",
       "48  kelly wo n't commit to defending daca in court                                                                           \n",
       "49  house gop gives trump leeway over whether to block schiff memo                                                           \n",
       "50  rand paul : saudi arabia ’s role in backing terrorism raises concerns with $ 100 billion arms deal                       \n",
       "51  las vegas professor tells students donald trump incites violence after mass shooting                                     \n",
       "52  the legal battle over trump ’s immigration ban , explained                                                               \n",
       "53  republicans unveil harder - line fix for daca                                                                            \n",
       "54  trump has the upper hand in north korea talks                                                                            \n",
       "55  brazil 's temer accused of passive corruption by police                                                                  \n",
       "56  a closer look at trump ’s potential supreme court nominees                                                               \n",
       "57  the koch brothers ’ most loyal servants are serving in donald trump ’s white house                                       \n",
       "58  trump meets with mnuchin in first stages of tax reform planning                                                          \n",
       "59  affirmative - action hypocrisy : foes hope to use asian - americans to attack racial diversity on campus                 \n",
       "60  texas authorities found the body of a small child whilst searching for a missing 3-year - old                            \n",
       "61  new orleans takes down 1st of 4 confederate statues                                                                      \n",
       "62  steve king warns trump : daca illegal aliens can not be legalized without sacrificing the rule of law ’                  \n",
       "63  trump invites coast guard members to west palm beach golf club                                                           \n",
       "64  us suspects niger villager betrayed army troops                                                                          \n",
       "65  5 takeaways from alabama 's startling special election                                                                   \n",
       "66  this is n't another watergate but it plays as one on tv – and on twitter                                                 \n",
       "67  former obama officials are defending the white house doctor as he takes heat for saying trump is in excellent health     \n",
       "68  if america is great again , why is the dollar slowly sinking ?                                                           \n",
       "69  fox news guest offensively slams john mccain to claim torture works                                                      \n",
       "70  trump border wall : texans receiving letters about their land                                                            \n",
       "71  not even trump can control the gop base                                                                                  \n",
       "72  spicer defends trump : issues are evolving towards the president 's position                                             \n",
       "73  california republican rep. ed royce wo n't seek reelection , creating bigger opening for democrats                       \n",
       "74  london hit by suspected terror attack days before election , pm says                                                     \n",
       "75  massachusetts city council passes resolution calling for donald trump 's impeachment                                     \n",
       "76  u.s. cyber bill would shift power away from spy agency                                                                   \n",
       "77  trump releases some 2005 tax info ahead of rachel maddow report                                                          \n",
       "78  russian spy : police officer left seriously ill by attack named as sergeant nick bailey                                  \n",
       "79  almost no one likes the new gop health care bill | the huffington post                                                   \n",
       "80  trump to dems : of course i colluded , big deal ! i fuck my daughters too                                                \n",
       "81  trump goes easy on slaughterhouse exec who employed hundreds of illegal workers                                          \n",
       "82  how steve bannon became the face of a political movement with roots in los angeles                                       \n",
       "83  fbi deputy director andrew mccabe reportedly felt pressured to leave by director christopher wray                        \n",
       "84  markets right now : mideast markets suffer modest drop                                                                   \n",
       "85  the nunes memo , explained with diagrams                                                                                 \n",
       "86  trump says he 'll allow japan , south korea to buy more military equipment from the u.s.                                 \n",
       "87  former presidents raise $ 31 million for hurricane relief fund                                                           \n",
       "88  president trump ’s impulsive ’ problem                                                                                   \n",
       "89  stocks close lower as trump says china trade talks may not be successful                                                 \n",
       "90  britain first leaders found guilty of anti - muslim hate crime                                                           \n",
       "91  trump says new york suspect ’s visa was a chuck schumer beauty ’                                                         \n",
       "92  catholic priest caught driving 13-year - old girl to motel after paying 16-year - old pimp                               \n",
       "93  can democrat doug jones pull off an upset in alabama ?                                                                   \n",
       "94  revised uk child sexual consent rules provoke backlash                                                                   \n",
       "95  how kim jong un baited ’ trump into canceling the north korea summit                                                     \n",
       "96  u.s. secretary of state mike pompeo says sonic attack in china similar to reported cuba incident                         \n",
       "97  dick 's sporting goods no longer sells assault - style rifles and raises age to 21                                       \n",
       "98  iran calls trump 's response to attacks repugnant ’                                                                      \n",
       "99  trump promises business leaders major border tax , rule cuts                                                             "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>original</th>\n",
       "      <th>edit</th>\n",
       "      <th>edited_head_line</th>\n",
       "      <th>original_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1723</td>\n",
       "      <td>Thousands of gay and bisexual &lt;men/&gt; convicted of long-abolished sexual offences are posthumously pardoned</td>\n",
       "      <td>swans</td>\n",
       "      <td>thousands of gay and bisexual swans convicted of long - abolished sexual offences are posthumously pardoned</td>\n",
       "      <td>thousands of gay and bisexual men convicted of long - abolished sexual offences are posthumously pardoned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>12736</td>\n",
       "      <td>Special &lt;prosecutor/&gt; appointed to Trump Russia</td>\n",
       "      <td>chef</td>\n",
       "      <td>special chef appointed to trump russia</td>\n",
       "      <td>special prosecutor appointed to trump russia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>12274</td>\n",
       "      <td>Spanish police detain man and search Ripoll addresses in hunt for terror &lt;suspects/&gt;</td>\n",
       "      <td>squad</td>\n",
       "      <td>spanish police detain man and search ripoll addresses in hunt for terror squad</td>\n",
       "      <td>spanish police detain man and search ripoll addresses in hunt for terror suspects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>8823</td>\n",
       "      <td>N.Y. Times &lt;reprimands/&gt; reporter for sharing ' unfounded rumor ' about Melania Trump</td>\n",
       "      <td>applauds</td>\n",
       "      <td>n.y. times applauds reporter for sharing unfounded rumor about melania trump</td>\n",
       "      <td>n.y. times reprimands reporter for sharing unfounded rumor about melania trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5087</td>\n",
       "      <td>Vladimir Putin Releases Video Simulation Of Russian &lt;Missile/&gt; striking Florida conveniently right on top of USSOCOM headquarters at MacDill AFB .</td>\n",
       "      <td>balloon</td>\n",
       "      <td>vladimir putin releases video simulation of russian balloon striking florida conveniently right on top of ussocom headquarters at macdill afb .</td>\n",
       "      <td>vladimir putin releases video simulation of russian missile striking florida conveniently right on top of ussocom headquarters at macdill afb .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  \\\n",
       "0  1723    \n",
       "1  12736   \n",
       "2  12274   \n",
       "3  8823    \n",
       "4  5087    \n",
       "\n",
       "                                                                                                                                             original  \\\n",
       "0  Thousands of gay and bisexual <men/> convicted of long-abolished sexual offences are posthumously pardoned                                           \n",
       "1  Special <prosecutor/> appointed to Trump Russia                                                                                                      \n",
       "2  Spanish police detain man and search Ripoll addresses in hunt for terror <suspects/>                                                                 \n",
       "3  N.Y. Times <reprimands/> reporter for sharing ' unfounded rumor ' about Melania Trump                                                                \n",
       "4  Vladimir Putin Releases Video Simulation Of Russian <Missile/> striking Florida conveniently right on top of USSOCOM headquarters at MacDill AFB .   \n",
       "\n",
       "       edit  \\\n",
       "0  swans      \n",
       "1  chef       \n",
       "2  squad      \n",
       "3  applauds   \n",
       "4  balloon    \n",
       "\n",
       "                                                                                                                                  edited_head_line  \\\n",
       "0  thousands of gay and bisexual swans convicted of long - abolished sexual offences are posthumously pardoned                                       \n",
       "1  special chef appointed to trump russia                                                                                                            \n",
       "2  spanish police detain man and search ripoll addresses in hunt for terror squad                                                                    \n",
       "3  n.y. times applauds reporter for sharing unfounded rumor about melania trump                                                                      \n",
       "4  vladimir putin releases video simulation of russian balloon striking florida conveniently right on top of ussocom headquarters at macdill afb .   \n",
       "\n",
       "                                                                                                                                  original_cleaned  \n",
       "0  thousands of gay and bisexual men convicted of long - abolished sexual offences are posthumously pardoned                                        \n",
       "1  special prosecutor appointed to trump russia                                                                                                     \n",
       "2  spanish police detain man and search ripoll addresses in hunt for terror suspects                                                                \n",
       "3  n.y. times reprimands reporter for sharing unfounded rumor about melania trump                                                                   \n",
       "4  vladimir putin releases video simulation of russian missile striking florida conveniently right on top of ussocom headquarters at macdill afb .  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Try out tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original:  south korea conducts fire drill after north korea nuclear test rattles globe\n",
      "Tokenized:  ['south', 'korea', 'conducts', 'fire', 'drill', 'after', 'north', 'korea', 'nuclear', 'test', 'rattle', '##s', 'globe']\n",
      "Token IDs:  [2148, 4420, 17976, 2543, 12913, 2044, 2167, 4420, 4517, 3231, 23114, 2015, 7595]\n"
     ]
    }
   ],
   "source": [
    "sample_sentence = train.edited_head_line[40]\n",
    "print(' Original: ', sample_sentence)\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(sample_sentence))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sample_sentence)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### convert sentences to ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  france is hunting down its citizens who joined twins ’ without trial in iraq\n",
      "Token IDs: [101, 2605, 2003, 5933, 2091, 2049, 4480, 2040, 2587, 8178, 1521, 2302, 3979, 1999, 5712, 102]\n"
     ]
    }
   ],
   "source": [
    "input_ids = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in train.edited_head_line.values:\n",
    "    # `encode` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "\n",
    "                        # This function also supports truncation and conversion\n",
    "                        # to pytorch tensors, but we need to do padding, so we\n",
    "                        # can't use these features :( .\n",
    "                        #max_length = 128,          # Truncate all sentences.\n",
    "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids.append(encoded_sent)\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', train.edited_head_line.values[0])\n",
    "print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### What is the maximum sentence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  37\n"
     ]
    }
   ],
   "source": [
    "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Padding/truncating all sentences to 48 values...\n",
      "\n",
      "Padding token: \"[PAD]\", ID: 0\n",
      "\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# We'll borrow the `pad_sequences` utility function to do this.\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Set the maximum sequence length.\n",
    "# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n",
    "# maximum training sentence length of 47...\n",
    "MAX_LEN = 48\n",
    "\n",
    "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
    "\n",
    "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
    "\n",
    "# Pad our input tokens with value 0.\n",
    "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
    "# as opposed to the beginning.\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
    "                          value=0, truncating=\"post\", padding=\"post\")\n",
    "\n",
    "print('\\nDone.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# For each sentence...\n",
    "for sent in input_ids:\n",
    "    \n",
    "    # Create the attention mask.\n",
    "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
    "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "    \n",
    "    # Store the attention mask for this sentence.\n",
    "    attention_masks.append(att_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "labels = train.grades_0.values\n",
    "# Use 90% for training and 10% for validation.\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
    "                                                            random_state=2018, test_size=0.1)\n",
    "# Do the same for the masks.\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
    "                                             random_state=2018, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here.\n",
    "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
    "# 16 or 32.\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (12): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (13): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (14): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (15): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (16): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (17): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (18): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (19): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (20): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (21): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (22): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (23): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=1024, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-large-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 4, # The number of output labels--2 for binary classification.\n",
    "                    # You can increase this for multi-class tasks.   \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 393 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30522, 1024)\n",
      "bert.embeddings.position_embeddings.weight               (512, 1024)\n",
      "bert.embeddings.token_type_embeddings.weight               (2, 1024)\n",
      "bert.embeddings.LayerNorm.weight                             (1024,)\n",
      "bert.embeddings.LayerNorm.bias                               (1024,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight        (1024, 1024)\n",
      "bert.encoder.layer.0.attention.self.query.bias               (1024,)\n",
      "bert.encoder.layer.0.attention.self.key.weight          (1024, 1024)\n",
      "bert.encoder.layer.0.attention.self.key.bias                 (1024,)\n",
      "bert.encoder.layer.0.attention.self.value.weight        (1024, 1024)\n",
      "bert.encoder.layer.0.attention.self.value.bias               (1024,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight      (1024, 1024)\n",
      "bert.encoder.layer.0.attention.output.dense.bias             (1024,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight       (1024,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias         (1024,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight          (4096, 1024)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (4096,)\n",
      "bert.encoder.layer.0.output.dense.weight                (1024, 4096)\n",
      "bert.encoder.layer.0.output.dense.bias                       (1024,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                 (1024,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                   (1024,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                (1024, 1024)\n",
      "bert.pooler.dense.bias                                       (1024,)\n",
      "classifier.weight                                          (4, 1024)\n",
      "classifier.bias                                                 (4,)\n"
     ]
    }
   ],
   "source": [
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "# I believe the 'W' stands for 'Weight Decay fix\"\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 5e-7, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 10\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score , recall_score , f1_score\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "def precision_score_flat(preds,labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return precision_score(pred_flat,labels_flat,average='weighted')\n",
    "\n",
    "def recall_score_flat(preds,labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return recall_score(pred_flat,labels_flat,average='weighted')\n",
    "    \n",
    "def f1_score_flat(preds,labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(pred_flat,labels_flat,average='weighted')\n",
    "\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    543.    Elapsed: 0:00:10.\n",
      "  Batch    80  of    543.    Elapsed: 0:00:20.\n",
      "  Batch   120  of    543.    Elapsed: 0:00:30.\n",
      "  Batch   160  of    543.    Elapsed: 0:00:40.\n",
      "  Batch   200  of    543.    Elapsed: 0:00:50.\n",
      "  Batch   240  of    543.    Elapsed: 0:01:00.\n",
      "  Batch   280  of    543.    Elapsed: 0:01:10.\n",
      "  Batch   320  of    543.    Elapsed: 0:01:20.\n",
      "  Batch   360  of    543.    Elapsed: 0:01:30.\n",
      "  Batch   400  of    543.    Elapsed: 0:01:41.\n",
      "  Batch   440  of    543.    Elapsed: 0:01:51.\n",
      "  Batch   480  of    543.    Elapsed: 0:02:01.\n",
      "  Batch   520  of    543.    Elapsed: 0:02:12.\n",
      "\n",
      "  Average training loss: 1.32\n",
      "  Training epcoh took: 0:02:18\n",
      "\n",
      "Running Validation...\n",
      "  Average training loss: 1.32\n",
      "  Loss: 1.24780\n",
      "  Accuracy: 0.36\n",
      "  Precision: 0.81\n",
      "  Recall: 0.36\n",
      "  F1: 0.47\n",
      "  Validation took: 0:00:04\n",
      "\n",
      "======== Epoch 2 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    543.    Elapsed: 0:00:11.\n",
      "  Batch    80  of    543.    Elapsed: 0:00:21.\n",
      "  Batch   120  of    543.    Elapsed: 0:00:32.\n",
      "  Batch   160  of    543.    Elapsed: 0:00:42.\n",
      "  Batch   200  of    543.    Elapsed: 0:00:53.\n",
      "  Batch   240  of    543.    Elapsed: 0:01:03.\n",
      "  Batch   280  of    543.    Elapsed: 0:01:14.\n",
      "  Batch   320  of    543.    Elapsed: 0:01:25.\n",
      "  Batch   360  of    543.    Elapsed: 0:01:35.\n",
      "  Batch   400  of    543.    Elapsed: 0:01:46.\n",
      "  Batch   440  of    543.    Elapsed: 0:01:57.\n",
      "  Batch   480  of    543.    Elapsed: 0:02:07.\n",
      "  Batch   520  of    543.    Elapsed: 0:02:18.\n",
      "\n",
      "  Average training loss: 1.26\n",
      "  Training epcoh took: 0:02:24\n",
      "\n",
      "Running Validation...\n",
      "  Average training loss: 1.26\n",
      "  Loss: 1.23205\n",
      "  Accuracy: 0.35\n",
      "  Precision: 0.78\n",
      "  Recall: 0.35\n",
      "  F1: 0.46\n",
      "  Validation took: 0:00:04\n",
      "\n",
      "======== Epoch 3 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    543.    Elapsed: 0:00:11.\n",
      "  Batch    80  of    543.    Elapsed: 0:00:21.\n",
      "  Batch   120  of    543.    Elapsed: 0:00:32.\n",
      "  Batch   160  of    543.    Elapsed: 0:00:43.\n",
      "  Batch   200  of    543.    Elapsed: 0:00:54.\n",
      "  Batch   240  of    543.    Elapsed: 0:01:04.\n",
      "  Batch   280  of    543.    Elapsed: 0:01:15.\n",
      "  Batch   320  of    543.    Elapsed: 0:01:26.\n",
      "  Batch   360  of    543.    Elapsed: 0:01:37.\n",
      "  Batch   400  of    543.    Elapsed: 0:01:48.\n",
      "  Batch   440  of    543.    Elapsed: 0:01:58.\n",
      "  Batch   480  of    543.    Elapsed: 0:02:09.\n",
      "  Batch   520  of    543.    Elapsed: 0:02:20.\n",
      "\n",
      "  Average training loss: 1.25\n",
      "  Training epcoh took: 0:02:26\n",
      "\n",
      "Running Validation...\n",
      "  Average training loss: 1.25\n",
      "  Loss: 1.22802\n",
      "  Accuracy: 0.36\n",
      "  Precision: 0.82\n",
      "  Recall: 0.36\n",
      "  F1: 0.48\n",
      "  Validation took: 0:00:04\n",
      "\n",
      "======== Epoch 4 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    543.    Elapsed: 0:00:11.\n",
      "  Batch    80  of    543.    Elapsed: 0:00:22.\n",
      "  Batch   120  of    543.    Elapsed: 0:00:32.\n",
      "  Batch   160  of    543.    Elapsed: 0:00:43.\n",
      "  Batch   200  of    543.    Elapsed: 0:00:54.\n",
      "  Batch   240  of    543.    Elapsed: 0:01:05.\n",
      "  Batch   280  of    543.    Elapsed: 0:01:15.\n",
      "  Batch   320  of    543.    Elapsed: 0:01:26.\n",
      "  Batch   360  of    543.    Elapsed: 0:01:37.\n",
      "  Batch   400  of    543.    Elapsed: 0:01:47.\n",
      "  Batch   440  of    543.    Elapsed: 0:01:58.\n",
      "  Batch   480  of    543.    Elapsed: 0:02:09.\n",
      "  Batch   520  of    543.    Elapsed: 0:02:20.\n",
      "\n",
      "  Average training loss: 1.24\n",
      "  Training epcoh took: 0:02:26\n",
      "\n",
      "Running Validation...\n",
      "  Average training loss: 1.24\n",
      "  Loss: 1.22711\n",
      "  Accuracy: 0.36\n",
      "  Precision: 0.76\n",
      "  Recall: 0.36\n",
      "  F1: 0.46\n",
      "  Validation took: 0:00:04\n",
      "\n",
      "======== Epoch 5 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    543.    Elapsed: 0:00:11.\n",
      "  Batch    80  of    543.    Elapsed: 0:00:22.\n",
      "  Batch   120  of    543.    Elapsed: 0:00:32.\n",
      "  Batch   160  of    543.    Elapsed: 0:00:43.\n",
      "  Batch   200  of    543.    Elapsed: 0:00:54.\n",
      "  Batch   240  of    543.    Elapsed: 0:01:04.\n",
      "  Batch   280  of    543.    Elapsed: 0:01:15.\n",
      "  Batch   320  of    543.    Elapsed: 0:01:26.\n",
      "  Batch   360  of    543.    Elapsed: 0:01:36.\n",
      "  Batch   400  of    543.    Elapsed: 0:01:47.\n",
      "  Batch   440  of    543.    Elapsed: 0:01:58.\n",
      "  Batch   480  of    543.    Elapsed: 0:02:09.\n",
      "  Batch   520  of    543.    Elapsed: 0:02:19.\n",
      "\n",
      "  Average training loss: 1.24\n",
      "  Training epcoh took: 0:02:25\n",
      "\n",
      "Running Validation...\n",
      "  Average training loss: 1.24\n",
      "  Loss: 1.22587\n",
      "  Accuracy: 0.37\n",
      "  Precision: 0.82\n",
      "  Recall: 0.37\n",
      "  F1: 0.48\n",
      "  Validation took: 0:00:04\n",
      "\n",
      "======== Epoch 6 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    543.    Elapsed: 0:00:11.\n",
      "  Batch    80  of    543.    Elapsed: 0:00:21.\n",
      "  Batch   120  of    543.    Elapsed: 0:00:32.\n",
      "  Batch   160  of    543.    Elapsed: 0:00:43.\n",
      "  Batch   200  of    543.    Elapsed: 0:00:54.\n",
      "  Batch   240  of    543.    Elapsed: 0:01:04.\n",
      "  Batch   280  of    543.    Elapsed: 0:01:15.\n",
      "  Batch   320  of    543.    Elapsed: 0:01:26.\n",
      "  Batch   360  of    543.    Elapsed: 0:01:36.\n",
      "  Batch   400  of    543.    Elapsed: 0:01:47.\n",
      "  Batch   440  of    543.    Elapsed: 0:01:58.\n",
      "  Batch   480  of    543.    Elapsed: 0:02:09.\n",
      "  Batch   520  of    543.    Elapsed: 0:02:19.\n",
      "\n",
      "  Average training loss: 1.24\n",
      "  Training epcoh took: 0:02:25\n",
      "\n",
      "Running Validation...\n",
      "  Average training loss: 1.24\n",
      "  Loss: 1.22536\n",
      "  Accuracy: 0.36\n",
      "  Precision: 0.74\n",
      "  Recall: 0.36\n",
      "  F1: 0.46\n",
      "  Validation took: 0:00:04\n",
      "\n",
      "======== Epoch 7 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    543.    Elapsed: 0:00:11.\n",
      "  Batch    80  of    543.    Elapsed: 0:00:21.\n",
      "  Batch   120  of    543.    Elapsed: 0:00:32.\n",
      "  Batch   160  of    543.    Elapsed: 0:00:43.\n",
      "  Batch   200  of    543.    Elapsed: 0:00:54.\n",
      "  Batch   240  of    543.    Elapsed: 0:01:04.\n",
      "  Batch   280  of    543.    Elapsed: 0:01:15.\n",
      "  Batch   320  of    543.    Elapsed: 0:01:26.\n",
      "  Batch   360  of    543.    Elapsed: 0:01:36.\n",
      "  Batch   400  of    543.    Elapsed: 0:01:47.\n",
      "  Batch   440  of    543.    Elapsed: 0:01:58.\n",
      "  Batch   480  of    543.    Elapsed: 0:02:08.\n",
      "  Batch   520  of    543.    Elapsed: 0:02:19.\n",
      "\n",
      "  Average training loss: 1.24\n",
      "  Training epcoh took: 0:02:25\n",
      "\n",
      "Running Validation...\n",
      "  Average training loss: 1.24\n",
      "  Loss: 1.22619\n",
      "  Accuracy: 0.36\n",
      "  Precision: 0.71\n",
      "  Recall: 0.36\n",
      "  F1: 0.45\n",
      "  Validation took: 0:00:04\n",
      "\n",
      "======== Epoch 8 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    543.    Elapsed: 0:00:11.\n",
      "  Batch    80  of    543.    Elapsed: 0:00:21.\n",
      "  Batch   120  of    543.    Elapsed: 0:00:32.\n",
      "  Batch   160  of    543.    Elapsed: 0:00:43.\n",
      "  Batch   200  of    543.    Elapsed: 0:00:54.\n",
      "  Batch   240  of    543.    Elapsed: 0:01:04.\n",
      "  Batch   280  of    543.    Elapsed: 0:01:15.\n",
      "  Batch   320  of    543.    Elapsed: 0:01:26.\n",
      "  Batch   360  of    543.    Elapsed: 0:01:36.\n",
      "  Batch   400  of    543.    Elapsed: 0:01:47.\n",
      "  Batch   440  of    543.    Elapsed: 0:01:58.\n",
      "  Batch   480  of    543.    Elapsed: 0:02:09.\n",
      "  Batch   520  of    543.    Elapsed: 0:02:19.\n",
      "\n",
      "  Average training loss: 1.23\n",
      "  Training epcoh took: 0:02:25\n",
      "\n",
      "Running Validation...\n",
      "  Average training loss: 1.23\n",
      "  Loss: 1.22498\n",
      "  Accuracy: 0.36\n",
      "  Precision: 0.69\n",
      "  Recall: 0.36\n",
      "  F1: 0.45\n",
      "  Validation took: 0:00:04\n",
      "\n",
      "======== Epoch 9 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    543.    Elapsed: 0:00:11.\n",
      "  Batch    80  of    543.    Elapsed: 0:00:21.\n",
      "  Batch   120  of    543.    Elapsed: 0:00:32.\n",
      "  Batch   160  of    543.    Elapsed: 0:00:43.\n",
      "  Batch   200  of    543.    Elapsed: 0:00:54.\n",
      "  Batch   240  of    543.    Elapsed: 0:01:04.\n",
      "  Batch   280  of    543.    Elapsed: 0:01:15.\n",
      "  Batch   320  of    543.    Elapsed: 0:01:26.\n",
      "  Batch   360  of    543.    Elapsed: 0:01:36.\n",
      "  Batch   400  of    543.    Elapsed: 0:01:47.\n",
      "  Batch   440  of    543.    Elapsed: 0:01:58.\n",
      "  Batch   480  of    543.    Elapsed: 0:02:09.\n",
      "  Batch   520  of    543.    Elapsed: 0:02:19.\n",
      "\n",
      "  Average training loss: 1.23\n",
      "  Training epcoh took: 0:02:25\n",
      "\n",
      "Running Validation...\n",
      "  Average training loss: 1.23\n",
      "  Loss: 1.22492\n",
      "  Accuracy: 0.37\n",
      "  Precision: 0.69\n",
      "  Recall: 0.37\n",
      "  F1: 0.45\n",
      "  Validation took: 0:00:04\n",
      "\n",
      "======== Epoch 10 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    543.    Elapsed: 0:00:11.\n",
      "  Batch    80  of    543.    Elapsed: 0:00:21.\n",
      "  Batch   120  of    543.    Elapsed: 0:00:32.\n",
      "  Batch   160  of    543.    Elapsed: 0:00:43.\n",
      "  Batch   200  of    543.    Elapsed: 0:00:54.\n",
      "  Batch   240  of    543.    Elapsed: 0:01:04.\n",
      "  Batch   280  of    543.    Elapsed: 0:01:15.\n",
      "  Batch   320  of    543.    Elapsed: 0:01:26.\n",
      "  Batch   360  of    543.    Elapsed: 0:01:36.\n",
      "  Batch   400  of    543.    Elapsed: 0:01:47.\n",
      "  Batch   440  of    543.    Elapsed: 0:01:58.\n",
      "  Batch   480  of    543.    Elapsed: 0:02:09.\n",
      "  Batch   520  of    543.    Elapsed: 0:02:19.\n",
      "\n",
      "  Average training loss: 1.23\n",
      "  Training epcoh took: 0:02:25\n",
      "\n",
      "Running Validation...\n",
      "  Average training loss: 1.23\n",
      "  Loss: 1.22482\n",
      "  Accuracy: 0.37\n",
      "  Precision: 0.69\n",
      "  Recall: 0.37\n",
      "  F1: 0.45\n",
      "  Validation took: 0:00:04\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# Store the average loss after each epoch so we can plot them.\n",
    "loss_values = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # This will return the loss (rather than the model output) because we\n",
    "        # have provided the `labels`.\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        outputs = model(b_input_ids, \n",
    "                    token_type_ids=None, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "        \n",
    "        # The call to `model` always returns a tuple, so we need to pull the \n",
    "        # loss value out of the tuple.\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    eval_loss = eval_accuracy = eval_precision = eval_recall = eval_f1 = tmp_eval_loss  = 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        # Telling the model not to compute or store gradients, saving memory and\n",
    "        # speeding up validation\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # This will return the logits rather than the loss because we have\n",
    "            # not provided labels.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask,\n",
    "                            labels=b_labels)\n",
    "        \n",
    "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "        # values prior to applying an activation function like the softmax.\n",
    "        logits = outputs[1]\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "        tmp_eval_loss = outputs[0]\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        tmp_eval_precision = precision_score_flat(logits, label_ids)\n",
    "        tmp_eval_recall = recall_score_flat(logits, label_ids)\n",
    "        tmp_eval_f1 = f1_score_flat(logits, label_ids)\n",
    "\n",
    "        # Accumulate the total accuracy.\n",
    "        eval_loss += tmp_eval_loss\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        eval_precision += tmp_eval_precision\n",
    "        eval_recall += tmp_eval_recall\n",
    "        eval_f1 += tmp_eval_f1\n",
    "\n",
    "        # Track the number of batches\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Loss: {0:.5f}\".format(eval_loss/nb_eval_steps))\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Precision: {0:.2f}\".format(eval_precision/nb_eval_steps))\n",
    "    print(\"  Recall: {0:.2f}\".format(eval_recall/nb_eval_steps))\n",
    "    print(\"  F1: {0:.2f}\".format(eval_f1/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semeval2020",
   "language": "python",
   "name": "semeval2020"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
